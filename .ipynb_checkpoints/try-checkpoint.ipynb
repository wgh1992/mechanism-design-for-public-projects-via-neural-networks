{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 9773056/9912422 [00:14<00:00, 1075743.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\n",
      " 57%|█████▋    | 16384/28881 [00:00<00:00, 62237.78it/s]\n",
      "32768it [00:00, 41490.10it/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\n",
      "  1%|          | 16384/1648877 [00:00<00:29, 55379.77it/s]\n",
      "  3%|▎         | 49152/1648877 [00:01<00:23, 68558.90it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# 超参数\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "TIME_STEP = 28  # rnn time step  / image height\n",
    "INPUT_SIZE = 28  # rnn input size / image width\n",
    "LR = 0.01\n",
    "DOWNLOWD_MNIST = True  # 如果没有下载好MNIST数据，设置为True\n",
    " \n",
    "# 下载数据\n",
    "# 训练数据\n",
    "train_data = datasets.MNIST(root='./mnist', train=True, transform=transforms.ToTensor(), download=DOWNLOWD_MNIST)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "#print(train_data.train_data.shape) 60000*28*28\n",
    "\n",
    "# 测试数据\n",
    "test_data = datasets.MNIST(root='./mnist', train=False)\n",
    "#print(test_data.test_data.shape)大小10000*28*28\n",
    "test_x = Variable(test_data.test_data, volatile=True).type(torch.FloatTensor)[:2000] / 255. # size 2000*28*28\n",
    "\n",
    "test_y = test_data.test_labels.numpy()[:2000]\n",
    "\n",
    " \n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    " \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=64,\n",
    "            num_layers=2,  # hidden_layer的数目\n",
    "            batch_first=True,  # 输入数据的维度一般是（batch, time_step, input)，该属性表征batch是否放在第一个维度\n",
    "        )\n",
    " \n",
    "        self.out = nn.Linear(64, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        # rnn 运行的结果出了每层的输出之外，还有该层要传入下一层进行辅助分析的hidden state,\n",
    "        # lstm 的hidden state相比于 RNN，其分成了主线h_n,分线h_c\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)  # x shape ( batch, step, input_size), None 之前的hidden state（没有则填None）\n",
    "       # print(r_out.shape) 64* 28*64\n",
    "        # print(h_c.shape)  1*64*64\n",
    "        # print(h_n.shape)   1*64 *64\n",
    "        #print(r_out[:, -1, :].shape)\n",
    "        out = self.out(r_out[:, -1, :])  # 选取最后一个时刻的output，进行最终的类别判断\n",
    "        #print(out.shape)\n",
    "        return out\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN()\n",
    "# print(rnn)\n",
    " \n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)\n",
    "# 误差函数\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    " \n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        # X的size 64*1*28*28\n",
    "        b_x = Variable(x.view(-1, 28, 28))  # reshape x to (batch, time_step, input_size)\n",
    "       #b_x size 64*28*28\n",
    "        b_y = Variable(y)\n",
    "        #b_y size 64\n",
    "        #print(b_y)\n",
    "        output = rnn(b_x)\n",
    "        #print(output)\n",
    "        # print(output.shape) 64*10\n",
    "        loss = loss_func(output, b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        if step % 50 == 0:\n",
    "            test_output = rnn(test_x)\n",
    "            pred_y = np.squeeze(torch.max(test_output, 1)[1].data.numpy())\n",
    "            accuracy = float((pred_y == test_y).astype(int).sum()) / float(test_y.size)\n",
    "            print('Epoch: ', epoch, ' | train loss: %.4f' % loss.data.numpy(), ' | test accuracy: %.2f' % accuracy )\n",
    "            print(step)\n",
    " \n",
    "# 输出前10个测试数据的测试值\n",
    "test_output = rnn(test_x[: 10].view(-1, 28, 28))\n",
    "pred_y = np.squeeze(torch.max(test_output, 1)[1].data.numpy())\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
