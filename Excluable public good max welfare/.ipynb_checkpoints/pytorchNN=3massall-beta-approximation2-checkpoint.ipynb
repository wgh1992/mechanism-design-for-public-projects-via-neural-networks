{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3540388371733616\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from random import randint\n",
    "import random\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "global decision1,decision2\n",
    "global decision1,decision2,record_ans\n",
    "from pylab import *\n",
    "from scipy.stats import beta\n",
    "import math\n",
    "n = 5\n",
    "epochs = 1\n",
    "supervisionEpochs = 1\n",
    "lr1 = 0.001\n",
    "lr2 = 0.00001\n",
    "log_interval = 20\n",
    "trainSize = 60000#100000\n",
    "percentage_train_test= 0.25\n",
    "penaltyLambda = 10\n",
    "doublePeakHighMean = 0.9\n",
    "doublePeakLowMean = 0.1\n",
    "doublePeakStd = 0.1\n",
    "uniformlow=0\n",
    "uniformhigh=1.0\n",
    "normalloc = 0.2\n",
    "normalscale = 0.1\n",
    "\n",
    "cauchyloc = 1/n\n",
    "cauchyscalen = 0.004\n",
    "\n",
    "exponentialhigh = 15 #Symbol(\"b\", real=True)\n",
    "exponentiallow  = 15 #Symbol(\"a\", real=True)\n",
    "\n",
    "\n",
    "beta_a = 0.1\n",
    "beta_b  = 0.1\n",
    "kumaraswamy_a = beta_a \n",
    "kumaraswamy_b = (1.0+(beta_a-1.0)*math.pow( (beta_a+beta_b-2.0)/(beta_a-1.0), beta_a) )/beta_a \n",
    "print(kumaraswamy_b)\n",
    "\n",
    "independentnormalloc1=[(float(ii)+1)/(2*n+1) for ii in range(n,0,-1)]\n",
    "independentnormalscale1=[0.05 for ii in range(n)]\n",
    "\n",
    "independentnormalloc2=[(float(ii)+1)/(2*n+1) for ii in range(1,n+1,1)]\n",
    "independentnormalscale2=[0.05 for ii in range(n)]\n",
    "stage=[\"U-exponential\"]\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"beta\",\"U-exponential\",\"arcsine\"\n",
    "order1name=[\"dp\",\"random initializing\",\"costsharing\"]\n",
    "#order1name=[\"random initializing1\",\"random initializing2\",\"random initializing3\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = D.normal.Normal(doublePeakLowMean, doublePeakStd)\n",
    "d2 = D.normal.Normal(doublePeakHighMean, doublePeakStd)\n",
    "distributionRatio1 = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase1 = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(normalloc, normalscale)\n",
    "distributionRatio3 = d3.cdf(1) - d3.cdf(0)\n",
    "distributionBase3 = d3.cdf(0)\n",
    "\n",
    "d4 = D.uniform.Uniform(uniformlow,uniformhigh)\n",
    "distributionRatio4 = d4.cdf(1) - d4.cdf(0)\n",
    "distributionBase4 = d4.cdf(0)\n",
    "\n",
    "d5 = [D.normal.Normal(independentnormalloc1[ii], independentnormalscale1[ii]) for ii in range(n)]\n",
    "d6 = [D.normal.Normal(independentnormalloc2[ii], independentnormalscale2[ii]) for ii in range(n)]\n",
    "\n",
    "d7 = D.cauchy.Cauchy(cauchyloc,cauchyscalen)\n",
    "\n",
    "d81 = D.exponential.Exponential(exponentiallow)\n",
    "d82 = D.exponential.Exponential(exponentialhigh)\n",
    "\n",
    "d9 = D.beta.Beta(beta_a,beta_b)\n",
    "#sample_d9=d9.rsample(torch.Size([100000]))\n",
    "\n",
    "#d9_sample=np.linspace(0.0001, 0.9999, 10000)\n",
    "#d9_pdf=torch.exp(d9.log_prob(torch.tensor(d9_sample,dtype=torch.float32)))\n",
    "#d9_delta=d9_sample[1]-d9_sample[0]\n",
    "#d9_sum_pdf=torch.sum(d9_pdf*d9_delta)\n",
    "\n",
    "d10 = D.beta.Beta(0.5,0.5)\n",
    "\n",
    "def cdf(x,y, i=None):\n",
    "    if(y==\"twopeak\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) - distributionBase1) / 2 / distributionRatio1\n",
    "    elif(y==\"normal\"):\n",
    "        return (d3.cdf(x)-distributionBase3)/distributionRatio3;\n",
    "    elif(y==\"uniform\"):\n",
    "        return (d4.cdf(x)-distributionBase4)/distributionRatio4;\n",
    "    elif(y==\"independent1\"):\n",
    "        return d5[i].cdf(x);\n",
    "    elif(y==\"independent2\"):\n",
    "        return d6[i].cdf(x);\n",
    "    elif(y==\"cauchy\"):\n",
    "        return d7.cdf(x);\n",
    "    elif(y==\"beta\"):\n",
    "#         sum_cdf=0.0;\n",
    "#         if(x<0.0001):\n",
    "#             x=0.00011;\n",
    "#         if(x>0.9999):\n",
    "#             x=0.99989;\n",
    "#         for i in range(len(d9_pdf)):\n",
    "#             if(d9_sample[i]<x):\n",
    "#                 sum_cdf+=d9_pdf[i]*d9_delta;\n",
    "#             else:\n",
    "#                 sum_cdf+=(d9_pdf[i]+d9_pdf[i-1])/ 2 *(x-d9_sample[i-1])\n",
    "#                 break;\n",
    "#         return sum_cdf/d9_sum_pdf\n",
    "#         cdf_v=torch.sum((sample_d9<(x)), dtype=torch.float32)/100000\n",
    "#         return cdf_v\n",
    "#    F(x|a,b)=1–(1–x^a)^b\n",
    "        if(x<0.0000001):\n",
    "            x=0.0000001\n",
    "        elif(x >0.9999999):\n",
    "            x=0.9999999\n",
    "        try:\n",
    "            return 1.0-torch.pow(1.0-torch.pow(x,kumaraswamy_a),kumaraswamy_b);\n",
    "        except:\n",
    "            return 1.0-torch.pow(1.0-torch.pow(torch.tensor(x,dtype=torch.float32),kumaraswamy_a),kumaraswamy_b);\n",
    "    elif(y==\"arcsine\"):\n",
    "        #\n",
    "        if(x<0.0000001):\n",
    "            x=0.0000001\n",
    "        elif(x >0.9999999):\n",
    "            x=0.9999999\n",
    "        try:\n",
    "            res=2.0/math.pi * torch.asin(torch.sqrt(x))\n",
    "            #print(x)\n",
    "            return res# + 0.0001*1.0/(\n",
    "            #math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "        except:\n",
    "            return 2.0/math.pi * torch.asin(torch.sqrt(torch.tensor(x,dtype=torch.float32)))# + 0.0001*1.0/(\n",
    "            #math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "    elif(y==\"U-exponential\"):\n",
    "        return (d81.cdf(x) + (1.0 - d82.cdf(1.0-x)))  / 2 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global record_ans\n",
    "record_ans=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    if torch.sum(bits).item() == 0:\n",
    "        return torch.ones(n)\n",
    "    bits     = bits.type(torch.float32)\n",
    "    negBits  = torch.ones(n) - bits\n",
    "    payments = model(bits)\n",
    "    payments = payments - 1000 * negBits\n",
    "    payments = torch.softmax(payments, 0)\n",
    "    payments = payments + negBits\n",
    "    return payments\n",
    "\n",
    "def tpToBits(tp, bits=torch.ones(n).type(torch.uint8)):\n",
    "    payments = bitsToPayments(bits)\n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return tpToBits(tp, newBits)#bits-bits#tpToBits(tp, newBits)\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp))\n",
    "\n",
    "\n",
    "def tpToTotalWelfare(tp):\n",
    "    return torch.max(torch.tensor(0.0),torch.sum(torch.dot(tp,tpToBits(tp).type(torch.float32)))-1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpSupervisionRule(tp):\n",
    "    global decision1,decision2\n",
    "    global record_ans\n",
    "    global  dp,decision\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    money = dpPrecision\n",
    "    yes = 0\n",
    "    record_=record_ans\n",
    "    for i in range(n):\n",
    "        offerIndex = decision1[n - i, money,record_]\n",
    "        record_ = decision2[n - i, money,record_]\n",
    "        offer = float(offerIndex) / dpPrecision\n",
    "        if tp[i] > offer:\n",
    "            money -= offerIndex\n",
    "            yes += 1\n",
    "            bits[i] = 1\n",
    "            payments[i] = offer\n",
    "        else:\n",
    "            bits[i] = 0\n",
    "            payments[i] = 1\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "#     print()\n",
    "#     print(tp)\n",
    "#     print(bits)\n",
    "#     print(payments)\n",
    "#     print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def heuristicSupervisionRule(tp):\n",
    "    global  dp_H,decision_H\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    tempold=-1;\n",
    "    for turns in range(n,0,-1):\n",
    "        money = dpPrecision\n",
    "        j=0\n",
    "        tempo=sum(bits)\n",
    "        #print(\"bits\",tempo)\n",
    "        for i in range(n):\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            \n",
    "            offerIndex = decision_H[tempo ,tempo - i, money]\n",
    "            offer = float(offerIndex) / dpPrecision\n",
    "            while(j<n):\n",
    "                if(bits[j]!=0):\n",
    "                    break;\n",
    "                j+=1;\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            if tp[j] >= offer:\n",
    "                #print(money,j,tp[j],offer)\n",
    "                money -= offerIndex\n",
    "                bits[j] = 1\n",
    "                payments[j] = offer\n",
    "            else:\n",
    "                bits[j] = 0;\n",
    "                payments[j] = 1.0;\n",
    "            j+=1;\n",
    "        #print(\"money\",money)\n",
    "        if(money==0 and tempold==tempo):\n",
    "            break;\n",
    "        tempold=tempo;\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "\n",
    "    bits = torch.tensor(bits, dtype=torch.float32)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    # print()\n",
    "    # print(tp)\n",
    "    # print(bits)\n",
    "    # print(payments)\n",
    "    # print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "\n",
    "def costSharingSupervisionRule(tp):\n",
    "    tp = list(tp.numpy())\n",
    "    for k in range(n, -1, -1):\n",
    "        if k == 0:\n",
    "            break\n",
    "        bits = [1 if tp[ii] >= 1.0 / k else 0 for ii in range(n)]\n",
    "        if sum(bits) == k:\n",
    "            break\n",
    "    if k == 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1 for ii in range(n)]\n",
    "    else:\n",
    "        payments = [1.0 / k if bits[ii] == 1 else 1 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    return (bits, payments)\n",
    "\n",
    "    \n",
    "def costSharingWelfare(tp):\n",
    "    #print(tp,costSharingSupervisionRule(tp)[0])\n",
    "    return max(0.0,float(torch.dot(tp,torch.tensor(costSharingSupervisionRule(tp)[0],dtype=torch.float32)).item()-1.0))\n",
    "\n",
    "def dpWelfare(tp):\n",
    "    return max(0.0,float(torch.dot(tp,torch.tensor(dpSupervisionRule(tp)[0],dtype=torch.float32)).item()-1.0))\n",
    "\n",
    "def heuristicWelfare(tp):\n",
    "    return max(0.0,float(torch.dot(tp,torch.tensor(heuristicSupervisionRule(tp)[0],dtype=torch.float32)).item()-1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordAndReport(name, source, loss):\n",
    "    source.append(loss)\n",
    "    realLength = len(source)\n",
    "    #print(f\"{name} ({realLength}): {loss}\")\n",
    "    print(name,realLength,\":\" ,loss)\n",
    "\n",
    "def supervisionTrain(epoch, supervisionRule):\n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    \n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss = penalty * penaltyLambda /100000\n",
    "        \n",
    "        for tp in tp_batch:\n",
    "            bits, payments = supervisionRule(tp)\n",
    "            loss = loss + F.mse_loss(bitsToPayments(bits), payments)\n",
    "\n",
    "        loss = loss / len(tp_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "losslist=[];\n",
    "losslistname=[];\n",
    "losslisttemp=[];\n",
    "def test_batch():\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        lenLoss= 0\n",
    "        nnLoss = 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "            for tp in tp_batch:\n",
    "                nnLoss += tpToTotalWelfare(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        nnLoss/=lenLoss\n",
    "    return nnLoss\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    global record_ans\n",
    "    global losslisttemp; \n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        loss=0;\n",
    "        for tp in tp_batch:\n",
    "            for i in range(n):\n",
    "                tp1 = tp.clone()\n",
    "                tp1[i] = 1\n",
    "                tp0 = tp.clone()\n",
    "                tp0[i] = 0\n",
    "                offer = tpToPayments(tp1)[i]\n",
    "                Welfare1 = tpToTotalWelfare(tp1)\n",
    "                Welfare0 = tpToTotalWelfare(tp0)\n",
    "                if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                    loss = loss + (1 - cdf(offer,order)) * Welfare1 + cdf(offer,order) * Welfare0\n",
    "                else:\n",
    "                    loss = loss + (1 - cdf(offer,order,i)) * Welfare1 + cdf(offer,order,i) * Welfare0\n",
    "\n",
    "        loss = -loss / len(tp_batch) / n\n",
    "        \n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss += penalty * penaltyLambda\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            losstemp=test_batch();\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                ),\"testing loss:\",losstemp\n",
    "            )\n",
    "            losslisttemp.append(losstemp);\n",
    "            \n",
    "    print(\"penalty:\",penalty.item())\n",
    "    \n",
    "allBits = [torch.tensor(bits, dtype=torch.int16) for bits in itertools.product([0, 1], repeat=n)]\n",
    "\n",
    "def test():\n",
    "    global record_ans\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        costSharingLoss = 0\n",
    "        dpLoss = 0\n",
    "        nnLoss = 0\n",
    "        heuristicLoss=0\n",
    "        lenLoss= 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "\n",
    "            for tp in tp_batch:\n",
    "                costSharingLoss += costSharingWelfare(tp)\n",
    "                dpLoss += dpWelfare(tp)\n",
    "                nnLoss += tpToTotalWelfare(tp)\n",
    "                heuristicLoss+= heuristicWelfare(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        costSharingLoss /= lenLoss\n",
    "        dpLoss /= lenLoss\n",
    "        nnLoss /= lenLoss\n",
    "        heuristicLoss /= lenLoss\n",
    "        #print(lenLoss)\n",
    "        losslisttemp.append(nnLoss);\n",
    "        recordAndReport(\"NN\", runningLossNN, nnLoss)\n",
    "        recordAndReport(\"CS\", runningLossCS, costSharingLoss)\n",
    "        recordAndReport(\"DP\", runningLossDP, dpLoss)\n",
    "        recordAndReport(\"heuristic\", runningLossHeuristic, heuristicLoss)\n",
    "        print(\"DP:\",dp[n, dpPrecision,0])\n",
    "        #for i in range(n, 0, -1):\n",
    "        #    print(\"Heuristic:\",i,5*(1-dp_H[i, i, dpPrecision]))\n",
    "        for i in range(n, 0, -1):\n",
    "            print(\n",
    "                    tpToPayments(\n",
    "                            torch.tensor([0 if ii >= i else 1 for ii in range(n)], dtype=torch.float32)\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "dpPrecision = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def producedata(order):\n",
    "    global decision1,decision2\n",
    "    global record_ans\n",
    "    global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "    dpPrecision = 50\n",
    "    if(order==\"twopeak\"):\n",
    "        print(\"loc\",doublePeakLowMean, \"scale\",doublePeakStd)\n",
    "        print(\"loc\",doublePeakHighMean, \"scale\",doublePeakStd)\n",
    "        signals = np.random.randint(2, size=(trainSize, n))\n",
    "        samples1 = np.random.normal(\n",
    "            loc=doublePeakLowMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=doublePeakLowMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samples2 = np.random.normal(\n",
    "            loc=doublePeakHighMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "                    samples2[i, j] = np.random.normal(\n",
    "                        loc=doublePeakHighMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samplesJoint = signals * samples1 - (signals - 1) * samples2\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "        # tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "    elif(order==\"normal\"):\n",
    "        print(\"loc\",normalloc, \"scale\",normalscale)\n",
    "        samples1 = np.random.normal(\n",
    "            loc=normalloc, scale=normalscale, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=normalloc, scale=normalscale\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"uniform\"):  \n",
    "        print(\"uniformlow\",uniformlow, \"uniformhigh\",uniformhigh)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        uniformlow, uniformhigh\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"independent1\"):\n",
    "        print(\"loc\",independentnormalloc1,\"scale\",independentnormalscale1)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc1[j], independentnormalscale1[j]\n",
    "                    )\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc1[j], independentnormalscale1[j]\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"independent2\"):\n",
    "        print(\"loc\",independentnormalloc2, \"scale\",independentnormalscale2)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc2[j], independentnormalscale2[j]\n",
    "                    )\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc2[j], independentnormalscale2[j]\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"cauchy\"):\n",
    "        print(\"cauchyloc\",cauchyloc, \"cauchyscale\",cauchyscalen)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = d7.rsample(torch.Size([1]))\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = d7.rsample(torch.Size([1]))\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"beta\"):\n",
    "        print(\"beta_a\",beta_a, \"beta_b\",beta_b)\n",
    "        print(\"kumaraswamy_a\",kumaraswamy_a, \"kumaraswamy_b\",kumaraswamy_b)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = beta.rvs(beta_a,beta_b,  size = 1)\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = beta.rvs(beta_a,beta_b,  size = 1)\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"arcsine\"):\n",
    "        print(\"betalow\",0.5, \"betahigh\",0.5)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = beta.rvs(0.5,0.5,  size = 1)\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = beta.rvs(0.5,0.5,  size = 1)\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"U-exponential\"):\n",
    "        print(\"loc\",doublePeakLowMean, \"scale\",doublePeakStd)\n",
    "        print(\"loc\",doublePeakHighMean, \"scale\",doublePeakStd)\n",
    "        signals = np.random.randint(2, size=(trainSize, n))\n",
    "        samples1 = d81.rsample(torch.Size([trainSize, n])).numpy()\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = d81.rsample(torch.Size([1])).numpy()\n",
    "                    \n",
    "        samples2 = d82.rsample(torch.Size([trainSize, n])).numpy()\n",
    "        \n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "                    samples2[i, j] = d82.rsample(torch.Size([1])).numpy()\n",
    "        samples2 = 1.0 - samples2\n",
    "        samplesJoint = signals * samples1 - (signals - 1.0) * samples2\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        \n",
    "    plt.hist(samplesJoint,bins=500)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    pdfPrecision=1000\n",
    "    pdfnumber=[0 for i in range(pdfPrecision+1)];\n",
    "    cdfnumber=[0 for i in range(pdfPrecision+1)];\n",
    "    utilitynumber=[0 for i in range(pdfPrecision+1)];\n",
    "    Possible_utility=[0 for i in range(pdfPrecision+1)];\n",
    "    for i in range(int(trainSize * percentage_train_test)):\n",
    "        for j in range(n):\n",
    "            pdfnumber[int(samplesJoint[i,j]*pdfPrecision)]+=1.0/int(trainSize * percentage_train_test*n)\n",
    "    cdfnumber[0]=pdfnumber[0];\n",
    "    for i in range(1,pdfPrecision+1):\n",
    "        cdfnumber[i]=cdfnumber[i-1]+pdfnumber[i]\n",
    "    #print(cdfnumber)  \n",
    "    for i in range(1,pdfPrecision+1):\n",
    "        cdfnumber[i]=cdfnumber[i-1]+pdfnumber[i]   \n",
    "    for i in range(0,pdfPrecision+1):\n",
    "        utilitynumber[i]=0\n",
    "        for j in range(i,pdfPrecision+1):\n",
    "            utilitynumber[i]+=pdfnumber[j]*float(j-i)/pdfPrecision\n",
    "        if(sum(pdfnumber[i:])!=0):\n",
    "            utilitynumber[i]/=sum(pdfnumber[i:])\n",
    "    \n",
    "    plt.plot(pdfnumber)\n",
    "    plt.show()\n",
    "    print(sum(pdfnumber))\n",
    "\n",
    "    plt.plot(utilitynumber)\n",
    "    plt.show()\n",
    "    \n",
    "    tp_dataset = TensorDataset(tp_tensor[: int(trainSize * percentage_train_test)])\n",
    "    tp_dataset_testing = TensorDataset(tp_tensor[int(trainSize * (1.0-percentage_train_test)) :])\n",
    "    tp_dataloader = DataLoader(tp_dataset, batch_size=128, shuffle=True)\n",
    "    tp_dataloader_testing = DataLoader(tp_dataset_testing, batch_size=256, shuffle=False)\n",
    "    \n",
    "\n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp        = np.zeros([n + 1, dpPrecision + 1, dpPrecision*n + 1])\n",
    "    decision1 = np.zeros([n + 1, dpPrecision + 1, dpPrecision*n + 1], dtype=np.uint8)\n",
    "    decision2 = np.zeros([n + 1, dpPrecision + 1, dpPrecision*n + 1], dtype=np.uint8)\n",
    "    for yes in range(dpPrecision*n + 1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "                offer = float(money) / dpPrecision                                                                     \n",
    "                dp[1, money, yes] =(1.0 - cdf(offer,order).item()) * (yes/dpPrecision + utilitynumber[round(offer*pdfPrecision)])\n",
    "                decision1[1, money, yes] = money\n",
    "                decision2[1, money, yes] = int(yes + utilitynumber[round(offer*pdfPrecision)]*dpPrecision)\n",
    "    for ppl in range(2,  n + 1):\n",
    "        for yes in range(dpPrecision*n + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                maxSoFar = -100000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                        yes_old = int(yes+round(utilitynumber[round(offer*pdfPrecision)]*dpPrecision))\n",
    "                        \n",
    "                        res = (1 - cdf(offer,order)) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes_old, dpPrecision*n)\n",
    "                        ] + cdf(offer,order) * (dp[ppl - 1, money, yes])\n",
    "                    else:\n",
    "                        yes_old = int(yes+round(utilitynumber[round(offer*pdfPrecision)]*dpPrecision))\n",
    "                        res = (1 - cdf(offer,order,n-ppl).item()) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes_old, dpPrecision*n)\n",
    "                        ] + cdf(offer,order,n-ppl).item() * (dp[ppl - 1, money, yes])\n",
    "                    if maxSoFar < res:\n",
    "                        maxSoFar = res\n",
    "                        decision1[ppl, money, yes] = offerIndex\n",
    "                        decision2[ppl, money, yes] = yes_old\n",
    "                dp[ppl, money, yes] = maxSoFar\n",
    "    \n",
    "    print(\"dp\",dp[n, dpPrecision, 0])\n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp_H = np.zeros([n + 1 , n + 1, dpPrecision + 1])\n",
    "    decision_H = np.zeros([n + 1 , n + 1, dpPrecision + 1], dtype=np.uint8)\n",
    "    # ppl = 0 left\n",
    "    for i in range(1,n+1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            if money == 0:\n",
    "                dp_H[i, 0, 0] = 1\n",
    "            else:\n",
    "                offer = money / dpPrecision\n",
    "                dp_H[i, 0, money] = 0#cdf(offer)# + 1.0\n",
    "    for i in range(1,n+1):\n",
    "        for ppl in range(1, i + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                maxSoFar = -1000000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                        res = (1-cdf(offer,order)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    else:\n",
    "                        res = (1-cdf(offer,order,ppl-1)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    if maxSoFar < res.item():\n",
    "                        maxSoFar = res.item()\n",
    "                        decision_H[i, ppl, money] = offerIndex\n",
    "                dp_H[i, ppl, money] = maxSoFar\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc 0.1 scale 0.1\n",
      "loc 0.9 scale 0.1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp 1.4329012632369995\n",
      "Supervised Aim: U-exponential dp\n",
      "Sequential(\n",
      "  (0): Linear(in_features=5, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=100, out_features=5, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: 0.034643\n",
      "Train Epoch: 1 [2560/15000 (17%)]\tLoss: 0.016963\n",
      "Train Epoch: 1 [5120/15000 (34%)]\tLoss: 0.010705\n",
      "Train Epoch: 1 [7680/15000 (51%)]\tLoss: 0.006899\n",
      "Train Epoch: 1 [10240/15000 (68%)]\tLoss: 0.002413\n",
      "Train Epoch: 1 [12800/15000 (85%)]\tLoss: 0.001055\n",
      "Train Epoch: 2 [0/15000 (0%)]\tLoss: 0.000488\n",
      "Train Epoch: 2 [2560/15000 (17%)]\tLoss: 0.000262\n",
      "Train Epoch: 2 [5120/15000 (34%)]\tLoss: 0.000215\n",
      "Train Epoch: 2 [7680/15000 (51%)]\tLoss: 0.000121\n",
      "Train Epoch: 2 [10240/15000 (68%)]\tLoss: 0.000081\n",
      "Train Epoch: 2 [12800/15000 (85%)]\tLoss: 0.000075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:113: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN 1 : tensor(1.4314)\n",
      "CS 1 : 1.394951947569847\n",
      "DP 1 : 1.4323462651650112\n",
      "heuristic 1 : 1.0803951160033545\n",
      "DP: 1.4329012632369995\n",
      "tensor([3.5661e-01, 6.1696e-01, 2.4263e-02, 2.0688e-03, 1.0289e-04])\n",
      "tensor([0.3574, 0.6073, 0.0325, 0.0027, 1.0000])\n",
      "tensor([0.3610, 0.5914, 0.0476, 1.0000, 1.0000])\n",
      "tensor([0.3779, 0.6221, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: 43.466492 testing loss: tensor(1.4326)\n",
      "Train Epoch: 1 [2560/15000 (17%)]\tLoss: -0.506228 testing loss: tensor(1.0009)\n",
      "Train Epoch: 1 [5120/15000 (34%)]\tLoss: -0.896922 testing loss: tensor(0.9174)\n",
      "Train Epoch: 1 [7680/15000 (51%)]\tLoss: -1.054605 testing loss: tensor(0.9132)\n",
      "Train Epoch: 1 [10240/15000 (68%)]\tLoss: -0.902926 testing loss: tensor(0.9191)\n",
      "Train Epoch: 1 [12800/15000 (85%)]\tLoss: -0.861982 testing loss: tensor(0.9222)\n",
      "penalty: 0.005674812011420727\n",
      "NN 2 : tensor(0.9310)\n",
      "CS 2 : 1.394951947569847\n",
      "DP 2 : 1.4323462651650112\n",
      "heuristic 2 : 1.0803951160033545\n",
      "DP: 1.4329012632369995\n",
      "tensor([8.0932e-01, 1.8973e-01, 9.4373e-04, 2.1993e-06, 1.3289e-07])\n",
      "tensor([8.0916e-01, 1.8973e-01, 1.0996e-03, 3.4554e-06, 1.0000e+00])\n",
      "tensor([0.8075, 0.1912, 0.0013, 1.0000, 1.0000])\n",
      "tensor([0.8071, 0.1929, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/15000 (0%)]\tLoss: -0.959760 testing loss: tensor(0.9306)\n",
      "Train Epoch: 2 [2560/15000 (17%)]\tLoss: -0.950208 testing loss: tensor(0.9397)\n",
      "Train Epoch: 2 [5120/15000 (34%)]\tLoss: -1.015034 testing loss: tensor(0.9450)\n",
      "Train Epoch: 2 [7680/15000 (51%)]\tLoss: -0.983328 testing loss: tensor(0.9491)\n",
      "Train Epoch: 2 [10240/15000 (68%)]\tLoss: -1.009181 testing loss: tensor(0.9528)\n",
      "Train Epoch: 2 [12800/15000 (85%)]\tLoss: -0.837606 testing loss: tensor(0.9554)\n",
      "penalty: 0.004423721693456173\n",
      "NN 3 : tensor(0.9607)\n",
      "CS 3 : 1.394951947569847\n",
      "DP 3 : 1.4323462651650112\n",
      "heuristic 3 : 1.0803951160033545\n",
      "DP: 1.4329012632369995\n",
      "tensor([8.5279e-01, 1.4589e-01, 1.3195e-03, 2.1452e-06, 1.3657e-07])\n",
      "tensor([8.5314e-01, 1.4539e-01, 1.4670e-03, 3.0986e-06, 1.0000e+00])\n",
      "tensor([0.8538, 0.1445, 0.0017, 1.0000, 1.0000])\n",
      "tensor([0.8553, 0.1447, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: U-exponential random initializing\n",
      "Sequential(\n",
      "  (0): Linear(in_features=5, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=100, out_features=5, bias=True)\n",
      ")\n",
      "do nothing\n",
      "do nothing\n",
      "NN 1 : tensor(1.3962)\n",
      "CS 1 : 1.394951947569847\n",
      "DP 1 : 1.4323462651650112\n",
      "heuristic 1 : 1.0803951160033545\n",
      "DP: 1.4329012632369995\n",
      "tensor([0.1723, 0.1785, 0.2812, 0.1728, 0.1952])\n",
      "tensor([0.2187, 0.2235, 0.3277, 0.2301, 1.0000])\n",
      "tensor([0.2837, 0.2785, 0.4377, 1.0000, 1.0000])\n",
      "tensor([0.5206, 0.4794, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: -1.456879 testing loss: tensor(1.3971)\n",
      "Train Epoch: 1 [2560/15000 (17%)]\tLoss: -1.413877 testing loss: tensor(1.4067)\n",
      "Train Epoch: 1 [5120/15000 (34%)]\tLoss: -1.528588 testing loss: tensor(1.4110)\n",
      "Train Epoch: 1 [7680/15000 (51%)]\tLoss: -1.503046 testing loss: tensor(1.4118)\n",
      "Train Epoch: 1 [10240/15000 (68%)]\tLoss: -1.361500 testing loss: tensor(1.3905)\n",
      "Train Epoch: 1 [12800/15000 (85%)]\tLoss: -1.385166 testing loss: tensor(1.3338)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.3082)\n",
      "CS 2 : 1.394951947569847\n",
      "DP 2 : 1.4323462651650112\n",
      "heuristic 2 : 1.0803951160033545\n",
      "DP: 1.4329012632369995\n",
      "tensor([0.0136, 0.0157, 0.9151, 0.0213, 0.0344])\n",
      "tensor([0.0191, 0.0244, 0.9251, 0.0313, 1.0000])\n",
      "tensor([0.0241, 0.0300, 0.9459, 1.0000, 1.0000])\n",
      "tensor([0.3709, 0.6291, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/15000 (0%)]\tLoss: -1.507419 testing loss: tensor(1.3076)\n",
      "Train Epoch: 2 [2560/15000 (17%)]\tLoss: -1.387157 testing loss: tensor(1.3037)\n",
      "Train Epoch: 2 [5120/15000 (34%)]\tLoss: -1.431519 testing loss: tensor(1.2978)\n",
      "Train Epoch: 2 [7680/15000 (51%)]\tLoss: -1.400892 testing loss: tensor(1.3100)\n",
      "Train Epoch: 2 [10240/15000 (68%)]\tLoss: -1.443267 testing loss: tensor(1.3217)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "        \n",
    "def init_weights_xavier_uniform(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "        \n",
    "def init_weights_xavier_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "        \n",
    "        \n",
    "def init_weights_kaiming_uniform(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "        \n",
    "        \n",
    "def init_weights_kaiming_normal_(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "\n",
    "\n",
    "        \n",
    "for order in stage:\n",
    "    producedata(order)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "    #running\n",
    "    for order1 in order1name:\n",
    "        print(\"Supervised Aim:\",order,order1)\n",
    "        \n",
    "        # Instantiate the model with hyperparameters\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(n, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, n),\n",
    "        )\n",
    "        model.apply(init_weights)\n",
    "        # optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr1)\n",
    "        print(model)\n",
    "        \n",
    "        runningLossNN = []\n",
    "        runningLossCS = []\n",
    "        runningLossDP = []\n",
    "        runningLossHeuristic = []\n",
    "        #model=torch.load(\"save/pytorchNN=5dp1\");\n",
    "        #model.eval()\n",
    "        ##order1name=[\"costsharing\",\"dp\",\"heuristic\",\"random initializing\"]\n",
    "        for epoch in range(1, supervisionEpochs + 1):\n",
    "#             print(\"distributionRatio\",distributionRatio)\n",
    "            if(order1==\"costsharing\"):\n",
    "                supervisionTrain(epoch, costSharingSupervisionRule)\n",
    "            elif(order1==\"dp\"):\n",
    "                supervisionTrain(epoch, dpSupervisionRule)\n",
    "            elif(order1==\"heuristic\"):\n",
    "                supervisionTrain(epoch, heuristicSupervisionRule)\n",
    "            elif(order1==\"random initializing\"):\n",
    "                print(\"do nothing\");\n",
    "\n",
    "        test()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr2)\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train(epoch)\n",
    "            test()\n",
    "        losslistname.append(order+\" \"+order1);\n",
    "        losslist.append(losslisttemp);\n",
    "        losslisttemp=[];\n",
    "        savepath=\"save/pytorchNN=5all-beta\"+order+str(order1)\n",
    "        torch.save(model, savepath);\n",
    "        print(\"end\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colorlist=[\"#D2691E\",'#4169E1',\"#9ACD32\",\"#B22222\",\"#FF00FF\",\"#708090\"]\n",
    "for i in range(len(losslist)):\n",
    "    plt.plot(losslist[i], 'ro-', color=colorlist[i], alpha=0.8, label=losslistname[i])\n",
    "\n",
    "# 显示标签，如果不加这句，即使加了label='一些数字'的参数，最终还是不会显示标签\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('trianing times')\n",
    "plt.ylabel('Welfare')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
