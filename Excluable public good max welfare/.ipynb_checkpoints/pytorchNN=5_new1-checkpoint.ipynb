{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "global n\n",
    "n = 5\n",
    "epochs = 1\n",
    "supervisionEpochs = 1\n",
    "lr1 = 0.01\n",
    "lr2 = 0.00005\n",
    "log_interval = 5\n",
    "trainSize = 40000#100000\n",
    "percentage_train_test= 0.5\n",
    "penaltyLambda = 10\n",
    "dpPrecision=50\n",
    "pdfPrecision=100\n",
    "init_weights=\"xavier_normal\"#\"kaiming_uniform\"\"kaiming_normal\"\"xavier_uniform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pylab import *\n",
    "from scipy.stats import beta\n",
    "import math\n",
    "from localfiles import mydistribution\n",
    "global samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "global decision_offer,decision_welfare,record_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage=[\"twopeak\"]\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"beta\",\"U-exponential\",\"arcsine\"\n",
    "order1name=[\"dp\",\"random initializing\",\"costsharing\",\"heuristic\"]\n",
    "#order1name=[\"random initializing1\",\"random initializing2\",\"random initializing3\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'localfiles.mydistribution' from 'D:\\\\coding\\\\jupyter workplace\\\\Mechanism Design\\\\Public Good\\\\Excluable public good max welfare\\\\localfiles\\\\mydistribution.py'>\n",
      "0.3540388371733616\n"
     ]
    }
   ],
   "source": [
    "print(mydistribution)\n",
    "mydistribution.inital(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global record_ans\n",
    "record_ans=0\n",
    "def recordAndReport(name, source, loss):\n",
    "    source.append(loss)\n",
    "    realLength = len(source)\n",
    "    #print(f\"{name} ({realLength}): {loss}\")\n",
    "    print(name,realLength,\":\" ,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    if torch.sum(bits).item() == 0:\n",
    "        return torch.ones(n)\n",
    "    bits     = bits.type(torch.float32)\n",
    "    negBits  = torch.ones(n) - bits\n",
    "    payments = model(bits)\n",
    "    payments = payments - 1000 * negBits\n",
    "    payments = torch.softmax(payments, 0)\n",
    "    payments = payments + negBits\n",
    "    return payments\n",
    "\n",
    "def tpToBits(tp, bits=torch.ones(n).type(torch.uint8)):\n",
    "    payments = bitsToPayments(bits)\n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return tpToBits(tp, newBits)#bits-bits#tpToBits(tp, newBits)\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp))\n",
    "\n",
    "\n",
    "def tpToTotalWelfare(tp):\n",
    "    return torch.max(torch.tensor(0.0),torch.dot(tp,tpToBits(tp).type(torch.float32))-1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpSupervisionRule(tp):\n",
    "    global decision_offer,decision_welfare\n",
    "    global record_ans\n",
    "    global  dp,decision\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    money = dpPrecision\n",
    "    record_=0\n",
    "    for i in range(n):\n",
    "        offerIndex = decision_offer[n - i, money,record_]\n",
    "        offer = float(offerIndex) / dpPrecision\n",
    "        if tp[i] > offer:\n",
    "            money -= offerIndex\n",
    "            bits[i] = 1\n",
    "            record_ = decision_welfare[n - i, money, record_]\n",
    "            payments[i] = offer\n",
    "        else:\n",
    "            bits[i] = 0\n",
    "            payments[i] = 1\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "#     print()\n",
    "#     print(tp)\n",
    "#     print(bits)\n",
    "#     print(payments)\n",
    "#     print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def heuristicSupervisionRule(tp):\n",
    "    global  dp_H,decision_H\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    tempold=-1;\n",
    "    for turns in range(n,0,-1):\n",
    "        money = dpPrecision\n",
    "        j=0\n",
    "        tempo=sum(bits)\n",
    "        #print(\"bits\",tempo)\n",
    "        for i in range(n):\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            \n",
    "            offerIndex = decision_H[tempo ,tempo - i, money]\n",
    "            offer = float(offerIndex) / dpPrecision\n",
    "            while(j<n):\n",
    "                if(bits[j]!=0):\n",
    "                    break;\n",
    "                j+=1;\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            if tp[j] >= offer:\n",
    "                #print(money,j,tp[j],offer)\n",
    "                money -= offerIndex\n",
    "                bits[j] = 1\n",
    "                payments[j] = offer\n",
    "            else:\n",
    "                bits[j] = 0;\n",
    "                payments[j] = 1.0;\n",
    "            j+=1;\n",
    "        #print(\"money\",money)\n",
    "        if(money==0 and tempold==tempo):\n",
    "            break;\n",
    "        tempold=tempo;\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "\n",
    "    bits = torch.tensor(bits, dtype=torch.float32)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    # print()\n",
    "    # print(tp)\n",
    "    # print(bits)\n",
    "    # print(payments)\n",
    "    # print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "\n",
    "def costSharingSupervisionRule(tp):\n",
    "    tp = list(tp.numpy())\n",
    "    for k in range(n, -1, -1):\n",
    "        if k == 0:\n",
    "            break\n",
    "        bits = [1 if tp[ii] >= 1.0 / k else 0 for ii in range(n)]\n",
    "        if sum(bits) == k:\n",
    "            break\n",
    "    if k == 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1 for ii in range(n)]\n",
    "    else:\n",
    "        payments = [1.0 / k if bits[ii] == 1 else 1 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    return (bits, payments)\n",
    "\n",
    "    \n",
    "def costSharingWelfare(tp):\n",
    "    #print(tp,costSharingSupervisionRule(tp)[0])\n",
    "    return max(0.0,float(torch.dot(tp,torch.tensor(costSharingSupervisionRule(tp)[0],dtype=torch.float32)).item()-1.0))\n",
    "\n",
    "def dpWelfare(tp):\n",
    "    return max(0.0,float(torch.dot(tp,torch.tensor(dpSupervisionRule(tp)[0],dtype=torch.float32)).item()-1.0))\n",
    "\n",
    "def heuristicWelfare(tp):\n",
    "    return max(0.0,float(torch.dot(tp,torch.tensor(heuristicSupervisionRule(tp)[0],dtype=torch.float32)).item()-1.0))\n",
    "\n",
    "def tpToTotalDelay(tp):\n",
    "    return n - torch.sum(tpToBits(tp).type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     12
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def supervisionTrain(epoch, supervisionRule):\n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    \n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss = penalty * penaltyLambda /100000\n",
    "        \n",
    "        for tp in tp_batch:\n",
    "            bits, payments = supervisionRule(tp)\n",
    "            loss += F.mse_loss(bitsToPayments(bits), payments)\n",
    "\n",
    "        loss = loss / len(tp_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % (log_interval*5) == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "losslist=[];\n",
    "losslistname=[];\n",
    "losslisttemp=[];\n",
    "def test_batch():\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        lenLoss= 0\n",
    "        nnLoss = 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "            for tp in tp_batch:\n",
    "                nnLoss += tpToTotalWelfare(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        nnLoss/=lenLoss\n",
    "    return nnLoss\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    global record_ans\n",
    "    global losslisttemp; \n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        loss=0;\n",
    "        for tp in tp_batch:\n",
    "            for i in range(n):\n",
    "                tp1 = tp.clone()\n",
    "                tp1[i] = 1\n",
    "                tp0 = tp.clone()\n",
    "                tp0[i] = 0\n",
    "                offer = tpToPayments(tp1)[i]\n",
    "                Welfare1 = tpToTotalWelfare(tp1)\n",
    "                Welfare0 = tpToTotalWelfare(tp0)\n",
    "                offerIndex=int(offer*dpPrecision)\n",
    "                if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                    losspart2= (utilitya[offerIndex]*offer+utilityb[offerIndex])*1\n",
    "                    loss -= (1 - mydistribution.cdf(offer,order)) * (Welfare1+losspart2-losspart2.item()) + mydistribution.cdf(offer,order) * Welfare0\n",
    "                else:\n",
    "                    loss -= (1 - mydistribution.cdf(offer,order,i)) * Welfare1 + mydistribution.cdf(offer,order,i) * Welfare0\n",
    "                    \n",
    "                Delay1 = tpToTotalDelay(tp1)\n",
    "                Delay0 = tpToTotalDelay(tp0)\n",
    "                if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                    loss += (1 - mydistribution.cdf(offer,order)) * Delay1 + mydistribution.cdf(offer,order) * Delay0\n",
    "                else:\n",
    "                    loss += (1 - mydistribution.cdf(offer,order,i)) * Delay1 + mydistribution.cdf(offer,order,i) * Delay0\n",
    "        loss = loss / len(tp_batch) / n\n",
    "        \n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss += penalty * penaltyLambda\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            losstemp=test_batch();\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                ),\"testing loss:\",losstemp\n",
    "            )\n",
    "            losslisttemp.append(losstemp);\n",
    "            \n",
    "    print(\"penalty:\",penalty.item())\n",
    "    \n",
    "allBits = [torch.tensor(bits, dtype=torch.int16) for bits in itertools.product([0, 1], repeat=n)]\n",
    "\n",
    "def test():\n",
    "    global record_ans\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        costSharingLoss = 0\n",
    "        dpLoss = 0\n",
    "        nnLoss = 0\n",
    "        heuristicLoss=0\n",
    "        lenLoss= 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "\n",
    "            for tp in tp_batch:\n",
    "                costSharingLoss += costSharingWelfare(tp)\n",
    "                dpLoss += dpWelfare(tp)\n",
    "                nnLoss += tpToTotalWelfare(tp)\n",
    "                heuristicLoss+= heuristicWelfare(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        costSharingLoss /= lenLoss\n",
    "        dpLoss /= lenLoss\n",
    "        nnLoss /= lenLoss\n",
    "        heuristicLoss /= lenLoss\n",
    "        #print(lenLoss)\n",
    "        losslisttemp.append(nnLoss);\n",
    "        recordAndReport(\"NN\", runningLossNN, nnLoss)\n",
    "        recordAndReport(\"CS\", runningLossCS, costSharingLoss)\n",
    "        recordAndReport(\"DP\", runningLossDP, dpLoss)\n",
    "        recordAndReport(\"heuristic\", runningLossHeuristic, heuristicLoss)\n",
    "        print(\"DP:\",dp[n, dpPrecision,0])\n",
    "        #for i in range(n, 0, -1):\n",
    "        #    print(\"Heuristic:\",i,5*(1-dp_H[i, i, dpPrecision]))\n",
    "        for i in range(n, 0, -1):\n",
    "            print(\n",
    "                    tpToPayments(\n",
    "                            torch.tensor([0 if ii >= i else 1 for ii in range(n)], dtype=torch.float32)\n",
    "                    )\n",
    "                )\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dp():\n",
    "    global decision_offer,decision_welfare,decision_H\n",
    "    global dp,dp_H,record_ans,utilitya,utilityb\n",
    "    pdfnumber=[0 for i in range(pdfPrecision+1)];\n",
    "    cdfnumber=[0 for i in range(pdfPrecision+1)];\n",
    "    utilitynumber=[0 for i in range(pdfPrecision+1)];\n",
    "    Possible_utility=[0 for i in range(pdfPrecision+1)];\n",
    "    utilitya=[0 for i in range(dpPrecision+1)];\n",
    "    utilityb=[0 for i in range(dpPrecision+1)];\n",
    "    for i in range(int(trainSize * percentage_train_test)):\n",
    "        for j in range(n):\n",
    "            pdfnumber[int(samplesJoint[i,j]*pdfPrecision)]+=1.0/int(trainSize * percentage_train_test*n)\n",
    "    cdfnumber[0]=pdfnumber[0];\n",
    "    for i in range(1,pdfPrecision+1):\n",
    "        cdfnumber[i]=cdfnumber[i-1]+pdfnumber[i]\n",
    "    #print(cdfnumber)  \n",
    "    for i in range(1,pdfPrecision+1):\n",
    "        cdfnumber[i]=cdfnumber[i-1]+pdfnumber[i]   \n",
    "    for i in range(0,pdfPrecision+1):\n",
    "        utilitynumber[i]=0\n",
    "        for j in range(i,pdfPrecision+1):\n",
    "            utilitynumber[i]+=pdfnumber[j]*float(j-i)/pdfPrecision\n",
    "        if(sum(pdfnumber[i:])!=0):\n",
    "            utilitynumber[i]/=sum(pdfnumber[i:])\n",
    "    for i in range(0,dpPrecision):\n",
    "        ii=int(float(i)/dpPrecision*pdfPrecision)\n",
    "        jj=int(float(i+1)/dpPrecision*pdfPrecision)\n",
    "        utilitya[i]=(utilitynumber[jj]-utilitynumber[ii])/dpPrecision\n",
    "        utilityb[i]=utilitynumber[ii]-utilitya[i]*float(i)/dpPrecision\n",
    "    plt.plot(pdfnumber)\n",
    "    plt.show()\n",
    "    print(sum(pdfnumber))\n",
    "\n",
    "    plt.plot(utilitynumber)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp        = np.zeros([n + 1, dpPrecision + 1, dpPrecision*n + 1])\n",
    "    decision_offer = np.zeros([n + 1, dpPrecision + 1, dpPrecision*n + 1], dtype=np.uint8)\n",
    "    decision_welfare = np.zeros([n + 1, dpPrecision + 1, dpPrecision*n + 1], dtype=np.uint8)\n",
    "    for yes in range(dpPrecision*n + 1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "                offer = float(money) / dpPrecision                                                                     \n",
    "                dp[1, money, yes] =(1.0 - mydistribution.cdf(offer,order).item()) * (yes/dpPrecision + utilitynumber[round(offer*pdfPrecision)])\n",
    "                decision_offer[1, money, yes] = money\n",
    "                decision_welfare[1, money, yes] = int(yes + utilitynumber[round(offer*pdfPrecision)]*dpPrecision)\n",
    "    for ppl in range(2,  n + 1):\n",
    "        for yes in range(dpPrecision*n + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                maxSoFar = -100000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                        yes_old = int(yes+round(utilitynumber[round(offer*pdfPrecision)]*dpPrecision))\n",
    "                        \n",
    "                        res = (1 - mydistribution.cdf(offer,order)) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes_old, dpPrecision*n)\n",
    "                        ] + mydistribution.cdf(offer,order) * (dp[ppl - 1, money, yes])\n",
    "                    else:\n",
    "                        yes_old = int(yes+round(utilitynumber[round(offer*pdfPrecision)]*dpPrecision))\n",
    "                        res = (1 - mydistribution.cdf(offer,order,n-ppl).item()) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes_old, dpPrecision*n)\n",
    "                        ] + mydistribution.cdf(offer,order,n-ppl).item() * (dp[ppl - 1, money, yes])\n",
    "                    if maxSoFar < res:\n",
    "                        maxSoFar = res\n",
    "                        decision_offer[ppl, money, yes] = offerIndex\n",
    "                        decision_welfare[ppl, money, yes] = yes_old\n",
    "                dp[ppl, money, yes] = maxSoFar\n",
    "    \n",
    "    print(\"dp\",dp[n, dpPrecision, 0])\n",
    "    \n",
    "    def verify_dp(temp,debug):\n",
    "        if(debug==1):\n",
    "            print(temp)\n",
    "        ans =0;\n",
    "        o_list=[];\n",
    "        remain_list=[];\n",
    "        remain=dpPrecision\n",
    "        record_= 0\n",
    "        for ppl in range(n,0,-1):\n",
    "            o=decision_offer[ppl, remain, record_]\n",
    "            \n",
    "            #print(\"record\",o,record_)\n",
    "            if(debug==1):\n",
    "                print(o,remain,record_)\n",
    "            o_list.append(o)\n",
    "            remain_list.append(remain);\n",
    "            if(o<temp[n-ppl]):\n",
    "                remain-=int(o);\n",
    "                record_=decision_welfare[ppl, remain, record_]\n",
    "                ans=1#+=float(temp[n-ppl]-o)/dpPrecision\n",
    "                #print(\"record\",record_)\n",
    "            elif (remain>0):\n",
    "                ans=0;\n",
    "        if(remain<=1):\n",
    "            return ans,o_list;\n",
    "        else:\n",
    "            return 0,o_list;\n",
    "    ans_list=[];\n",
    "    for i in range(5):\n",
    "        temp=samplesJoint[i]*dpPrecision\n",
    "        #print(temp)\n",
    "        tempres=verify_dp(temp,1)\n",
    "        ans_list.append(tempres[0]);\n",
    "        print(tempres)\n",
    "        #print(\"\\n\",temp)\n",
    "        #print(plan_dp(temp,1))\n",
    "\n",
    "    for i in range(10000):\n",
    "        temp=samplesJoint[i]*dpPrecision\n",
    "        #print(temp)\n",
    "        ans_list.append(verify_dp(temp,0)[0]);\n",
    "        #print(\"\\n\",temp)\n",
    "        #print(plan_dp(temp))\n",
    "    print(\"verify dp vaule:\",sum(ans_list)/len(ans_list))\n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp_H = np.zeros([n + 1 , n + 1, dpPrecision + 1])\n",
    "    decision_H = np.zeros([n + 1 , n + 1, dpPrecision + 1], dtype=np.uint8)\n",
    "    # ppl = 0 left\n",
    "    for i in range(1,n+1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            if money == 0:\n",
    "                dp_H[i, 0, 0] = 1\n",
    "            else:\n",
    "                offer = money / dpPrecision\n",
    "                dp_H[i, 0, money] = 0#mydistribution.cdf(offer)# + 1.0\n",
    "    for i in range(1,n+1):\n",
    "        for ppl in range(1, i + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                maxSoFar = -1000000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                        res = (1-mydistribution.cdf(offer,order)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    else:\n",
    "                        res = (1-mydistribution.cdf(offer,order,ppl-1)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    if maxSoFar < res.item():\n",
    "                        maxSoFar = res.item()\n",
    "                        decision_H[i, ppl, money] = offerIndex\n",
    "                dp_H[i, ppl, money] = maxSoFar\n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights_xavier_uniform(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        \n",
    "def init_weights_xavier_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        \n",
    "        \n",
    "def init_weights_kaiming_uniform(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        \n",
    "        \n",
    "def init_weights_kaiming_normal_(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc 0.2 scale 0.1\n",
      "loc 0.6 scale 0.1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999731\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp 0.7437459230422974\n",
      "[ 5.10087578 30.51766289  6.29124399 10.38652256 32.5299857 ]\n",
      "23 50 0\n",
      "23 50 0\n",
      "16 27 15\n",
      "23 27 15\n",
      "27 27 15\n",
      "(1, [23, 23, 16, 23, 27])\n",
      "[11.18053787  1.8698986  23.10686095 24.31454329 20.6693293 ]\n",
      "23 50 0\n",
      "23 50 0\n",
      "23 50 0\n",
      "23 27 14\n",
      "4 4 31\n",
      "(1, [23, 23, 23, 23, 4])\n",
      "[10.46328819 14.61377959 23.39887505 24.71639119  4.50669437]\n",
      "23 50 0\n",
      "23 50 0\n",
      "23 50 0\n",
      "23 27 14\n",
      "4 4 31\n",
      "(1, [23, 23, 23, 23, 4])\n",
      "[7.02919795e+00 4.70812929e+00 2.95116261e+01 2.03647857e-03\n",
      " 7.49458773e+00]\n",
      "23 50 0\n",
      "23 50 0\n",
      "23 50 0\n",
      "23 27 14\n",
      "27 27 14\n",
      "(0, [23, 23, 23, 23, 27])\n",
      "[11.03414755 10.59745786  1.02344133 34.8094017  31.0963652 ]\n",
      "23 50 0\n",
      "23 50 0\n",
      "23 50 0\n",
      "26 50 0\n",
      "24 24 11\n",
      "(1, [23, 23, 23, 26, 24])\n",
      "verify dp vaule: 0.7211394302848576\n",
      "Supervised Aim: twopeak dp\n",
      "Sequential(\n",
      "  (0): Linear(in_features=5, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=100, out_features=5, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.010840\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 0.000585\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 0.000071\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 0.000042\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.000008\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 0.000002\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN 1 : tensor(0.7407)\n",
      "CS 1 : 0.7788871702194213\n",
      "DP 1 : 0.7277208984434604\n",
      "heuristic 1 : 0.7266990943431855\n",
      "DP: 0.7437459230422974\n",
      "tensor([0.4592, 0.1793, 0.1797, 0.1595, 0.0223])\n",
      "tensor([0.4738, 0.1871, 0.1753, 0.1639, 1.0000])\n",
      "tensor([0.5565, 0.2380, 0.2055, 1.0000, 1.0000])\n",
      "tensor([0.7045, 0.2955, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 1.936977 testing loss: tensor(0.7429)\n",
      "Train Epoch: 1 [640/20000 (3%)]\tLoss: 1.403876 testing loss: tensor(0.7450)\n",
      "Train Epoch: 1 [1280/20000 (6%)]\tLoss: 0.891984 testing loss: tensor(0.7447)\n",
      "Train Epoch: 1 [1920/20000 (10%)]\tLoss: 0.783974 testing loss: tensor(0.7435)\n",
      "Train Epoch: 1 [2560/20000 (13%)]\tLoss: 1.187776 testing loss: tensor(0.7431)\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 0.898711 testing loss: tensor(0.7431)\n",
      "Train Epoch: 1 [3840/20000 (19%)]\tLoss: 1.005100 testing loss: tensor(0.7427)\n",
      "Train Epoch: 1 [4480/20000 (22%)]\tLoss: 1.313022 testing loss: tensor(0.7426)\n",
      "Train Epoch: 1 [5120/20000 (25%)]\tLoss: 1.238571 testing loss: tensor(0.7428)\n",
      "Train Epoch: 1 [5760/20000 (29%)]\tLoss: 0.934023 testing loss: tensor(0.7430)\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 1.089015 testing loss: tensor(0.7430)\n",
      "Train Epoch: 1 [7040/20000 (35%)]\tLoss: 0.995353 testing loss: tensor(0.7433)\n",
      "Train Epoch: 1 [7680/20000 (38%)]\tLoss: 0.932339 testing loss: tensor(0.7438)\n",
      "Train Epoch: 1 [8320/20000 (41%)]\tLoss: 0.881154 testing loss: tensor(0.7442)\n",
      "Train Epoch: 1 [8960/20000 (45%)]\tLoss: 0.874118 testing loss: tensor(0.7445)\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 1.231704 testing loss: tensor(0.7448)\n",
      "Train Epoch: 1 [10240/20000 (51%)]\tLoss: 1.163140 testing loss: tensor(0.7453)\n",
      "Train Epoch: 1 [10880/20000 (54%)]\tLoss: 0.905994 testing loss: tensor(0.7453)\n",
      "Train Epoch: 1 [11520/20000 (57%)]\tLoss: 1.024514 testing loss: tensor(0.7457)\n",
      "Train Epoch: 1 [12160/20000 (61%)]\tLoss: 1.243710 testing loss: tensor(0.7462)\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.909699 testing loss: tensor(0.7464)\n",
      "Train Epoch: 1 [13440/20000 (67%)]\tLoss: 1.228028 testing loss: tensor(0.7472)\n",
      "Train Epoch: 1 [14080/20000 (70%)]\tLoss: 1.013591 testing loss: tensor(0.7482)\n",
      "Train Epoch: 1 [14720/20000 (73%)]\tLoss: 1.016475 testing loss: tensor(0.7492)\n",
      "Train Epoch: 1 [15360/20000 (76%)]\tLoss: 0.905532 testing loss: tensor(0.7501)\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 1.254513 testing loss: tensor(0.7506)\n",
      "Train Epoch: 1 [16640/20000 (83%)]\tLoss: 1.168351 testing loss: tensor(0.7511)\n",
      "Train Epoch: 1 [17280/20000 (86%)]\tLoss: 1.334106 testing loss: tensor(0.7512)\n",
      "Train Epoch: 1 [17920/20000 (89%)]\tLoss: 0.940743 testing loss: tensor(0.7514)\n",
      "Train Epoch: 1 [18560/20000 (92%)]\tLoss: 0.884142 testing loss: tensor(0.7515)\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 0.970884 testing loss: tensor(0.7514)\n",
      "Train Epoch: 1 [19840/20000 (99%)]\tLoss: 1.206937 testing loss: tensor(0.7513)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(0.7513)\n",
      "CS 2 : 0.7788871702194213\n",
      "DP 2 : 0.7277208984434604\n",
      "heuristic 2 : 0.7266990943431855\n",
      "DP: 0.7437459230422974\n",
      "tensor([0.4387, 0.1840, 0.1792, 0.1639, 0.0342])\n",
      "tensor([0.4487, 0.1878, 0.1913, 0.1722, 1.0000])\n",
      "tensor([0.4892, 0.2636, 0.2472, 1.0000, 1.0000])\n",
      "tensor([0.6342, 0.3658, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: twopeak random initializing\n",
      "Sequential(\n",
      "  (0): Linear(in_features=5, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=100, out_features=5, bias=True)\n",
      ")\n",
      "do nothing\n",
      "NN 1 : tensor(0.7647)\n",
      "CS 1 : 0.7788871702194213\n",
      "DP 1 : 0.7277208984434604\n",
      "heuristic 1 : 0.7266990943431855\n",
      "DP: 0.7437459230422974\n",
      "tensor([0.1429, 0.1396, 0.3100, 0.1775, 0.2301])\n",
      "tensor([0.1687, 0.1939, 0.3889, 0.2485, 1.0000])\n",
      "tensor([0.2237, 0.2943, 0.4821, 1.0000, 1.0000])\n",
      "tensor([0.4614, 0.5386, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.965844 testing loss: tensor(0.7664)\n",
      "Train Epoch: 1 [640/20000 (3%)]\tLoss: 1.000420 testing loss: tensor(0.7514)\n",
      "Train Epoch: 1 [1280/20000 (6%)]\tLoss: 1.030448 testing loss: tensor(0.7664)\n",
      "Train Epoch: 1 [1920/20000 (10%)]\tLoss: 1.170652 testing loss: tensor(0.7675)\n",
      "Train Epoch: 1 [2560/20000 (13%)]\tLoss: 1.133026 testing loss: tensor(0.7643)\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 0.714216 testing loss: tensor(0.7664)\n",
      "Train Epoch: 1 [3840/20000 (19%)]\tLoss: 1.084869 testing loss: tensor(0.7661)\n",
      "Train Epoch: 1 [4480/20000 (22%)]\tLoss: 0.992080 testing loss: tensor(0.7654)\n",
      "Train Epoch: 1 [5120/20000 (25%)]\tLoss: 0.947729 testing loss: tensor(0.7672)\n",
      "Train Epoch: 1 [5760/20000 (29%)]\tLoss: 1.196385 testing loss: tensor(0.7685)\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 1.015332 testing loss: tensor(0.7679)\n",
      "Train Epoch: 1 [7040/20000 (35%)]\tLoss: 0.886492 testing loss: tensor(0.7667)\n",
      "Train Epoch: 1 [7680/20000 (38%)]\tLoss: 1.125062 testing loss: tensor(0.7665)\n",
      "Train Epoch: 1 [8320/20000 (41%)]\tLoss: 1.041637 testing loss: tensor(0.7659)\n",
      "Train Epoch: 1 [8960/20000 (45%)]\tLoss: 0.639668 testing loss: tensor(0.7649)\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 1.121881 testing loss: tensor(0.7669)\n",
      "Train Epoch: 1 [10240/20000 (51%)]\tLoss: 0.999540 testing loss: tensor(0.7657)\n",
      "Train Epoch: 1 [10880/20000 (54%)]\tLoss: 0.966761 testing loss: tensor(0.7667)\n",
      "Train Epoch: 1 [11520/20000 (57%)]\tLoss: 0.879532 testing loss: tensor(0.7653)\n",
      "Train Epoch: 1 [12160/20000 (61%)]\tLoss: 0.972118 testing loss: tensor(0.7662)\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.561466 testing loss: tensor(0.7665)\n",
      "Train Epoch: 1 [13440/20000 (67%)]\tLoss: 0.777557 testing loss: tensor(0.7644)\n",
      "Train Epoch: 1 [14080/20000 (70%)]\tLoss: 1.113204 testing loss: tensor(0.7644)\n",
      "Train Epoch: 1 [14720/20000 (73%)]\tLoss: 1.113327 testing loss: tensor(0.7641)\n",
      "Train Epoch: 1 [15360/20000 (76%)]\tLoss: 1.061955 testing loss: tensor(0.7630)\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 1.126526 testing loss: tensor(0.7629)\n",
      "Train Epoch: 1 [16640/20000 (83%)]\tLoss: 1.119496 testing loss: tensor(0.7634)\n",
      "Train Epoch: 1 [17280/20000 (86%)]\tLoss: 1.090834 testing loss: tensor(0.7647)\n",
      "Train Epoch: 1 [17920/20000 (89%)]\tLoss: 0.914953 testing loss: tensor(0.7652)\n",
      "Train Epoch: 1 [18560/20000 (92%)]\tLoss: 0.707822 testing loss: tensor(0.7655)\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 1.036099 testing loss: tensor(0.7655)\n",
      "Train Epoch: 1 [19840/20000 (99%)]\tLoss: 0.929561 testing loss: tensor(0.7666)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(0.7664)\n",
      "CS 2 : 0.7788871702194213\n",
      "DP 2 : 0.7277208984434604\n",
      "heuristic 2 : 0.7266990943431855\n",
      "DP: 0.7437459230422974\n",
      "tensor([0.1488, 0.1302, 0.4245, 0.1269, 0.1696])\n",
      "tensor([0.1794, 0.1629, 0.4747, 0.1830, 1.0000])\n",
      "tensor([0.2289, 0.2622, 0.5089, 1.0000, 1.0000])\n",
      "tensor([0.5018, 0.4982, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: twopeak costsharing\n",
      "Sequential(\n",
      "  (0): Linear(in_features=5, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=100, out_features=5, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.000722\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 0.000012\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 0.000002\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 0.000000\n",
      "NN 1 : tensor(0.7788)\n",
      "CS 1 : 0.7788871702194213\n",
      "DP 1 : 0.7277208984434604\n",
      "heuristic 1 : 0.7266990943431855\n",
      "DP: 0.7437459230422974\n",
      "tensor([0.1997, 0.2000, 0.2001, 0.2000, 0.2001])\n",
      "tensor([0.2504, 0.2500, 0.2497, 0.2499, 1.0000])\n",
      "tensor([0.3332, 0.3333, 0.3335, 1.0000, 1.0000])\n",
      "tensor([0.4997, 0.5003, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.910552 testing loss: tensor(0.7793)\n",
      "Train Epoch: 1 [640/20000 (3%)]\tLoss: 1.080669 testing loss: tensor(0.7794)\n",
      "Train Epoch: 1 [1280/20000 (6%)]\tLoss: 1.155821 testing loss: tensor(0.7790)\n",
      "Train Epoch: 1 [1920/20000 (10%)]\tLoss: 1.448528 testing loss: tensor(0.7788)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [2560/20000 (13%)]\tLoss: 0.991797 testing loss: tensor(0.7791)\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 1.196563 testing loss: tensor(0.7791)\n",
      "Train Epoch: 1 [3840/20000 (19%)]\tLoss: 1.078395 testing loss: tensor(0.7791)\n",
      "Train Epoch: 1 [4480/20000 (22%)]\tLoss: 1.090649 testing loss: tensor(0.7793)\n",
      "Train Epoch: 1 [5120/20000 (25%)]\tLoss: 1.041075 testing loss: tensor(0.7791)\n",
      "Train Epoch: 1 [5760/20000 (29%)]\tLoss: 0.977376 testing loss: tensor(0.7793)\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 1.165673 testing loss: tensor(0.7790)\n",
      "Train Epoch: 1 [7040/20000 (35%)]\tLoss: 1.044002 testing loss: tensor(0.7790)\n",
      "Train Epoch: 1 [7680/20000 (38%)]\tLoss: 0.986852 testing loss: tensor(0.7792)\n",
      "Train Epoch: 1 [8320/20000 (41%)]\tLoss: 0.853566 testing loss: tensor(0.7789)\n",
      "Train Epoch: 1 [8960/20000 (45%)]\tLoss: 1.032821 testing loss: tensor(0.7788)\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 1.150821 testing loss: tensor(0.7787)\n",
      "Train Epoch: 1 [10240/20000 (51%)]\tLoss: 0.997376 testing loss: tensor(0.7786)\n",
      "Train Epoch: 1 [10880/20000 (54%)]\tLoss: 0.717571 testing loss: tensor(0.7787)\n",
      "Train Epoch: 1 [11520/20000 (57%)]\tLoss: 1.150477 testing loss: tensor(0.7787)\n",
      "Train Epoch: 1 [12160/20000 (61%)]\tLoss: 0.858486 testing loss: tensor(0.7787)\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.841764 testing loss: tensor(0.7784)\n",
      "Train Epoch: 1 [13440/20000 (67%)]\tLoss: 1.334929 testing loss: tensor(0.7788)\n",
      "Train Epoch: 1 [14080/20000 (70%)]\tLoss: 1.131909 testing loss: tensor(0.7788)\n",
      "Train Epoch: 1 [14720/20000 (73%)]\tLoss: 1.046979 testing loss: tensor(0.7787)\n",
      "Train Epoch: 1 [15360/20000 (76%)]\tLoss: 1.167410 testing loss: tensor(0.7787)\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 1.031652 testing loss: tensor(0.7790)\n",
      "Train Epoch: 1 [16640/20000 (83%)]\tLoss: 1.057261 testing loss: tensor(0.7788)\n",
      "Train Epoch: 1 [17280/20000 (86%)]\tLoss: 0.953946 testing loss: tensor(0.7789)\n",
      "Train Epoch: 1 [17920/20000 (89%)]\tLoss: 0.928020 testing loss: tensor(0.7788)\n",
      "Train Epoch: 1 [18560/20000 (92%)]\tLoss: 1.074685 testing loss: tensor(0.7791)\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 0.703890 testing loss: tensor(0.7790)\n",
      "Train Epoch: 1 [19840/20000 (99%)]\tLoss: 0.982158 testing loss: tensor(0.7792)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(0.7792)\n",
      "CS 2 : 0.7788871702194213\n",
      "DP 2 : 0.7277208984434604\n",
      "heuristic 2 : 0.7266990943431855\n",
      "DP: 0.7437459230422974\n",
      "tensor([0.1988, 0.1977, 0.1975, 0.2030, 0.2030])\n",
      "tensor([0.2507, 0.2476, 0.2479, 0.2538, 1.0000])\n",
      "tensor([0.3341, 0.3333, 0.3326, 1.0000, 1.0000])\n",
      "tensor([0.5011, 0.4989, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: twopeak heuristic\n",
      "Sequential(\n",
      "  (0): Linear(in_features=5, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=100, out_features=5, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.009359\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 0.000982\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 0.000190\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 0.000037\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.000097\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 0.000033\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 0.000031\n",
      "NN 1 : tensor(0.7634)\n",
      "CS 1 : 0.7788871702194213\n",
      "DP 1 : 0.7277208984434604\n",
      "heuristic 1 : 0.7266990943431855\n",
      "DP: 0.7437459230422974\n",
      "tensor([0.1231, 0.1405, 0.1379, 0.1386, 0.4599])\n",
      "tensor([0.1832, 0.1581, 0.1772, 0.4816, 1.0000])\n",
      "tensor([0.1171, 0.4468, 0.4362, 1.0000, 1.0000])\n",
      "tensor([0.5049, 0.4951, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 16.804970 testing loss: tensor(0.7662)\n",
      "Train Epoch: 1 [640/20000 (3%)]\tLoss: 10.285113 testing loss: tensor(0.7727)\n",
      "Train Epoch: 1 [1280/20000 (6%)]\tLoss: 5.650300 testing loss: tensor(0.7737)\n",
      "Train Epoch: 1 [1920/20000 (10%)]\tLoss: 2.069408 testing loss: tensor(0.7723)\n",
      "Train Epoch: 1 [2560/20000 (13%)]\tLoss: 1.186557 testing loss: tensor(0.7696)\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 0.866056 testing loss: tensor(0.7688)\n",
      "Train Epoch: 1 [3840/20000 (19%)]\tLoss: 0.650078 testing loss: tensor(0.7687)\n",
      "Train Epoch: 1 [4480/20000 (22%)]\tLoss: 1.110244 testing loss: tensor(0.7683)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for order in stage:\n",
    "    samplesJoint=mydistribution.producedata(order,trainSize)\n",
    "    tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    tp_dataset = TensorDataset(tp_tensor[: int(trainSize * percentage_train_test)])\n",
    "    tp_dataset_testing = TensorDataset(tp_tensor[int(trainSize * (1.0-percentage_train_test)) :])\n",
    "    tp_dataloader = DataLoader(tp_dataset, batch_size=128, shuffle=True)\n",
    "    tp_dataloader_testing = DataLoader(tp_dataset_testing, batch_size=256, shuffle=False)\n",
    "    run_dp()\n",
    "    #running\n",
    "    for order1 in order1name:\n",
    "        print(\"Supervised Aim:\",order,order1)\n",
    "        \n",
    "        # Instantiate the model with hyperparameters\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(n, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, n),\n",
    "        )\n",
    "        if(init_weights==\"xavier_uniform\"):\n",
    "            model.apply(init_weights_xavier_uniform)\n",
    "        if(init_weights==\"xavier_normal\"):\n",
    "            model.apply(init_weights_xavier_normal)\n",
    "        if(init_weights==\"kaiming_uniform\"):\n",
    "            model.apply(init_weights_xavier_uniform)\n",
    "        if(init_weights==\"kaiming_normal\"):\n",
    "            model.apply(init_weights_xavier_normal)\n",
    "        # optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr1)\n",
    "        print(model)\n",
    "        \n",
    "        runningLossNN = []\n",
    "        runningLossCS = []\n",
    "        runningLossDP = []\n",
    "        runningLossHeuristic = []\n",
    "        #model=torch.load(\"save/pytorchNN=5dp1\");\n",
    "        #model.eval()\n",
    "        ##order1name=[\"costsharing\",\"dp\",\"heuristic\",\"random initializing\"]\n",
    "        for epoch in range(1, supervisionEpochs + 1):\n",
    "#             print(\"distributionRatio\",distributionRatio)\n",
    "            if(order1==\"costsharing\"):\n",
    "                supervisionTrain(epoch, costSharingSupervisionRule)\n",
    "            elif(order1==\"dp\"):\n",
    "                supervisionTrain(epoch, dpSupervisionRule)\n",
    "            elif(order1==\"heuristic\"):\n",
    "                supervisionTrain(epoch, heuristicSupervisionRule)\n",
    "            elif(order1==\"random initializing\"):\n",
    "                print(\"do nothing\");\n",
    "\n",
    "        test()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr2)\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train(epoch)\n",
    "            test()\n",
    "        losslistname.append(order+\" \"+order1);\n",
    "        losslist.append(losslisttemp);\n",
    "        losslisttemp=[];\n",
    "        savepath=\"save/pytorchNN=5all-beta\"+order+str(order1)\n",
    "        torch.save(model, savepath);\n",
    "        print(\"end\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colorlist=[\"#D2691E\",'#4169E1',\"#9ACD32\",\"#B22222\",\"#FF00FF\",\"#708090\"]\n",
    "for i in range(len(losslist)):\n",
    "    plt.plot(losslist[i], '.-', color=colorlist[i], alpha=0.8, label=losslistname[i])\n",
    "\n",
    "# label=''\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Trianing Times')\n",
    "plt.ylabel('Welfare')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
