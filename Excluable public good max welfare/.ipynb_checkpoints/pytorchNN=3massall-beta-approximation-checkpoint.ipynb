{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3540388371733616\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from random import randint\n",
    "import random\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "global decision1,decision2,record_ans\n",
    "from pylab import *\n",
    "from scipy.stats import beta\n",
    "import math\n",
    "n = 5\n",
    "epochs = 1\n",
    "supervisionEpochs = 1\n",
    "lr1 = 0.001\n",
    "lr2 = 0.00001\n",
    "log_interval = 20\n",
    "trainSize = 60000#100000\n",
    "percentage_train_test= 0.25\n",
    "penaltyLambda = 10\n",
    "doublePeakHighMean = 0.9\n",
    "doublePeakLowMean = 0.1\n",
    "doublePeakStd = 0.1\n",
    "uniformlow=0\n",
    "uniformhigh=1.0\n",
    "normalloc = 0.2\n",
    "normalscale = 0.1\n",
    "\n",
    "cauchyloc = 1/n\n",
    "cauchyscalen = 0.004\n",
    "\n",
    "exponentialhigh = 15 #Symbol(\"b\", real=True)\n",
    "exponentiallow  = 15 #Symbol(\"a\", real=True)\n",
    "dpPrecision = 50\n",
    "record_ans = 0\n",
    "\n",
    "beta_a = 0.1\n",
    "beta_b  = 0.1\n",
    "kumaraswamy_a = beta_a \n",
    "kumaraswamy_b = (1.0+(beta_a-1.0)*math.pow( (beta_a+beta_b-2.0)/(beta_a-1.0), beta_a) )/beta_a \n",
    "print(kumaraswamy_b)\n",
    "\n",
    "independentnormalloc1=[(float(ii)+1)/(2*n+1) for ii in range(n,0,-1)]\n",
    "independentnormalscale1=[0.05 for ii in range(n)]\n",
    "\n",
    "independentnormalloc2=[(float(ii)+1)/(2*n+1) for ii in range(1,n+1,1)]\n",
    "independentnormalscale2=[0.05 for ii in range(n)]\n",
    "stage=[\"twopeak\"]\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"beta\",\"U-exponential\",\"arcsine\"\n",
    "order1name=[\"dp\",\"random initializing\",\"costsharing\"]\n",
    "#order1name=[\"random initializing1\",\"random initializing2\",\"random initializing3\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = D.normal.Normal(doublePeakLowMean, doublePeakStd)\n",
    "d2 = D.normal.Normal(doublePeakHighMean, doublePeakStd)\n",
    "distributionRatio1 = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase1 = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(normalloc, normalscale)\n",
    "distributionRatio3 = d3.cdf(1) - d3.cdf(0)\n",
    "distributionBase3 = d3.cdf(0)\n",
    "\n",
    "d4 = D.uniform.Uniform(uniformlow,uniformhigh)\n",
    "distributionRatio4 = d4.cdf(1) - d4.cdf(0)\n",
    "distributionBase4 = d4.cdf(0)\n",
    "\n",
    "d5 = [D.normal.Normal(independentnormalloc1[ii], independentnormalscale1[ii]) for ii in range(n)]\n",
    "d6 = [D.normal.Normal(independentnormalloc2[ii], independentnormalscale2[ii]) for ii in range(n)]\n",
    "\n",
    "d7 = D.cauchy.Cauchy(cauchyloc,cauchyscalen)\n",
    "\n",
    "d81 = D.exponential.Exponential(exponentiallow)\n",
    "d82 = D.exponential.Exponential(exponentialhigh)\n",
    "\n",
    "d9 = D.beta.Beta(beta_a,beta_b)\n",
    "#sample_d9=d9.rsample(torch.Size([100000]))\n",
    "\n",
    "#d9_sample=np.linspace(0.0001, 0.9999, 10000)\n",
    "#d9_pdf=torch.exp(d9.log_prob(torch.tensor(d9_sample,dtype=torch.float32)))\n",
    "#d9_delta=d9_sample[1]-d9_sample[0]\n",
    "#d9_sum_pdf=torch.sum(d9_pdf*d9_delta)\n",
    "\n",
    "d10 = D.beta.Beta(0.5,0.5)\n",
    "\n",
    "def cdf(x,y, i=None):\n",
    "    if(y==\"twopeak\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) - distributionBase1) / 2 / distributionRatio1\n",
    "    elif(y==\"normal\"):\n",
    "        return (d3.cdf(x)-distributionBase3)/distributionRatio3;\n",
    "    elif(y==\"uniform\"):\n",
    "        return (d4.cdf(x)-distributionBase4)/distributionRatio4;\n",
    "    elif(y==\"independent1\"):\n",
    "        return d5[i].cdf(x);\n",
    "    elif(y==\"independent2\"):\n",
    "        return d6[i].cdf(x);\n",
    "    elif(y==\"cauchy\"):\n",
    "        return d7.cdf(x);\n",
    "    elif(y==\"beta\"):\n",
    "#         sum_cdf=0.0;\n",
    "#         if(x<0.0001):\n",
    "#             x=0.00011;\n",
    "#         if(x>0.9999):\n",
    "#             x=0.99989;\n",
    "#         for i in range(len(d9_pdf)):\n",
    "#             if(d9_sample[i]<x):\n",
    "#                 sum_cdf+=d9_pdf[i]*d9_delta;\n",
    "#             else:\n",
    "#                 sum_cdf+=(d9_pdf[i]+d9_pdf[i-1])/ 2 *(x-d9_sample[i-1])\n",
    "#                 break;\n",
    "#         return sum_cdf/d9_sum_pdf\n",
    "#         cdf_v=torch.sum((sample_d9<(x)), dtype=torch.float32)/100000\n",
    "#         return cdf_v\n",
    "#    F(x|a,b)=1–(1–x^a)^b\n",
    "        if(x<0.0000001):\n",
    "            x=0.0000001\n",
    "        elif(x >0.9999999):\n",
    "            x=0.9999999\n",
    "        try:\n",
    "            return 1.0-torch.pow(1.0-torch.pow(x,kumaraswamy_a),kumaraswamy_b);\n",
    "        except:\n",
    "            return 1.0-torch.pow(1.0-torch.pow(torch.tensor(x,dtype=torch.float32),kumaraswamy_a),kumaraswamy_b);\n",
    "    elif(y==\"arcsine\"):\n",
    "        #\n",
    "        if(x<0.0000001):\n",
    "            x=0.0000001\n",
    "        elif(x >0.9999999):\n",
    "            x=0.9999999\n",
    "        try:\n",
    "            res=2.0/math.pi * torch.asin(torch.sqrt(x))\n",
    "            #print(x)\n",
    "            return res# + 0.0001*1.0/(\n",
    "            #math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "        except:\n",
    "            return 2.0/math.pi * torch.asin(torch.sqrt(torch.tensor(x,dtype=torch.float32)))# + 0.0001*1.0/(\n",
    "            #math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "    elif(y==\"U-exponential\"):\n",
    "        return (d81.cdf(x) + (1.0 - d82.cdf(1.0-x)))  / 2 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global record_ans\n",
    "record_ans=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    if torch.sum(bits).item() == 0:\n",
    "        return torch.ones(n)\n",
    "    bits     = bits.type(torch.float32)\n",
    "    negBits  = torch.ones(n) - bits\n",
    "    payments = model(bits)\n",
    "    payments = payments - 1000 * negBits\n",
    "    payments = torch.softmax(payments, 0)\n",
    "    payments = payments + negBits\n",
    "    return payments\n",
    "\n",
    "def tpToBits(tp, bits=torch.ones(n).type(torch.uint8)):\n",
    "    payments = bitsToPayments(bits)\n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return tpToBits(tp, newBits)#bits-bits#tpToBits(tp, newBits)\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp))\n",
    "\n",
    "\n",
    "def tpToTotalWelfare(tp):\n",
    "    return torch.max(torch.tensor(0.0),torch.dot(tp,tpToBits(tp).type(torch.float32))-1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpSupervisionRule(tp):\n",
    "    global decision1,decision2\n",
    "    global record_ans\n",
    "    global  dp,decision\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    money = dpPrecision\n",
    "    record_=0\n",
    "    for i in range(n):\n",
    "        offerIndex = decision1[n - i, money,record_]\n",
    "        offer = float(offerIndex) / dpPrecision\n",
    "        if tp[i] > offer:\n",
    "            money -= offerIndex\n",
    "            bits[i] = 1\n",
    "            record_ = decision2[n - i, money, record_]\n",
    "            payments[i] = offer\n",
    "        else:\n",
    "            bits[i] = 0\n",
    "            payments[i] = 1\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "#     print()\n",
    "#     print(tp)\n",
    "#     print(bits)\n",
    "#     print(payments)\n",
    "#     print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def heuristicSupervisionRule(tp):\n",
    "    global  dp_H,decision_H\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    tempold=-1;\n",
    "    for turns in range(n,0,-1):\n",
    "        money = dpPrecision\n",
    "        j=0\n",
    "        tempo=sum(bits)\n",
    "        #print(\"bits\",tempo)\n",
    "        for i in range(n):\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            \n",
    "            offerIndex = decision_H[tempo ,tempo - i, money]\n",
    "            offer = float(offerIndex) / dpPrecision\n",
    "            while(j<n):\n",
    "                if(bits[j]!=0):\n",
    "                    break;\n",
    "                j+=1;\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            if tp[j] >= offer:\n",
    "                #print(money,j,tp[j],offer)\n",
    "                money -= offerIndex\n",
    "                bits[j] = 1\n",
    "                payments[j] = offer\n",
    "            else:\n",
    "                bits[j] = 0;\n",
    "                payments[j] = 1.0;\n",
    "            j+=1;\n",
    "        #print(\"money\",money)\n",
    "        if(money==0 and tempold==tempo):\n",
    "            break;\n",
    "        tempold=tempo;\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "\n",
    "    bits = torch.tensor(bits, dtype=torch.float32)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    # print()\n",
    "    # print(tp)\n",
    "    # print(bits)\n",
    "    # print(payments)\n",
    "    # print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "\n",
    "def costSharingSupervisionRule(tp):\n",
    "    tp = list(tp.numpy())\n",
    "    for k in range(n, -1, -1):\n",
    "        if k == 0:\n",
    "            break\n",
    "        bits = [1 if tp[ii] >= 1.0 / k else 0 for ii in range(n)]\n",
    "        if sum(bits) == k:\n",
    "            break\n",
    "    if k == 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1 for ii in range(n)]\n",
    "    else:\n",
    "        payments = [1.0 / k if bits[ii] == 1 else 1 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    return (bits, payments)\n",
    "\n",
    "    \n",
    "def costSharingWelfare(tp):\n",
    "    #print(tp,costSharingSupervisionRule(tp)[0])\n",
    "    return max(0.0,float(torch.dot(tp,torch.tensor(costSharingSupervisionRule(tp)[0],dtype=torch.float32)).item()-1.0))\n",
    "\n",
    "def dpWelfare(tp):\n",
    "    return max(0.0,float(torch.dot(tp,torch.tensor(dpSupervisionRule(tp)[0],dtype=torch.float32)).item()-1.0))\n",
    "\n",
    "def heuristicWelfare(tp):\n",
    "    return max(0.0,float(torch.dot(tp,torch.tensor(heuristicSupervisionRule(tp)[0],dtype=torch.float32)).item()-1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordAndReport(name, source, loss):\n",
    "    source.append(loss)\n",
    "    realLength = len(source)\n",
    "    #print(f\"{name} ({realLength}): {loss}\")\n",
    "    print(name,realLength,\":\" ,loss)\n",
    "\n",
    "def supervisionTrain(epoch, supervisionRule):\n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    \n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss = penalty * penaltyLambda /100000\n",
    "        \n",
    "        for tp in tp_batch:\n",
    "            bits, payments = supervisionRule(tp)\n",
    "#             print()\n",
    "#             print(tp)\n",
    "#             print(bits)\n",
    "#             print(bitsToPayments(bits))\n",
    "#             print(payments)\n",
    "#             print()\n",
    "            loss = loss + F.mse_loss(bitsToPayments(bits), payments)\n",
    "\n",
    "        loss = loss / len(tp_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "losslist=[];\n",
    "losslistname=[];\n",
    "losslisttemp=[];\n",
    "def test_batch():\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        lenLoss= 0\n",
    "        nnLoss = 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "            for tp in tp_batch:\n",
    "                nnLoss += tpToTotalWelfare(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        nnLoss/=lenLoss\n",
    "    return nnLoss\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    global record_ans\n",
    "    global losslisttemp; \n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        loss=0;\n",
    "        for tp in tp_batch:\n",
    "            for i in range(n):\n",
    "                tp1 = tp.clone()\n",
    "                tp1[i] = 1\n",
    "                tp0 = tp.clone()\n",
    "                tp0[i] = 0\n",
    "                offer = tpToPayments(tp1)[i]\n",
    "                Welfare1 = tpToTotalWelfare(tp1)\n",
    "                Welfare0 = tpToTotalWelfare(tp0)\n",
    "                if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                    loss = loss + (1 - cdf(offer,order)) * Welfare1 + cdf(offer,order) * Welfare0\n",
    "                else:\n",
    "                    loss = loss + (1 - cdf(offer,order,i)) * Welfare1 + cdf(offer,order,i) * Welfare0\n",
    "\n",
    "        loss = -loss / len(tp_batch) / n\n",
    "        \n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss += penalty * penaltyLambda\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            losstemp=test_batch();\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                ),\"testing loss:\",losstemp\n",
    "            )\n",
    "            losslisttemp.append(losstemp);\n",
    "            \n",
    "    print(\"penalty:\",penalty.item())\n",
    "    \n",
    "allBits = [torch.tensor(bits, dtype=torch.int16) for bits in itertools.product([0, 1], repeat=n)]\n",
    "\n",
    "def test():\n",
    "    global record_ans\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        costSharingLoss = 0\n",
    "        dpLoss = 0\n",
    "        nnLoss = 0\n",
    "        heuristicLoss=0\n",
    "        lenLoss= 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "\n",
    "            for tp in tp_batch:\n",
    "                costSharingLoss += costSharingWelfare(tp)\n",
    "                dpLoss += dpWelfare(tp)\n",
    "                nnLoss += tpToTotalWelfare(tp)\n",
    "                heuristicLoss+= heuristicWelfare(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        costSharingLoss /= lenLoss\n",
    "        dpLoss /= lenLoss\n",
    "        nnLoss /= lenLoss\n",
    "        heuristicLoss /= lenLoss\n",
    "        #print(lenLoss)\n",
    "        losslisttemp.append(nnLoss);\n",
    "        recordAndReport(\"NN\", runningLossNN, nnLoss)\n",
    "        recordAndReport(\"CS\", runningLossCS, costSharingLoss)\n",
    "        recordAndReport(\"DP\", runningLossDP, dpLoss)\n",
    "        recordAndReport(\"heuristic\", runningLossHeuristic, heuristicLoss)\n",
    "        print(\"DP:\",dp[n, dpPrecision,0])\n",
    "        #for i in range(n, 0, -1):\n",
    "        #    print(\"Heuristic:\",i,5*(1-dp_H[i, i, dpPrecision]))\n",
    "        for i in range(n, 0, -1):\n",
    "            print(\n",
    "                    tpToPayments(\n",
    "                            torch.tensor([0 if ii >= i else 1 for ii in range(n)], dtype=torch.float32)\n",
    "                    )\n",
    "                )\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def producedata(order):\n",
    "    global decision1,decision2\n",
    "    global record_ans\n",
    "    global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "    if(order==\"twopeak\"):\n",
    "        print(\"loc\",doublePeakLowMean, \"scale\",doublePeakStd)\n",
    "        print(\"loc\",doublePeakHighMean, \"scale\",doublePeakStd)\n",
    "        signals = np.random.randint(2, size=(trainSize, n))\n",
    "        samples1 = np.random.normal(\n",
    "            loc=doublePeakLowMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=doublePeakLowMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samples2 = np.random.normal(\n",
    "            loc=doublePeakHighMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "                    samples2[i, j] = np.random.normal(\n",
    "                        loc=doublePeakHighMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samplesJoint = signals * samples1 - (signals - 1) * samples2\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "        # tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "    elif(order==\"normal\"):\n",
    "        print(\"loc\",normalloc, \"scale\",normalscale)\n",
    "        samples1 = np.random.normal(\n",
    "            loc=normalloc, scale=normalscale, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=normalloc, scale=normalscale\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"uniform\"):  \n",
    "        print(\"uniformlow\",uniformlow, \"uniformhigh\",uniformhigh)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        uniformlow, uniformhigh\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"independent1\"):\n",
    "        print(\"loc\",independentnormalloc1,\"scale\",independentnormalscale1)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc1[j], independentnormalscale1[j]\n",
    "                    )\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc1[j], independentnormalscale1[j]\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"independent2\"):\n",
    "        print(\"loc\",independentnormalloc2, \"scale\",independentnormalscale2)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc2[j], independentnormalscale2[j]\n",
    "                    )\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc2[j], independentnormalscale2[j]\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"cauchy\"):\n",
    "        print(\"cauchyloc\",cauchyloc, \"cauchyscale\",cauchyscalen)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = d7.rsample(torch.Size([1]))\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = d7.rsample(torch.Size([1]))\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"beta\"):\n",
    "        print(\"beta_a\",beta_a, \"beta_b\",beta_b)\n",
    "        print(\"kumaraswamy_a\",kumaraswamy_a, \"kumaraswamy_b\",kumaraswamy_b)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = beta.rvs(beta_a,beta_b,  size = 1)\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = beta.rvs(beta_a,beta_b,  size = 1)\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"arcsine\"):\n",
    "        print(\"betalow\",0.5, \"betahigh\",0.5)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = beta.rvs(0.5,0.5,  size = 1)\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = beta.rvs(0.5,0.5,  size = 1)\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"U-exponential\"):\n",
    "        print(\"loc\",doublePeakLowMean, \"scale\",doublePeakStd)\n",
    "        print(\"loc\",doublePeakHighMean, \"scale\",doublePeakStd)\n",
    "        signals = np.random.randint(2, size=(trainSize, n))\n",
    "        samples1 = d81.rsample(torch.Size([trainSize, n])).numpy()\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = d81.rsample(torch.Size([1])).numpy()\n",
    "                    \n",
    "        samples2 = d82.rsample(torch.Size([trainSize, n])).numpy()\n",
    "        \n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "                    samples2[i, j] = d82.rsample(torch.Size([1])).numpy()\n",
    "        samples2 = 1.0 - samples2\n",
    "        samplesJoint = signals * samples1 - (signals - 1.0) * samples2\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "\n",
    "        # tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "        \n",
    "    plt.hist(samplesJoint,bins=500)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    pdfPrecision=1000\n",
    "    pdfnumber=[0 for i in range(pdfPrecision+1)];\n",
    "    cdfnumber=[0 for i in range(pdfPrecision+1)];\n",
    "    utilitynumber=[0 for i in range(pdfPrecision+1)];\n",
    "    Possible_utility=[0 for i in range(pdfPrecision+1)];\n",
    "    for i in range(int(trainSize * percentage_train_test)):\n",
    "        for j in range(n):\n",
    "            pdfnumber[int(samplesJoint[i,j]*pdfPrecision)]+=1.0/int(trainSize * percentage_train_test*n)\n",
    "    cdfnumber[0]=pdfnumber[0];\n",
    "    for i in range(1,pdfPrecision+1):\n",
    "        cdfnumber[i]=cdfnumber[i-1]+pdfnumber[i]\n",
    "    #print(cdfnumber)  \n",
    "    for i in range(1,pdfPrecision+1):\n",
    "        cdfnumber[i]=cdfnumber[i-1]+pdfnumber[i]   \n",
    "    for i in range(0,pdfPrecision+1):\n",
    "        utilitynumber[i]=0\n",
    "        for j in range(i,pdfPrecision+1):\n",
    "            utilitynumber[i]+=pdfnumber[j]*float(j-i)/pdfPrecision\n",
    "        if(sum(pdfnumber[i:])!=0):\n",
    "            utilitynumber[i]/=sum(pdfnumber[i:])\n",
    "    plt.plot(pdfnumber)\n",
    "    plt.show()\n",
    "    print(sum(pdfnumber))\n",
    "\n",
    "    plt.plot(utilitynumber)\n",
    "    plt.show()\n",
    "    \n",
    "    tp_dataset = TensorDataset(tp_tensor[: int(trainSize * percentage_train_test)])\n",
    "    tp_dataset_testing = TensorDataset(tp_tensor[int(trainSize * (1.0-percentage_train_test)) :])\n",
    "    tp_dataloader = DataLoader(tp_dataset, batch_size=128, shuffle=True)\n",
    "    tp_dataloader_testing = DataLoader(tp_dataset_testing, batch_size=256, shuffle=False)\n",
    "    \n",
    "\n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp        = np.zeros([n + 1, dpPrecision + 1, dpPrecision*n + 1])\n",
    "    decision1 = np.zeros([n + 1, dpPrecision + 1, dpPrecision*n + 1], dtype=np.uint8)\n",
    "    decision2 = np.zeros([n + 1, dpPrecision + 1, dpPrecision*n + 1], dtype=np.uint8)\n",
    "    for yes in range(dpPrecision*n + 1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "                offer = float(money) / dpPrecision                                                                     \n",
    "                dp[1, money, yes] =(1.0 - cdf(offer,order).item()) * (yes/dpPrecision + utilitynumber[round(offer*pdfPrecision)])\n",
    "                decision1[1, money, yes] = money\n",
    "                decision2[1, money, yes] = int(yes + utilitynumber[round(offer*pdfPrecision)]*dpPrecision)\n",
    "    for ppl in range(2,  n + 1):\n",
    "        for yes in range(dpPrecision*n + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                maxSoFar = -100000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                        yes_old = int(yes+round(utilitynumber[round(offer*pdfPrecision)]*dpPrecision))\n",
    "                        \n",
    "                        res = (1 - cdf(offer,order)) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes_old, dpPrecision*n)\n",
    "                        ] + cdf(offer,order) * (dp[ppl - 1, money, yes])\n",
    "                    else:\n",
    "                        yes_old = int(yes+round(utilitynumber[round(offer*pdfPrecision)]*dpPrecision))\n",
    "                        res = (1 - cdf(offer,order,n-ppl).item()) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes_old, dpPrecision*n)\n",
    "                        ] + cdf(offer,order,n-ppl).item() * (dp[ppl - 1, money, yes])\n",
    "                    if maxSoFar < res:\n",
    "                        maxSoFar = res\n",
    "                        decision1[ppl, money, yes] = offerIndex\n",
    "                        decision2[ppl, money, yes] = yes_old\n",
    "                dp[ppl, money, yes] = maxSoFar\n",
    "    \n",
    "    print(\"dp\",dp[n, dpPrecision, 0])\n",
    "\n",
    "    def plan_dp(temp,debug):\n",
    "        if(debug==1):\n",
    "            print(temp)\n",
    "        ans =0;\n",
    "        o_list=[];\n",
    "        remain_list=[];\n",
    "        remain=dpPrecision\n",
    "        record_= 0\n",
    "        for ppl in range(n,0,-1):\n",
    "            o=decision1[ppl, remain, record_]\n",
    "            \n",
    "            #print(\"record\",o,record_)\n",
    "            if(debug==1):\n",
    "                print(o,remain,record_)\n",
    "            o_list.append(o)\n",
    "            remain_list.append(remain);\n",
    "            if(o<temp[n-ppl]):\n",
    "                remain-=int(o);\n",
    "                record_=decision2[ppl, remain, record_]\n",
    "                ans=1#+=float(temp[n-ppl]-o)/dpPrecision\n",
    "                #print(\"record\",record_)\n",
    "            elif (remain>0):\n",
    "                ans=0;\n",
    "        if(remain<=1):\n",
    "            return ans,o_list;\n",
    "        else:\n",
    "            return 0,o_list;\n",
    "    ans_list=[];\n",
    "    for i in range(5):\n",
    "        temp=samplesJoint[i]*dpPrecision\n",
    "        #print(temp)\n",
    "        tempres=plan_dp(temp,1)\n",
    "        ans_list.append(tempres[0]);\n",
    "        print(tempres)\n",
    "        #print(\"\\n\",temp)\n",
    "        #print(plan_dp(temp,1))\n",
    "\n",
    "    for i in range(10000):\n",
    "        temp=samplesJoint[i]*dpPrecision\n",
    "        #print(temp)\n",
    "        ans_list.append(plan_dp(temp,0)[0]);\n",
    "        #print(\"\\n\",temp)\n",
    "        #print(plan_dp(temp))\n",
    "    print(sum(ans_list)/len(ans_list))\n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp_H = np.zeros([n + 1 , n + 1, dpPrecision + 1])\n",
    "    decision_H = np.zeros([n + 1 , n + 1, dpPrecision + 1], dtype=np.uint8)\n",
    "    # ppl = 0 left\n",
    "    for i in range(1,n+1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            if money == 0:\n",
    "                dp_H[i, 0, 0] = 1\n",
    "            else:\n",
    "                offer = money / dpPrecision\n",
    "                dp_H[i, 0, money] = 0#cdf(offer)# + 1.0\n",
    "    for i in range(1,n+1):\n",
    "        for ppl in range(1, i + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                maxSoFar = -1000000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                        res = (1-cdf(offer,order)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    else:\n",
    "                        res = (1-cdf(offer,order,ppl-1)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    if maxSoFar < res.item():\n",
    "                        maxSoFar = res.item()\n",
    "                        decision_H[i, ppl, money] = offerIndex\n",
    "                dp_H[i, ppl, money] = maxSoFar\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc 0.1 scale 0.1\n",
      "loc 0.9 scale 0.1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999994\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp 1.3425745964050293\n",
      "[48.16260343  5.72896546  3.26220574  7.48014349 48.95000224]\n",
      "35 50 0\n",
      "8 15 26\n",
      "13 15 26\n",
      "15 15 26\n",
      "15 15 26\n",
      "(1, [35, 8, 13, 15, 15])\n",
      "[ 3.24103537  5.27494003 38.60729381 46.18871042 47.04968387]\n",
      "35 50 0\n",
      "20 50 0\n",
      "20 50 0\n",
      "30 30 15\n",
      "0 0 40\n",
      "(1, [35, 20, 20, 30, 0])\n",
      "[ 4.69378772  3.23042892  1.43038712 34.67464183 46.89751848]\n",
      "35 50 0\n",
      "20 50 0\n",
      "20 50 0\n",
      "20 50 0\n",
      "30 30 14\n",
      "(1, [35, 20, 20, 20, 30])\n",
      "[15.72995967  7.19431981 46.63899902 12.45627281  5.79875588]\n",
      "35 50 0\n",
      "20 50 0\n",
      "20 50 0\n",
      "30 30 15\n",
      "30 30 15\n",
      "(0, [35, 20, 20, 30, 30])\n",
      "[ 4.85354036 45.96848717  0.59422374 49.94307917 45.52689651]\n",
      "35 50 0\n",
      "20 50 0\n",
      "29 30 16\n",
      "30 30 16\n",
      "0 0 41\n",
      "(1, [35, 20, 29, 30, 0])\n",
      "0.8112943528235882\n",
      "Supervised Aim: twopeak dp\n",
      "Sequential(\n",
      "  (0): Linear(in_features=5, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=100, out_features=5, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: 0.039624\n",
      "Train Epoch: 1 [2560/15000 (17%)]\tLoss: 0.008251\n",
      "Train Epoch: 1 [5120/15000 (34%)]\tLoss: 0.006215\n",
      "Train Epoch: 1 [7680/15000 (51%)]\tLoss: 0.004447\n",
      "Train Epoch: 1 [10240/15000 (68%)]\tLoss: 0.002658\n",
      "Train Epoch: 1 [12800/15000 (85%)]\tLoss: 0.001438\n",
      "Train Epoch: 2 [0/15000 (0%)]\tLoss: 0.000988\n",
      "Train Epoch: 2 [2560/15000 (17%)]\tLoss: 0.000432\n",
      "Train Epoch: 2 [5120/15000 (34%)]\tLoss: 0.000373\n",
      "Train Epoch: 2 [7680/15000 (51%)]\tLoss: 0.000253\n",
      "Train Epoch: 2 [10240/15000 (68%)]\tLoss: 0.000167\n",
      "Train Epoch: 2 [12800/15000 (85%)]\tLoss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN 1 : tensor(1.3330)\n",
      "CS 1 : 1.2648055307308832\n",
      "DP 1 : 1.3315719558159511\n",
      "heuristic 1 : 1.3003409478346506\n",
      "DP: 1.3425745964050293\n",
      "tensor([0.7051, 0.1656, 0.1117, 0.0161, 0.0015])\n",
      "tensor([0.6550, 0.1902, 0.1370, 0.0177, 1.0000])\n",
      "tensor([0.6862, 0.1811, 0.1326, 1.0000, 1.0000])\n",
      "tensor([0.7904, 0.2096, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: 12.523084 testing loss: tensor(1.3317)\n",
      "Train Epoch: 1 [2560/15000 (17%)]\tLoss: -0.987785 testing loss: tensor(1.0479)\n",
      "Train Epoch: 1 [5120/15000 (34%)]\tLoss: -1.194047 testing loss: tensor(1.0188)\n",
      "Train Epoch: 1 [7680/15000 (51%)]\tLoss: -0.936958 testing loss: tensor(1.0016)\n",
      "Train Epoch: 1 [10240/15000 (68%)]\tLoss: -1.116585 testing loss: tensor(1.0041)\n",
      "Train Epoch: 1 [12800/15000 (85%)]\tLoss: -1.326722 testing loss: tensor(1.0106)\n",
      "penalty: 0.002210266888141632\n",
      "NN 2 : tensor(1.0165)\n",
      "CS 2 : 1.2648055307308832\n",
      "DP 2 : 1.3315719558159511\n",
      "heuristic 2 : 1.3003409478346506\n",
      "DP: 1.3425745964050293\n",
      "tensor([7.9960e-01, 1.5917e-01, 4.0429e-02, 7.3811e-04, 5.9555e-05])\n",
      "tensor([8.0046e-01, 1.5853e-01, 4.0262e-02, 7.4957e-04, 1.0000e+00])\n",
      "tensor([0.8004, 0.1592, 0.0404, 1.0000, 1.0000])\n",
      "tensor([0.8128, 0.1872, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/15000 (0%)]\tLoss: -1.037679 testing loss: tensor(1.0171)\n",
      "Train Epoch: 2 [2560/15000 (17%)]\tLoss: -1.207812 testing loss: tensor(1.0269)\n",
      "Train Epoch: 2 [5120/15000 (34%)]\tLoss: -1.348096 testing loss: tensor(1.0341)\n",
      "Train Epoch: 2 [7680/15000 (51%)]\tLoss: -1.349870 testing loss: tensor(1.0454)\n",
      "Train Epoch: 2 [10240/15000 (68%)]\tLoss: -1.162115 testing loss: tensor(1.0528)\n",
      "Train Epoch: 2 [12800/15000 (85%)]\tLoss: -1.111430 testing loss: tensor(1.0634)\n",
      "penalty: 0.0005308664403855801\n",
      "NN 3 : tensor(1.0697)\n",
      "CS 3 : 1.2648055307308832\n",
      "DP 3 : 1.3315719558159511\n",
      "heuristic 3 : 1.3003409478346506\n",
      "DP: 1.3425745964050293\n",
      "tensor([7.8596e-01, 1.6142e-01, 5.0837e-02, 1.6283e-03, 1.4637e-04])\n",
      "tensor([0.7855, 0.1619, 0.0510, 0.0016, 1.0000])\n",
      "tensor([0.7866, 0.1621, 0.0512, 1.0000, 1.0000])\n",
      "tensor([0.8075, 0.1925, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: twopeak random initializing\n",
      "Sequential(\n",
      "  (0): Linear(in_features=5, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=100, out_features=5, bias=True)\n",
      ")\n",
      "do nothing\n",
      "do nothing\n",
      "NN 1 : tensor(1.2720)\n",
      "CS 1 : 1.2648055307308832\n",
      "DP 1 : 1.3315719558159511\n",
      "heuristic 1 : 1.3003409478346506\n",
      "DP: 1.3425745964050293\n",
      "tensor([0.2023, 0.1211, 0.2645, 0.1855, 0.2266])\n",
      "tensor([0.2366, 0.1699, 0.3480, 0.2455, 1.0000])\n",
      "tensor([0.3373, 0.2400, 0.4227, 1.0000, 1.0000])\n",
      "tensor([0.5780, 0.4220, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: -1.406473 testing loss: tensor(1.2770)\n",
      "Train Epoch: 1 [2560/15000 (17%)]\tLoss: -1.478564 testing loss: tensor(1.3038)\n",
      "Train Epoch: 1 [5120/15000 (34%)]\tLoss: -1.621700 testing loss: tensor(1.3312)\n",
      "Train Epoch: 1 [7680/15000 (51%)]\tLoss: -1.453207 testing loss: tensor(1.2835)\n",
      "Train Epoch: 1 [10240/15000 (68%)]\tLoss: -1.552742 testing loss: tensor(1.3088)\n",
      "Train Epoch: 1 [12800/15000 (85%)]\tLoss: -1.472932 testing loss: tensor(1.2938)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.2971)\n",
      "CS 2 : 1.2648055307308832\n",
      "DP 2 : 1.3315719558159511\n",
      "heuristic 2 : 1.3003409478346506\n",
      "DP: 1.3425745964050293\n",
      "tensor([0.0324, 0.0456, 0.7629, 0.1157, 0.0435])\n",
      "tensor([0.0405, 0.0564, 0.7800, 0.1231, 1.0000])\n",
      "tensor([0.0584, 0.0738, 0.8678, 1.0000, 1.0000])\n",
      "tensor([0.4997, 0.5003, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/15000 (0%)]\tLoss: -1.444440 testing loss: tensor(1.2972)\n",
      "Train Epoch: 2 [2560/15000 (17%)]\tLoss: -1.456128 testing loss: tensor(1.2860)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "        \n",
    "def init_weights_xavier_uniform(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "        \n",
    "def init_weights_xavier_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "        \n",
    "        \n",
    "def init_weights_kaiming_uniform(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "        \n",
    "        \n",
    "def init_weights_kaiming_normal_(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "\n",
    "\n",
    "        \n",
    "for order in stage:\n",
    "    producedata(order)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "    #running\n",
    "    for order1 in order1name:\n",
    "        print(\"Supervised Aim:\",order,order1)\n",
    "        \n",
    "        # Instantiate the model with hyperparameters\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(n, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, n),\n",
    "        )\n",
    "        model.apply(init_weights)\n",
    "        # optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr1)\n",
    "        print(model)\n",
    "        \n",
    "        runningLossNN = []\n",
    "        runningLossCS = []\n",
    "        runningLossDP = []\n",
    "        runningLossHeuristic = []\n",
    "        #model=torch.load(\"save/pytorchNN=5dp1\");\n",
    "        #model.eval()\n",
    "        ##order1name=[\"costsharing\",\"dp\",\"heuristic\",\"random initializing\"]\n",
    "        for epoch in range(1, supervisionEpochs + 1):\n",
    "#             print(\"distributionRatio\",distributionRatio)\n",
    "            if(order1==\"costsharing\"):\n",
    "                supervisionTrain(epoch, costSharingSupervisionRule)\n",
    "            elif(order1==\"dp\"):\n",
    "                supervisionTrain(epoch, dpSupervisionRule)\n",
    "            elif(order1==\"heuristic\"):\n",
    "                supervisionTrain(epoch, heuristicSupervisionRule)\n",
    "            elif(order1==\"random initializing\"):\n",
    "                print(\"do nothing\");\n",
    "\n",
    "        test()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr2)\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train(epoch)\n",
    "            test()\n",
    "        losslistname.append(order+\" \"+order1);\n",
    "        losslist.append(losslisttemp);\n",
    "        losslisttemp=[];\n",
    "        savepath=\"save/pytorchNN=5all-beta\"+order+str(order1)\n",
    "        torch.save(model, savepath);\n",
    "        print(\"end\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colorlist=[\"#D2691E\",'#4169E1',\"#9ACD32\",\"#B22222\",\"#FF00FF\",\"#708090\"]\n",
    "for i in range(len(losslist)):\n",
    "    plt.plot(losslist[i], 'ro-', color=colorlist[i], alpha=0.8, label=losslistname[i])\n",
    "\n",
    "# 显示标签，如果不加这句，即使加了label='一些数字'的参数，最终还是不会显示标签\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('trianing times')\n",
    "plt.ylabel('Welfare')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
