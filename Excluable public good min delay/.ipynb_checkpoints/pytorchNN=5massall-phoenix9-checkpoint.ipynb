{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from random import randint\n",
    "import random\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "from pylab import *\n",
    "from scipy.stats import beta\n",
    "n = 3\n",
    "epochs = 3\n",
    "supervisionEpochs = 4\n",
    "lr = 0.0005\n",
    "log_interval = 20\n",
    "trainSize = 40000#100000\n",
    "percentage_train_test= 0.25\n",
    "penaltyLambda = 10\n",
    "doublePeakHighMean = 0.9\n",
    "doublePeakLowMean = 0.1\n",
    "doublePeakStd = 0.1\n",
    "uniformlow=0\n",
    "uniformhigh=1.0\n",
    "normalloc = 0.2\n",
    "normalscale = 0.1\n",
    "\n",
    "cauchyloc = 1/n\n",
    "cauchyscalen = 0.004\n",
    "\n",
    "exponentialhigh = 15 #Symbol(\"b\", real=True)\n",
    "exponentiallow  = 15 #Symbol(\"a\", real=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "independentnormalloc1=[(float(ii)+1)/(2*n+1) for ii in range(n,0,-1)]\n",
    "independentnormalscale1=[0.05 for ii in range(n)]\n",
    "\n",
    "independentnormalloc2=[(float(ii)+1)/(2*n+1) for ii in range(1,n+1,1)]\n",
    "independentnormalscale2=[0.05 for ii in range(n)]\n",
    "stage=[\"U-exponential\"]\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"U-exponential\"\n",
    "order1name=[\"costsharing\",\"dp\",\"random initializing\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "d1 = D.normal.Normal(doublePeakLowMean, doublePeakStd)\n",
    "d2 = D.normal.Normal(doublePeakHighMean, doublePeakStd)\n",
    "distributionRatio1 = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase1 = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(normalloc, normalscale)\n",
    "distributionRatio3 = d3.cdf(1) - d3.cdf(0)\n",
    "distributionBase3 = d3.cdf(0)\n",
    "\n",
    "d4 = D.uniform.Uniform(uniformlow,uniformhigh)\n",
    "distributionRatio4 = d4.cdf(1) - d4.cdf(0)\n",
    "distributionBase4 = d4.cdf(0)\n",
    "\n",
    "d5 = [D.normal.Normal(independentnormalloc1[ii], independentnormalscale1[ii]) for ii in range(n)]\n",
    "d6 = [D.normal.Normal(independentnormalloc2[ii], independentnormalscale2[ii]) for ii in range(n)]\n",
    "\n",
    "d7 = D.cauchy.Cauchy(cauchyloc,cauchyscalen)\n",
    "\n",
    "d81 = D.exponential.Exponential(exponentiallow)\n",
    "d82 = D.exponential.Exponential(exponentialhigh)\n",
    "\n",
    "#d8 = beta(betahigh,betalow)\n",
    "#d9 = D.beta.Beta(betahigh,betalow)\n",
    "def cdf(x,y, i=None):\n",
    "    if(y==\"twopeak\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) - distributionBase1) / 2 / distributionRatio1\n",
    "    elif(y==\"normal\"):\n",
    "        return (d3.cdf(x)-distributionBase3)/distributionRatio3;\n",
    "    elif(y==\"uniform\"):\n",
    "        return (d4.cdf(x)-distributionBase4)/distributionRatio4;\n",
    "    elif(y==\"independent1\"):\n",
    "        return d5[i].cdf(x);\n",
    "    elif(y==\"independent2\"):\n",
    "        return d6[i].cdf(x);\n",
    "    elif(y==\"cauchy\"):\n",
    "        return d7.cdf(x);\n",
    "#     elif(y==\"beta\"):\n",
    "#         return torch.tensor(d8.cdf(x));\n",
    "    elif(y==\"U-exponential\"):\n",
    "        return (d81.cdf(x) + (1.0 - d82.cdf(1.0-x)))  / 2 \n",
    "print(cdf(0.5,\"U-exponential\"))\n",
    "\n",
    "print(d81.cdf(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    if torch.sum(bits).item() == 0:\n",
    "        return torch.ones(n)\n",
    "    bits = bits.type(torch.float32)\n",
    "    negBits = torch.ones(n) - bits\n",
    "    payments = model(bits)\n",
    "    payments = payments - 1000 * negBits\n",
    "    payments = torch.softmax(payments, 0)\n",
    "    payments = payments + negBits\n",
    "    return payments\n",
    "\n",
    "def tpToBits(tp, bits=torch.ones(n).type(torch.uint8)):\n",
    "    payments = bitsToPayments(bits)\n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return tpToBits(tp, newBits)#bits-bits#tpToBits(tp, newBits)\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp))\n",
    "\n",
    "\n",
    "def tpToTotalDelay(tp):\n",
    "    return n - torch.sum(tpToBits(tp).type(torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpSupervisionRule(tp):\n",
    "    global  dp,decision\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    money = dpPrecision\n",
    "    yes = 0\n",
    "    for i in range(n):\n",
    "        offerIndex = decision[n - i, money, yes]\n",
    "        offer = float(offerIndex) / dpPrecision\n",
    "        if tp[i] >= offer:\n",
    "            money -= offerIndex\n",
    "            yes += 1\n",
    "            bits[i] = 1\n",
    "            payments[i] = offer\n",
    "        else:\n",
    "            bits[i] = 0\n",
    "            payments[i] = 1\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "#     print()\n",
    "#     print(tp)\n",
    "#     print(bits)\n",
    "#     print(payments)\n",
    "#     print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def heuristicSupervisionRule(tp):\n",
    "    global  dp_H,decision_H\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    tempold=-1;\n",
    "    for turns in range(n,0,-1):\n",
    "        money = dpPrecision\n",
    "        j=0\n",
    "        tempo=sum(bits)\n",
    "        #print(\"bits\",tempo)\n",
    "        for i in range(n):\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            \n",
    "            offerIndex = decision_H[tempo ,tempo - i, money]\n",
    "            offer = float(offerIndex) / dpPrecision\n",
    "            while(j<n):\n",
    "                if(bits[j]!=0):\n",
    "                    break;\n",
    "                j+=1;\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            if tp[j] >= offer:\n",
    "                #print(money,j,tp[j],offer)\n",
    "                money -= offerIndex\n",
    "                bits[j] = 1\n",
    "                payments[j] = offer\n",
    "            else:\n",
    "                bits[j] = 0;\n",
    "                payments[j] = 1.0;\n",
    "            j+=1;\n",
    "        #print(\"money\",money)\n",
    "        if(money==0 and tempold==tempo):\n",
    "            break;\n",
    "        tempold=tempo;\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "\n",
    "    bits = torch.tensor(bits, dtype=torch.float32)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    # print()\n",
    "    # print(tp)\n",
    "    # print(bits)\n",
    "    # print(payments)\n",
    "    # print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "\n",
    "def costSharingSupervisionRule(tp):\n",
    "    tp = list(tp.numpy())\n",
    "    for k in range(n, -1, -1):\n",
    "        if k == 0:\n",
    "            break\n",
    "        bits = [1 if tp[ii] >= 1.0 / k else 0 for ii in range(n)]\n",
    "        if sum(bits) == k:\n",
    "            break\n",
    "    if k == 0:\n",
    "        payments = [1 for ii in range(n)]\n",
    "    else:\n",
    "        payments = [1.0 / k if bits[ii] == 1 else 1 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def costSharingDelay(tp):\n",
    "    return float(n - torch.sum(costSharingSupervisionRule(tp)[0]).item())\n",
    "\n",
    "def dpDelay(tp):\n",
    "    return float(n - torch.sum(dpSupervisionRule(tp)[0]).item())\n",
    "\n",
    "def heuristicDelay(tp):\n",
    "    return float(n - torch.sum(heuristicSupervisionRule(tp)[0]).item())\n",
    "\n",
    "\n",
    "# templire=0;\n",
    "# num=1\n",
    "# for i in range(num):\n",
    "#     temp=torch.tensor(samplesJoint[i])\n",
    "#     #print(temp)\n",
    "#     #print(temp);\n",
    "#     #print(heuristicSupervisionRule(temp))\n",
    "#     #print(dpSupervisionRule(temp))\n",
    "#     #print(dpDelay(temp))\n",
    "#     res=dpDelay(temp)\n",
    "#     templire+=res\n",
    "#     #print(\"delay\",res)\n",
    "#     #print()\n",
    "# print(templire/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordAndReport(name, source, loss):\n",
    "    source.append(loss)\n",
    "    realLength = len(source)\n",
    "    #print(f\"{name} ({realLength}): {loss}\")\n",
    "    print(name,realLength,\":\" ,loss)\n",
    "\n",
    "def supervisionTrain(epoch, supervisionRule):\n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    \n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss = penalty * penaltyLambda /100000\n",
    "        \n",
    "        for tp in tp_batch:\n",
    "            bits, payments = supervisionRule(tp)\n",
    "            loss = loss + F.mse_loss(bitsToPayments(bits), payments)\n",
    "\n",
    "        loss = loss / len(tp_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "losslist=[];\n",
    "losslistname=[];\n",
    "losslisttemp=[];\n",
    "def test_batch():\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        lenLoss= 0\n",
    "        nnLoss = 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "            for tp in tp_batch:\n",
    "                nnLoss += tpToTotalDelay(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        nnLoss/=lenLoss\n",
    "    return nnLoss\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    global losslisttemp; \n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss = penalty * penaltyLambda\n",
    "        for tp in tp_batch:\n",
    "            for i in range(n):\n",
    "                tp1 = tp.clone()\n",
    "                tp1[i] = 1\n",
    "                tp0 = tp.clone()\n",
    "                tp0[i] = 0\n",
    "                offer = tpToPayments(tp1)[i]\n",
    "                delay1 = tpToTotalDelay(tp1)\n",
    "                delay0 = tpToTotalDelay(tp0)\n",
    "                if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                    loss = loss + (1 - cdf(offer,order)) * delay1 + cdf(offer,order) * delay0\n",
    "                else:\n",
    "                    loss = loss + (1 - cdf(offer,order,i)) * delay1 + cdf(offer,order,i) * delay0\n",
    "\n",
    "        loss = loss / len(tp_batch) / n\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            losstemp=test_batch();\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                ),\"testing loss:\",losstemp\n",
    "            )\n",
    "            losslisttemp.append(losstemp);\n",
    "            \n",
    "    print(\"penalty:\",penalty.item())\n",
    "    \n",
    "allBits = [torch.tensor(bits, dtype=torch.int16) for bits in itertools.product([0, 1], repeat=n)]\n",
    "\n",
    "def test():\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        costSharingLoss = 0\n",
    "        dpLoss = 0\n",
    "        nnLoss = 0\n",
    "        heuristicLoss=0\n",
    "        lenLoss= 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "\n",
    "            for tp in tp_batch:\n",
    "                costSharingLoss += costSharingDelay(tp)\n",
    "                dpLoss += dpDelay(tp)\n",
    "                nnLoss += tpToTotalDelay(tp)\n",
    "                heuristicLoss+= heuristicDelay(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        costSharingLoss /= lenLoss\n",
    "        dpLoss /= lenLoss\n",
    "        nnLoss /= lenLoss\n",
    "        heuristicLoss /= lenLoss\n",
    "        #print(lenLoss)\n",
    "        losslisttemp.append(nnLoss);\n",
    "        recordAndReport(\"NN\", runningLossNN, nnLoss)\n",
    "        recordAndReport(\"CS\", runningLossCS, costSharingLoss)\n",
    "        recordAndReport(\"DP\", runningLossDP, dpLoss)\n",
    "        recordAndReport(\"heuristic\", runningLossHeuristic, heuristicLoss)\n",
    "        print(\"DP:\",dp[n, dpPrecision,0])\n",
    "        #for i in range(n, 0, -1):\n",
    "        #    print(\"Heuristic:\",i,5*(1-dp_H[i, i, dpPrecision]))\n",
    "        for i in range(n, 0, -1):\n",
    "            print(\n",
    "                    tpToPayments(\n",
    "                            torch.tensor([0 if ii >= i else 1 for ii in range(n)], dtype=torch.float32)\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "dpPrecision = 100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def producedata(order):\n",
    "    global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "    dpPrecision = 100 \n",
    "    if(order==\"twopeak\"):\n",
    "        print(\"loc\",doublePeakLowMean, \"scale\",doublePeakStd)\n",
    "        print(\"loc\",doublePeakHighMean, \"scale\",doublePeakStd)\n",
    "        signals = np.random.randint(2, size=(trainSize, n))\n",
    "        samples1 = np.random.normal(\n",
    "            loc=doublePeakLowMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=doublePeakLowMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samples2 = np.random.normal(\n",
    "            loc=doublePeakHighMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "                    samples2[i, j] = np.random.normal(\n",
    "                        loc=doublePeakHighMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samplesJoint = signals * samples1 - (signals - 1) * samples2\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "        # tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "    elif(order==\"normal\"):\n",
    "        print(\"loc\",normalloc, \"scale\",normalscale)\n",
    "        samples1 = np.random.normal(\n",
    "            loc=normalloc, scale=normalscale, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=normalloc, scale=normalscale\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"uniform\"):  \n",
    "        print(\"uniformlow\",uniformlow, \"uniformhigh\",uniformhigh)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        uniformlow, uniformhigh\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"independent1\"):\n",
    "        print(\"loc\",independentnormalloc1,\"scale\",independentnormalscale1)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc1[j], independentnormalscale1[j]\n",
    "                    )\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc1[j], independentnormalscale1[j]\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"independent2\"):\n",
    "        print(\"loc\",independentnormalloc2, \"scale\",independentnormalscale2)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc2[j], independentnormalscale2[j]\n",
    "                    )\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc2[j], independentnormalscale2[j]\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"cauchy\"):\n",
    "        print(\"cauchyloc\",cauchyloc, \"cauchyscale\",cauchyscalen)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = d7.rsample(torch.Size([1]))\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = d7.rsample(torch.Size([1]))\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"beta\"):\n",
    "        print(\"betalow\",betalow, \"betahigh\",betahigh)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = beta.rvs(betahigh,betalow,  size = 1)\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = beta.rvs(betahigh,betalow,  size = 1)\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"U-exponential\"):\n",
    "        print(\"loc\",doublePeakLowMean, \"scale\",doublePeakStd)\n",
    "        print(\"loc\",doublePeakHighMean, \"scale\",doublePeakStd)\n",
    "        signals = np.random.randint(2, size=(trainSize, n))\n",
    "        samples1 = d81.rsample(torch.Size([trainSize, n])).numpy()\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = d81.rsample(torch.Size([1])).numpy()\n",
    "                    \n",
    "        samples2 = d82.rsample(torch.Size([trainSize, n])).numpy()\n",
    "        \n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "                    samples2[i, j] = d82.rsample(torch.Size([1])).numpy()\n",
    "        samples2 = 1.0 - samples2\n",
    "        samplesJoint = signals * samples1 - (signals - 1.0) * samples2\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "        plt.hist(samplesJoint,bins=500)\n",
    "        plt.show()\n",
    "        # tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "    tp_dataset = TensorDataset(tp_tensor[: int(trainSize * percentage_train_test)])\n",
    "    tp_dataset_testing = TensorDataset(tp_tensor[int(trainSize * (1.0-percentage_train_test)) :])\n",
    "    tp_dataloader = DataLoader(tp_dataset, batch_size=128, shuffle=True)\n",
    "    tp_dataloader_testing = DataLoader(tp_dataset_testing, batch_size=256, shuffle=False)\n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp = np.zeros([n + 1, dpPrecision + 1, n + 1])\n",
    "    decision = np.zeros([n + 1, dpPrecision + 1, n + 1], dtype=np.uint8)\n",
    "    # ppl = 0 left\n",
    "    for yes in range(n + 1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            if money == 0:\n",
    "                dp[0, 0, yes] = 0\n",
    "            else:\n",
    "                dp[0, money, yes] = yes# + 1.0\n",
    "    for ppl in range(1,  n + 1):\n",
    "        for yes in range(n + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                minSoFar = 1000000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                        res = (1 - cdf(offer,order)) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes + 1, n)\n",
    "                        ] + cdf(offer,order) * (1 + dp[ppl - 1, money, yes])\n",
    "                    else:\n",
    "                        res = (1 - cdf(offer,order,n-ppl)) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes + 1, n)\n",
    "                        ] + cdf(offer,order,n-ppl) * (1 + dp[ppl - 1, money, yes])\n",
    "                    if minSoFar > res.item():\n",
    "                        minSoFar = res.item()\n",
    "                        decision[ppl, money, yes] = offerIndex\n",
    "                dp[ppl, money, yes] = minSoFar\n",
    "    \n",
    "    print(\"dp\",dp[n, dpPrecision, 0])\n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp_H = np.zeros([n + 1 , n + 1, dpPrecision + 1])\n",
    "    decision_H = np.zeros([n + 1 , n + 1, dpPrecision + 1], dtype=np.uint8)\n",
    "    # ppl = 0 left\n",
    "    for i in range(1,n+1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            if money == 0:\n",
    "                dp_H[i, 0, 0] = 1\n",
    "            else:\n",
    "                offer = money / dpPrecision\n",
    "                dp_H[i, 0, money] = 0#cdf(offer)# + 1.0\n",
    "    for i in range(1,n+1):\n",
    "        for ppl in range(1, i + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                maxSoFar = -1000000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                        res = (1-cdf(offer,order)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    else:\n",
    "                        res = (1-cdf(offer,order,ppl-1)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    if maxSoFar < res.item():\n",
    "                        maxSoFar = res.item()\n",
    "                        decision_H[i, ppl, money] = offerIndex\n",
    "                dp_H[i, ppl, money] = maxSoFar\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc 0.1 scale 0.1\n",
      "loc 0.9 scale 0.1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp 1.75\n",
      "Supervised Aim: U-exponential costsharing\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 0.008994\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 0.000285\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 0.000005\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 0.000006\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 0.000000\n",
      "NN 1 : tensor(1.8772)\n",
      "CS 1 : 1.8772\n",
      "DP 1 : 1.7529\n",
      "heuristic 1 : 2.0059\n",
      "DP: 1.75\n",
      "tensor([0.3333, 0.3333, 0.3333])\n",
      "tensor([0.5000, 0.5000, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 1.892373 testing loss: tensor(1.8771)\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 1.828308 testing loss: tensor(1.8753)\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 1.775100 testing loss: tensor(1.7846)\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 1.749124 testing loss: tensor(1.7612)\n",
      "penalty: 0.005584239959716797\n",
      "NN 2 : tensor(1.7537)\n",
      "CS 2 : 1.8772\n",
      "DP 2 : 1.7529\n",
      "heuristic 2 : 2.0059\n",
      "DP: 1.75\n",
      "tensor([0.6839, 0.0011, 0.3150])\n",
      "tensor([0.7663, 0.2337, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 1.797024 testing loss: tensor(1.7546)\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 1.669794 testing loss: tensor(1.7552)\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 1.816251 testing loss: tensor(1.7538)\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 1.741574 testing loss: tensor(1.7539)\n",
      "penalty: 0.0015039145946502686\n",
      "NN 3 : tensor(1.7540)\n",
      "CS 3 : 1.8772\n",
      "DP 3 : 1.7529\n",
      "heuristic 3 : 2.0059\n",
      "DP: 1.75\n",
      "tensor([5.9038e-01, 1.7799e-04, 4.0945e-01])\n",
      "tensor([0.6054, 0.3946, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.759582 testing loss: tensor(1.7542)\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 1.691458 testing loss: tensor(1.7546)\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 1.745093 testing loss: tensor(1.7535)\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 1.819093 testing loss: tensor(1.7541)\n",
      "penalty: 0.0\n",
      "NN 4 : tensor(1.7534)\n",
      "CS 4 : 1.8772\n",
      "DP 4 : 1.7529\n",
      "heuristic 4 : 2.0059\n",
      "DP: 1.75\n",
      "tensor([5.4121e-01, 9.9418e-05, 4.5869e-01])\n",
      "tensor([0.6289, 0.3711, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: U-exponential dp\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 0.020861\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 0.003456\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 0.002423\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 0.000880\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 0.000339\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 0.000201\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 0.000111\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 0.000070\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 0.000049\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 0.000054\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 0.000033\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 0.000027\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 0.000032\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 0.000015\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 0.000016\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 0.000017\n",
      "NN 1 : tensor(1.7692)\n",
      "CS 1 : 1.8772\n",
      "DP 1 : 1.7529\n",
      "heuristic 1 : 2.0059\n",
      "DP: 1.75\n",
      "tensor([0.4846, 0.5047, 0.0107])\n",
      "tensor([0.4859, 0.5141, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 1.697752 testing loss: tensor(1.7681)\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 1.806432 testing loss: tensor(1.7546)\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 1.781798 testing loss: tensor(1.7540)\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 1.822820 testing loss: tensor(1.7531)\n",
      "penalty: 0.0018368959426879883\n",
      "NN 2 : tensor(1.7568)\n",
      "CS 2 : 1.8772\n",
      "DP 2 : 1.7529\n",
      "heuristic 2 : 2.0059\n",
      "DP: 1.75\n",
      "tensor([5.8299e-01, 4.1682e-01, 1.9549e-04])\n",
      "tensor([0.6096, 0.3904, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 1.715624 testing loss: tensor(1.7597)\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 1.655057 testing loss: tensor(1.7591)\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 1.692258 testing loss: tensor(1.7522)\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 1.829847 testing loss: tensor(1.7533)\n",
      "penalty: 0.0023198723793029785\n",
      "NN 3 : tensor(1.7527)\n",
      "CS 3 : 1.8772\n",
      "DP 3 : 1.7529\n",
      "heuristic 3 : 2.0059\n",
      "DP: 1.75\n",
      "tensor([3.9964e-01, 6.0008e-01, 2.7572e-04])\n",
      "tensor([0.3913, 0.6087, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.934773 testing loss: tensor(1.7531)\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 1.693851 testing loss: tensor(1.7513)\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 1.727857 testing loss: tensor(1.7528)\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 1.738346 testing loss: tensor(1.7531)\n",
      "penalty: 0.000639796257019043\n",
      "NN 4 : tensor(1.7521)\n",
      "CS 4 : 1.8772\n",
      "DP 4 : 1.7529\n",
      "heuristic 4 : 2.0059\n",
      "DP: 1.75\n",
      "tensor([4.0014e-01, 5.9972e-01, 1.3636e-04])\n",
      "tensor([0.3903, 0.6097, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: U-exponential random initializing\n",
      "do nothing\n",
      "do nothing\n",
      "do nothing\n",
      "do nothing\n",
      "NN 1 : tensor(1.8743)\n",
      "CS 1 : 1.8772\n",
      "DP 1 : 1.7529\n",
      "heuristic 1 : 2.0059\n",
      "DP: 1.75\n",
      "tensor([0.4265, 0.2660, 0.3075])\n",
      "tensor([0.6426, 0.3574, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 1.792713 testing loss: tensor(1.8722)\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 1.781879 testing loss: tensor(1.8112)\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 1.831761 testing loss: tensor(1.8031)\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 1.710453 testing loss: tensor(1.7859)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.7749)\n",
      "CS 2 : 1.8772\n",
      "DP 2 : 1.7529\n",
      "heuristic 2 : 2.0059\n",
      "DP: 1.75\n",
      "tensor([0.7982, 0.0114, 0.1904])\n",
      "tensor([0.8125, 0.1875, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 1.845788 testing loss: tensor(1.7740)\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 1.771255 testing loss: tensor(1.7705)\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 1.754567 testing loss: tensor(1.7618)\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 1.771388 testing loss: tensor(1.7572)\n",
      "penalty: 0.0002034306526184082\n",
      "NN 3 : tensor(1.7602)\n",
      "CS 3 : 1.8772\n",
      "DP 3 : 1.7529\n",
      "heuristic 3 : 2.0059\n",
      "DP: 1.75\n",
      "tensor([0.6921, 0.0024, 0.3055])\n",
      "tensor([0.7189, 0.2811, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.711138 testing loss: tensor(1.7596)\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 1.693367 testing loss: tensor(1.7537)\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 1.749830 testing loss: tensor(1.7559)\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 1.795079 testing loss: tensor(1.7552)\n",
      "penalty: 0.0001685619354248047\n",
      "NN 4 : tensor(1.7537)\n",
      "CS 4 : 1.8772\n",
      "DP 4 : 1.7529\n",
      "heuristic 4 : 2.0059\n",
      "DP: 1.75\n",
      "tensor([6.6558e-01, 6.6377e-04, 3.3375e-01])\n",
      "tensor([0.7464, 0.2536, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "    \n",
    "for order in stage:\n",
    "    producedata(order)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "    #running\n",
    "    for order1 in order1name:\n",
    "        print(\"Supervised Aim:\",order,order1)\n",
    "        \n",
    "        # for mapping binary to payments before softmax\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(n, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, n),\n",
    "        )\n",
    "        model.apply(init_weights)\n",
    "        # optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        runningLossNN = []\n",
    "        runningLossCS = []\n",
    "        runningLossDP = []\n",
    "        runningLossHeuristic = []\n",
    "        #model=torch.load(\"save/pytorchNN=5dp1\");\n",
    "        #model.eval()\n",
    "        ##order1name=[\"costsharing\",\"dp\",\"heuristic\",\"random initializing\"]\n",
    "        for epoch in range(1, supervisionEpochs + 1):\n",
    "#             print(\"distributionRatio\",distributionRatio)\n",
    "            if(order1==\"costsharing\"):\n",
    "                supervisionTrain(epoch, costSharingSupervisionRule)\n",
    "            elif(order1==\"dp\"):\n",
    "                supervisionTrain(epoch, dpSupervisionRule)\n",
    "            elif(order1==\"heuristic\"):\n",
    "                supervisionTrain(epoch, heuristicSupervisionRule)\n",
    "            elif(order1==\"random initializing\"):\n",
    "                print(\"do nothing\");\n",
    "\n",
    "        test()\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train(epoch)\n",
    "            test()\n",
    "        losslistname.append(order+\" \"+order1);\n",
    "        losslist.append(losslisttemp);\n",
    "        losslisttemp=[];\n",
    "        savepath=\"save/pytorchNN=5all-phoenix\"+order+str(order1)\n",
    "        torch.save(model, savepath);\n",
    "        print(\"end\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colorlist=[\"#D2691E\",'#4169E1',\"#9ACD32\",\"#B22222\",\"#FF00FF\",\"#708090\"]\n",
    "for i in range(len(losslist)):\n",
    "    plt.plot(losslist[i], 'ro-', color=colorlist[i], alpha=0.8, label=losslistname[i])\n",
    "\n",
    "# 显示标签，如果不加这句，即使加了label='一些数字'的参数，最终还是不会显示标签\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('trianing times')\n",
    "plt.ylabel('delay')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
