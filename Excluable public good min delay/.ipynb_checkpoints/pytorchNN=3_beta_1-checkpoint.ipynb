{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3540388371733616\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from random import randint\n",
    "import random\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "from pylab import *\n",
    "from scipy.stats import beta\n",
    "import math\n",
    "n = 3\n",
    "epochs = 1\n",
    "supervisionEpochs = 1\n",
    "lr1 = 0.01\n",
    "lr2 = 0.0005\n",
    "log_interval = 10\n",
    "trainSize = 50000#100000\n",
    "percentage_train_test= 0.6\n",
    "penaltyLambda = 500\n",
    "doublePeakHighMean = 0.6\n",
    "doublePeakLowMean = 0.2\n",
    "doublePeakStd = 0.1\n",
    "uniformlow=0\n",
    "uniformhigh=1.0\n",
    "normalloc = 0.2\n",
    "normalscale = 0.1\n",
    "\n",
    "cauchyloc = 1/n\n",
    "cauchyscalen = 0.004\n",
    "\n",
    "exponentialhigh = 15 #Symbol(\"b\", real=True)\n",
    "exponentiallow  = 15 #Symbol(\"a\", real=True)\n",
    "\n",
    "\n",
    "beta_a = 0.1\n",
    "beta_b  = 0.1\n",
    "kumaraswamy_a = beta_a \n",
    "kumaraswamy_b = (1.0+(beta_a-1.0)*math.pow( (beta_a+beta_b-2.0)/(beta_a-1.0), beta_a) )/beta_a \n",
    "print(kumaraswamy_b)\n",
    "\n",
    "\n",
    "independentnormalloc1=[(float(ii)+1)/(2*n+1) for ii in range(n,0,-1)]\n",
    "independentnormalscale1=[0.05 for ii in range(n)]\n",
    "\n",
    "independentnormalloc2=[(float(ii)+1)/(2*n+1) for ii in range(1,n+1,1)]\n",
    "independentnormalscale2=[0.05 for ii in range(n)]\n",
    "stage=[\"beta\"]\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"beta\",\"U-exponential\",\"arcsine\"\n",
    "order1name=[\"dp\",\"random initializing\",\"costsharing\",\"heuristic\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = D.normal.Normal(doublePeakLowMean, doublePeakStd)\n",
    "d2 = D.normal.Normal(doublePeakHighMean, doublePeakStd)\n",
    "distributionRatio1 = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase1 = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(normalloc, normalscale)\n",
    "distributionRatio3 = d3.cdf(1) - d3.cdf(0)\n",
    "distributionBase3 = d3.cdf(0)\n",
    "\n",
    "d4 = D.uniform.Uniform(uniformlow,uniformhigh)\n",
    "distributionRatio4 = d4.cdf(1) - d4.cdf(0)\n",
    "distributionBase4 = d4.cdf(0)\n",
    "\n",
    "d5 = [D.normal.Normal(independentnormalloc1[ii], independentnormalscale1[ii]) for ii in range(n)]\n",
    "d6 = [D.normal.Normal(independentnormalloc2[ii], independentnormalscale2[ii]) for ii in range(n)]\n",
    "\n",
    "d7 = D.cauchy.Cauchy(cauchyloc,cauchyscalen)\n",
    "\n",
    "d81 = D.exponential.Exponential(exponentiallow)\n",
    "d82 = D.exponential.Exponential(exponentialhigh)\n",
    "\n",
    "d9 = D.beta.Beta(beta_a,beta_b)\n",
    "#sample_d9=d9.rsample(torch.Size([100000]))\n",
    "\n",
    "#d9_sample=np.linspace(0.0001, 0.9999, 10000)\n",
    "#d9_pdf=torch.exp(d9.log_prob(torch.tensor(d9_sample,dtype=torch.float32)))\n",
    "#d9_delta=d9_sample[1]-d9_sample[0]\n",
    "#d9_sum_pdf=torch.sum(d9_pdf*d9_delta)\n",
    "\n",
    "d10 = D.beta.Beta(0.5,0.5)\n",
    "\n",
    "def beta_cdf(x,y, i=None):\n",
    "    return beta.cdf(x, beta_a, beta_b)\n",
    "\n",
    "\n",
    "def cdf(x,y, i=None):\n",
    "    if(y==\"twopeak\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) - distributionBase1) / 2 / distributionRatio1\n",
    "    elif(y==\"normal\"):\n",
    "        return (d3.cdf(x)-distributionBase3)/distributionRatio3;\n",
    "    elif(y==\"uniform\"):\n",
    "        return (d4.cdf(x)-distributionBase4)/distributionRatio4;\n",
    "    elif(y==\"independent1\"):\n",
    "        return d5[i].cdf(x);\n",
    "    elif(y==\"independent2\"):\n",
    "        return d6[i].cdf(x);\n",
    "    elif(y==\"cauchy\"):\n",
    "        return d7.cdf(x);\n",
    "    elif(y==\"beta\"):\n",
    "#         sum_cdf=0.0;\n",
    "#         if(x<0.0001):\n",
    "#             x=0.00011;\n",
    "#         if(x>0.9999):\n",
    "#             x=0.99989;\n",
    "#         for i in range(len(d9_pdf)):\n",
    "#             if(d9_sample[i]<x):\n",
    "#                 sum_cdf+=d9_pdf[i]*d9_delta;\n",
    "#             else:\n",
    "#                 sum_cdf+=(d9_pdf[i]+d9_pdf[i-1])/ 2 *(x-d9_sample[i-1])\n",
    "#                 break;\n",
    "#         return sum_cdf/d9_sum_pdf\n",
    "#         cdf_v=torch.sum((sample_d9<(x)), dtype=torch.float32)/100000\n",
    "#         return cdf_v\n",
    "#    F(x|a,b)=1–(1–x^a)^b\n",
    "        if(x<0.0000001):\n",
    "            x=0.0000001\n",
    "        elif(x >0.9999999):\n",
    "            x=0.9999999\n",
    "        try:\n",
    "            return 1.0-torch.pow(1.0-torch.pow(x,kumaraswamy_a),kumaraswamy_b);\n",
    "        except:\n",
    "            return 1.0-torch.pow(1.0-torch.pow(torch.tensor(x,dtype=torch.float32),kumaraswamy_a),kumaraswamy_b);\n",
    "    elif(y==\"arcsine\"):\n",
    "        #\n",
    "        if(x<0.0000001):\n",
    "            x=0.0000001\n",
    "        elif(x >0.9999999):\n",
    "            x=0.9999999\n",
    "        try:\n",
    "            res=2.0/math.pi * torch.asin(torch.sqrt(x))\n",
    "            #print(x)\n",
    "            return res# + 0.0001*1.0/(\n",
    "            #math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "        except:\n",
    "            return 2.0/math.pi * torch.asin(torch.sqrt(torch.tensor(x,dtype=torch.float32)))# + 0.0001*1.0/(\n",
    "            #math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "    elif(y==\"U-exponential\"):\n",
    "        return (d81.cdf(x) + (1.0 - d82.cdf(1.0-x)))  / 2 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    if torch.sum(bits).item() == 0:\n",
    "        return torch.ones(n)\n",
    "    bits = bits.type(torch.float32)\n",
    "    negBits = torch.ones(n) - bits\n",
    "    payments = model(bits)\n",
    "    payments = payments - 1000 * negBits\n",
    "    payments = torch.softmax(payments, 0)\n",
    "    payments = payments + negBits\n",
    "    return payments\n",
    "\n",
    "def tpToBits(tp, bits=torch.ones(n).type(torch.uint8)):\n",
    "    payments = bitsToPayments(bits)\n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return tpToBits(tp, newBits)#bits-bits#tpToBits(tp, newBits)\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp))\n",
    "\n",
    "\n",
    "def tpToTotalDelay(tp):\n",
    "    return n - torch.sum(tpToBits(tp).type(torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpSupervisionRule(tp):\n",
    "    global  dp,decision\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    money = dpPrecision\n",
    "    yes = 0\n",
    "    for i in range(n):\n",
    "        offerIndex = decision[n - i, money, yes]\n",
    "        offer = float(offerIndex) / dpPrecision\n",
    "        if tp[i] >= offer:\n",
    "            money -= offerIndex\n",
    "            yes += 1\n",
    "            bits[i] = 1\n",
    "            payments[i] = offer\n",
    "        else:\n",
    "            bits[i] = 0\n",
    "            payments[i] = 1\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "#     print()\n",
    "#     print(tp)\n",
    "#     print(bits)\n",
    "#     print(payments)\n",
    "#     print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def heuristicSupervisionRule(tp):\n",
    "    global  dp_H,decision_H\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    tempold=-1;\n",
    "    for turns in range(n,0,-1):\n",
    "        money = dpPrecision\n",
    "        j=0\n",
    "        tempo=sum(bits)\n",
    "        #print(\"bits\",tempo)\n",
    "        for i in range(n):\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            \n",
    "            offerIndex = decision_H[tempo ,tempo - i, money]\n",
    "            offer = float(offerIndex) / dpPrecision\n",
    "            while(j<n):\n",
    "                if(bits[j]!=0):\n",
    "                    break;\n",
    "                j+=1;\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            if tp[j] >= offer:\n",
    "                #print(money,j,tp[j],offer)\n",
    "                money -= offerIndex\n",
    "                bits[j] = 1\n",
    "                payments[j] = offer\n",
    "            else:\n",
    "                bits[j] = 0;\n",
    "                payments[j] = 1.0;\n",
    "            j+=1;\n",
    "        #print(\"money\",money)\n",
    "        if(money==0 and tempold==tempo):\n",
    "            break;\n",
    "        tempold=tempo;\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "\n",
    "    bits = torch.tensor(bits, dtype=torch.float32)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    # print()\n",
    "    # print(tp)\n",
    "    # print(bits)\n",
    "    # print(payments)\n",
    "    # print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "\n",
    "def costSharingSupervisionRule(tp):\n",
    "    tp = list(tp.numpy())\n",
    "    for k in range(n, -1, -1):\n",
    "        if k == 0:\n",
    "            break\n",
    "        bits = [1 if tp[ii] >= 1.0 / k else 0 for ii in range(n)]\n",
    "        if sum(bits) == k:\n",
    "            break\n",
    "    if k == 0:\n",
    "        payments = [1 for ii in range(n)]\n",
    "    else:\n",
    "        payments = [1.0 / k if bits[ii] == 1 else 1 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def costSharingDelay(tp):\n",
    "    return float(n - torch.sum(costSharingSupervisionRule(tp)[0]).item())\n",
    "\n",
    "def dpDelay(tp):\n",
    "    return float(n - torch.sum(dpSupervisionRule(tp)[0]).item())\n",
    "\n",
    "def heuristicDelay(tp):\n",
    "    return float(n - torch.sum(heuristicSupervisionRule(tp)[0]).item())\n",
    "\n",
    "\n",
    "# templire=0;\n",
    "# num=1\n",
    "# for i in range(num):\n",
    "#     temp=torch.tensor(samplesJoint[i])\n",
    "#     #print(temp)\n",
    "#     #print(temp);\n",
    "#     #print(heuristicSupervisionRule(temp))\n",
    "#     #print(dpSupervisionRule(temp))\n",
    "#     #print(dpDelay(temp))\n",
    "#     res=dpDelay(temp)\n",
    "#     templire+=res\n",
    "#     #print(\"Delay\",res)\n",
    "#     #print()\n",
    "# print(templire/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordAndReport(name, source, loss):\n",
    "    source.append(loss)\n",
    "    realLength = len(source)\n",
    "    #print(f\"{name} ({realLength}): {loss}\")\n",
    "    print(name,realLength,\":\" ,loss)\n",
    "\n",
    "def supervisionTrain(epoch, supervisionRule):\n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    \n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss = penalty * penaltyLambda /100000\n",
    "        \n",
    "        for tp in tp_batch:\n",
    "            bits, payments = supervisionRule(tp)\n",
    "            loss = loss + F.mse_loss(bitsToPayments(bits), payments)\n",
    "\n",
    "        loss = loss / len(tp_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % (log_interval*5) == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "losslist=[];\n",
    "losslistname=[];\n",
    "losslisttemp=[];\n",
    "def test_batch():\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        lenLoss= 0\n",
    "        nnLoss = 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "            for tp in tp_batch:\n",
    "                nnLoss += tpToTotalDelay(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        nnLoss/=lenLoss\n",
    "    return nnLoss\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    global losslisttemp; \n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss = penalty * penaltyLambda\n",
    "        for tp in tp_batch:\n",
    "            for i in range(n):\n",
    "                tp1 = tp.clone()\n",
    "                tp1[i] = 1\n",
    "                tp0 = tp.clone()\n",
    "                tp0[i] = 0\n",
    "                offer = tpToPayments(tp1)[i]\n",
    "                Delay1 = tpToTotalDelay(tp1)\n",
    "                Delay0 = tpToTotalDelay(tp0)\n",
    "                if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                    loss = loss + (1 - cdf(offer,order)) * Delay1 + cdf(offer,order) * Delay0\n",
    "                else:\n",
    "                    loss = loss + (1 - cdf(offer,order,i)) * Delay1 + cdf(offer,order,i) * Delay0\n",
    "\n",
    "        loss = loss / len(tp_batch) / n\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            losstemp=test_batch();\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                ),\"testing loss:\",losstemp\n",
    "            )\n",
    "            losslisttemp.append(losstemp);\n",
    "            \n",
    "    print(\"penalty:\",penalty.item())\n",
    "    \n",
    "allBits = [torch.tensor(bits, dtype=torch.int16) for bits in itertools.product([0, 1], repeat=n)]\n",
    "\n",
    "def test():\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        costSharingLoss = 0\n",
    "        dpLoss = 0\n",
    "        nnLoss = 0\n",
    "        heuristicLoss=0\n",
    "        lenLoss= 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "\n",
    "            for tp in tp_batch:\n",
    "                costSharingLoss += costSharingDelay(tp)\n",
    "                dpLoss += dpDelay(tp)\n",
    "                nnLoss += tpToTotalDelay(tp)\n",
    "                heuristicLoss+= heuristicDelay(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        costSharingLoss /= lenLoss\n",
    "        dpLoss /= lenLoss\n",
    "        nnLoss /= lenLoss\n",
    "        heuristicLoss /= lenLoss\n",
    "        #print(lenLoss)\n",
    "        losslisttemp.append(nnLoss);\n",
    "        recordAndReport(\"NN\", runningLossNN, nnLoss)\n",
    "        recordAndReport(\"CS\", runningLossCS, costSharingLoss)\n",
    "        recordAndReport(\"DP\", runningLossDP, dpLoss)\n",
    "        recordAndReport(\"heuristic\", runningLossHeuristic, heuristicLoss)\n",
    "        print(\"DP:\",dp[n, dpPrecision,0])\n",
    "        #for i in range(n, 0, -1):\n",
    "        #    print(\"Heuristic:\",i,5*(1-dp_H[i, i, dpPrecision]))\n",
    "        for i in range(n, 0, -1):\n",
    "            print(\n",
    "                    tpToPayments(\n",
    "                            torch.tensor([0 if ii >= i else 1 for ii in range(n)], dtype=torch.float32)\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "dpPrecision = 100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def producedata(order):\n",
    "    global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "    dpPrecision = 100 \n",
    "    if(order==\"twopeak\"):\n",
    "        print(\"loc\",doublePeakLowMean, \"scale\",doublePeakStd)\n",
    "        print(\"loc\",doublePeakHighMean, \"scale\",doublePeakStd)\n",
    "        signals = np.random.randint(2, size=(trainSize, n))\n",
    "        samples1 = np.random.normal(\n",
    "            loc=doublePeakLowMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=doublePeakLowMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samples2 = np.random.normal(\n",
    "            loc=doublePeakHighMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "                    samples2[i, j] = np.random.normal(\n",
    "                        loc=doublePeakHighMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samplesJoint = signals * samples1 - (signals - 1) * samples2\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "        # tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "    elif(order==\"normal\"):\n",
    "        print(\"loc\",normalloc, \"scale\",normalscale)\n",
    "        samples1 = np.random.normal(\n",
    "            loc=normalloc, scale=normalscale, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=normalloc, scale=normalscale\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"uniform\"):  \n",
    "        print(\"uniformlow\",uniformlow, \"uniformhigh\",uniformhigh)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        uniformlow, uniformhigh\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"independent1\"):\n",
    "        print(\"loc\",independentnormalloc1,\"scale\",independentnormalscale1)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc1[j], independentnormalscale1[j]\n",
    "                    )\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc1[j], independentnormalscale1[j]\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"independent2\"):\n",
    "        print(\"loc\",independentnormalloc2, \"scale\",independentnormalscale2)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc2[j], independentnormalscale2[j]\n",
    "                    )\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc2[j], independentnormalscale2[j]\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"cauchy\"):\n",
    "        print(\"cauchyloc\",cauchyloc, \"cauchyscale\",cauchyscalen)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = d7.rsample(torch.Size([1]))\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = d7.rsample(torch.Size([1]))\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"beta\"):\n",
    "        print(\"beta_a\",beta_a, \"beta_b\",beta_b)\n",
    "        print(\"kumaraswamy_a\",kumaraswamy_a, \"kumaraswamy_b\",kumaraswamy_b)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = beta.rvs(beta_a,beta_b,  size = 1)\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = beta.rvs(beta_a,beta_b,  size = 1)\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"arcsine\"):\n",
    "        print(\"betalow\",0.5, \"betahigh\",0.5)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = beta.rvs(0.5,0.5,  size = 1)\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = beta.rvs(0.5,0.5,  size = 1)\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"U-exponential\"):\n",
    "        print(\"loc\",doublePeakLowMean, \"scale\",doublePeakStd)\n",
    "        print(\"loc\",doublePeakHighMean, \"scale\",doublePeakStd)\n",
    "        signals = np.random.randint(2, size=(trainSize, n))\n",
    "        samples1 = d81.rsample(torch.Size([trainSize, n])).numpy()\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = d81.rsample(torch.Size([1])).numpy()\n",
    "                    \n",
    "        samples2 = d82.rsample(torch.Size([trainSize, n])).numpy()\n",
    "        \n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "                    samples2[i, j] = d82.rsample(torch.Size([1])).numpy()\n",
    "        samples2 = 1.0 - samples2\n",
    "        samplesJoint = signals * samples1 - (signals - 1.0) * samples2\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "\n",
    "        # tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "        \n",
    "    plt.hist(samplesJoint,bins=500)\n",
    "    plt.show()\n",
    "    \n",
    "    tp_dataset = TensorDataset(tp_tensor[: int(trainSize * percentage_train_test)])\n",
    "    tp_dataset_testing = TensorDataset(tp_tensor[int(trainSize * (1.0-percentage_train_test)) :])\n",
    "    tp_dataloader = DataLoader(tp_dataset, batch_size=128, shuffle=True)\n",
    "    tp_dataloader_testing = DataLoader(tp_dataset_testing, batch_size=256, shuffle=False)\n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp = np.zeros([n + 1, dpPrecision + 1, n + 1])\n",
    "    decision = np.zeros([n + 1, dpPrecision + 1, n + 1], dtype=np.uint8)\n",
    "    # ppl = 0 left\n",
    "    for yes in range(n + 1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            if money == 0:\n",
    "                dp[0, 0, yes] = 0\n",
    "            else:\n",
    "                dp[0, money, yes] = yes# + 1.0\n",
    "    for ppl in range(1,  n + 1):\n",
    "        for yes in range(n + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                minSoFar = 1000000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order==\"beta\"):\n",
    "                        res = (1 - beta_cdf(offer,order)) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes + 1, n)\n",
    "                        ] + beta_cdf(offer,order) * (1 + dp[ppl - 1, money, yes])\n",
    "#                     if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "#                         res = (1 - cdf(offer,order)) * dp[\n",
    "#                         ppl - 1, money - offerIndex, min(yes + 1, n)\n",
    "#                         ] + cdf(offer,order) * (1 + dp[ppl - 1, money, yes])\n",
    "#                     else:\n",
    "#                         res = (1 - cdf(offer,order,n-ppl)) * dp[\n",
    "#                         ppl - 1, money - offerIndex, min(yes + 1, n)\n",
    "#                         ] + cdf(offer,order,n-ppl) * (1 + dp[ppl - 1, money, yes])\n",
    "                    if minSoFar > res.item():\n",
    "                        minSoFar = res.item()\n",
    "                        decision[ppl, money, yes] = offerIndex\n",
    "                dp[ppl, money, yes] = minSoFar\n",
    "    \n",
    "    print(\"dp\",dp[n, dpPrecision, 0])\n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp_H = np.zeros([n + 1 , n + 1, dpPrecision + 1])\n",
    "    decision_H = np.zeros([n + 1 , n + 1, dpPrecision + 1], dtype=np.uint8)\n",
    "    # ppl = 0 left\n",
    "    for i in range(1,n+1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            if money == 0:\n",
    "                dp_H[i, 0, 0] = 1\n",
    "            else:\n",
    "                offer = money / dpPrecision\n",
    "                dp_H[i, 0, money] = 0#cdf(offer)# + 1.0\n",
    "    for i in range(1,n+1):\n",
    "        for ppl in range(1, i + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                maxSoFar = -1000000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                        res = (1-cdf(offer,order)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    else:\n",
    "                        res = (1-cdf(offer,order,ppl-1)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    if maxSoFar < res.item():\n",
    "                        maxSoFar = res.item()\n",
    "                        decision_H[i, ppl, money] = offerIndex\n",
    "                dp_H[i, ppl, money] = maxSoFar\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_a 0.1 beta_b 0.1\n",
      "kumaraswamy_a 0.1 kumaraswamy_b 0.3540388371733616\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp 1.7499999999999998\n",
      "Supervised Aim: beta dp\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.013060\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 0.000330\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 0.000043\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 0.000010\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.000008\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 0.000004\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 0.000007\n",
      "NN 1 : tensor(1.7537)\n",
      "CS 1 : 1.77625\n",
      "DP 1 : 1.746\n",
      "heuristic 1 : 1.7446\n",
      "DP: 1.7499999999999998\n",
      "tensor([0.4959, 0.4993, 0.0048])\n",
      "tensor([0.4990, 0.5010, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 1.953429 testing loss: tensor(1.7516)\n",
      "Train Epoch: 1 [640/20000 (3%)]\tLoss: 1.876658 testing loss: tensor(1.7510)\n",
      "Train Epoch: 1 [1280/20000 (6%)]\tLoss: 1.931598 testing loss: tensor(1.7497)\n",
      "Train Epoch: 1 [1920/20000 (10%)]\tLoss: 1.917419 testing loss: tensor(1.7488)\n",
      "Train Epoch: 1 [2560/20000 (13%)]\tLoss: 1.930192 testing loss: tensor(1.7500)\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 1.927598 testing loss: tensor(1.7502)\n",
      "Train Epoch: 1 [3840/20000 (19%)]\tLoss: 2.008056 testing loss: tensor(1.7497)\n",
      "Train Epoch: 1 [4480/20000 (22%)]\tLoss: 1.955662 testing loss: tensor(1.7492)\n",
      "Train Epoch: 1 [5120/20000 (25%)]\tLoss: 1.890789 testing loss: tensor(1.7481)\n",
      "Train Epoch: 1 [5760/20000 (29%)]\tLoss: 1.952789 testing loss: tensor(1.7492)\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 1.948944 testing loss: tensor(1.7482)\n",
      "Train Epoch: 1 [7040/20000 (35%)]\tLoss: 1.906666 testing loss: tensor(1.7496)\n",
      "Train Epoch: 1 [7680/20000 (38%)]\tLoss: 1.909483 testing loss: tensor(1.7498)\n",
      "Train Epoch: 1 [8320/20000 (41%)]\tLoss: 1.903278 testing loss: tensor(1.7507)\n",
      "Train Epoch: 1 [8960/20000 (45%)]\tLoss: 1.854036 testing loss: tensor(1.7502)\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 1.964826 testing loss: tensor(1.7500)\n",
      "Train Epoch: 1 [10240/20000 (51%)]\tLoss: 1.926853 testing loss: tensor(1.7494)\n",
      "Train Epoch: 1 [10880/20000 (54%)]\tLoss: 1.856826 testing loss: tensor(1.7491)\n",
      "Train Epoch: 1 [11520/20000 (57%)]\tLoss: 1.978646 testing loss: tensor(1.7488)\n",
      "Train Epoch: 1 [12160/20000 (61%)]\tLoss: 1.934089 testing loss: tensor(1.7486)\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 1.725875 testing loss: tensor(1.7484)\n",
      "Train Epoch: 1 [13440/20000 (67%)]\tLoss: 1.947561 testing loss: tensor(1.7467)\n",
      "Train Epoch: 1 [14080/20000 (70%)]\tLoss: 1.942931 testing loss: tensor(1.7473)\n",
      "Train Epoch: 1 [14720/20000 (73%)]\tLoss: 1.862642 testing loss: tensor(1.7474)\n",
      "Train Epoch: 1 [15360/20000 (76%)]\tLoss: 1.935672 testing loss: tensor(1.7483)\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 1.857413 testing loss: tensor(1.7474)\n",
      "Train Epoch: 1 [16640/20000 (83%)]\tLoss: 1.773690 testing loss: tensor(1.7477)\n",
      "Train Epoch: 1 [17280/20000 (86%)]\tLoss: 1.976270 testing loss: tensor(1.7472)\n",
      "Train Epoch: 1 [17920/20000 (89%)]\tLoss: 1.860632 testing loss: tensor(1.7469)\n",
      "Train Epoch: 1 [18560/20000 (92%)]\tLoss: 1.908212 testing loss: tensor(1.7473)\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 1.828661 testing loss: tensor(1.7466)\n",
      "Train Epoch: 1 [19840/20000 (99%)]\tLoss: 1.839633 testing loss: tensor(1.7460)\n",
      "penalty: 0.000982046127319336\n",
      "NN 2 : tensor(1.7457)\n",
      "CS 2 : 1.77625\n",
      "DP 2 : 1.746\n",
      "heuristic 2 : 1.7446\n",
      "DP: 1.7499999999999998\n",
      "tensor([0.5204, 0.4775, 0.0021])\n",
      "tensor([0.5245, 0.4755, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: beta random initializing\n",
      "do nothing\n",
      "NN 1 : tensor(1.7773)\n",
      "CS 1 : 1.77625\n",
      "DP 1 : 1.746\n",
      "heuristic 1 : 1.7446\n",
      "DP: 1.7499999999999998\n",
      "tensor([0.4425, 0.2823, 0.2752])\n",
      "tensor([0.5892, 0.4108, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 1.947034 testing loss: tensor(1.7774)\n",
      "Train Epoch: 1 [640/20000 (3%)]\tLoss: 1.917356 testing loss: tensor(1.7763)\n",
      "Train Epoch: 1 [1280/20000 (6%)]\tLoss: 1.935590 testing loss: tensor(1.7793)\n",
      "Train Epoch: 1 [1920/20000 (10%)]\tLoss: 1.871548 testing loss: tensor(1.7794)\n",
      "Train Epoch: 1 [2560/20000 (13%)]\tLoss: 2.057119 testing loss: tensor(1.7794)\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 1.781986 testing loss: tensor(1.7787)\n",
      "Train Epoch: 1 [3840/20000 (19%)]\tLoss: 1.888673 testing loss: tensor(1.7780)\n",
      "Train Epoch: 1 [4480/20000 (22%)]\tLoss: 1.851272 testing loss: tensor(1.7790)\n",
      "Train Epoch: 1 [5120/20000 (25%)]\tLoss: 1.940501 testing loss: tensor(1.7806)\n",
      "Train Epoch: 1 [5760/20000 (29%)]\tLoss: 1.806986 testing loss: tensor(1.7790)\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 1.906872 testing loss: tensor(1.7799)\n",
      "Train Epoch: 1 [7040/20000 (35%)]\tLoss: 1.975487 testing loss: tensor(1.7785)\n",
      "Train Epoch: 1 [7680/20000 (38%)]\tLoss: 1.888595 testing loss: tensor(1.7767)\n",
      "Train Epoch: 1 [8320/20000 (41%)]\tLoss: 2.017526 testing loss: tensor(1.7770)\n",
      "Train Epoch: 1 [8960/20000 (45%)]\tLoss: 1.958625 testing loss: tensor(1.7778)\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 2.006387 testing loss: tensor(1.7791)\n",
      "Train Epoch: 1 [10240/20000 (51%)]\tLoss: 1.917230 testing loss: tensor(1.7814)\n",
      "Train Epoch: 1 [10880/20000 (54%)]\tLoss: 2.069610 testing loss: tensor(1.7818)\n",
      "Train Epoch: 1 [11520/20000 (57%)]\tLoss: 2.007185 testing loss: tensor(1.7802)\n",
      "Train Epoch: 1 [12160/20000 (61%)]\tLoss: 1.930126 testing loss: tensor(1.7797)\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 1.843225 testing loss: tensor(1.7789)\n",
      "Train Epoch: 1 [13440/20000 (67%)]\tLoss: 1.887520 testing loss: tensor(1.7798)\n",
      "Train Epoch: 1 [14080/20000 (70%)]\tLoss: 1.928186 testing loss: tensor(1.7787)\n",
      "Train Epoch: 1 [14720/20000 (73%)]\tLoss: 1.861957 testing loss: tensor(1.7766)\n",
      "Train Epoch: 1 [15360/20000 (76%)]\tLoss: 1.909891 testing loss: tensor(1.7768)\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 1.934917 testing loss: tensor(1.7768)\n",
      "Train Epoch: 1 [16640/20000 (83%)]\tLoss: 1.875298 testing loss: tensor(1.7754)\n",
      "Train Epoch: 1 [17280/20000 (86%)]\tLoss: 1.929683 testing loss: tensor(1.7770)\n",
      "Train Epoch: 1 [17920/20000 (89%)]\tLoss: 1.855975 testing loss: tensor(1.7761)\n",
      "Train Epoch: 1 [18560/20000 (92%)]\tLoss: 1.981417 testing loss: tensor(1.7778)\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 1.955228 testing loss: tensor(1.7802)\n",
      "Train Epoch: 1 [19840/20000 (99%)]\tLoss: 1.889288 testing loss: tensor(1.7806)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.7805)\n",
      "CS 2 : 1.77625\n",
      "DP 2 : 1.746\n",
      "heuristic 2 : 1.7446\n",
      "DP: 1.7499999999999998\n",
      "tensor([0.4395, 0.2132, 0.3473])\n",
      "tensor([0.6691, 0.3309, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: beta costsharing\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.005102\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 0.000157\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 0.000001\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 0.000000\n",
      "NN 1 : tensor(1.7762)\n",
      "CS 1 : 1.77625\n",
      "DP 1 : 1.746\n",
      "heuristic 1 : 1.7446\n",
      "DP: 1.7499999999999998\n",
      "tensor([0.3333, 0.3334, 0.3333])\n",
      "tensor([0.5000, 0.5000, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 1.985740 testing loss: tensor(1.7766)\n",
      "Train Epoch: 1 [640/20000 (3%)]\tLoss: 1.844676 testing loss: tensor(1.7768)\n",
      "Train Epoch: 1 [1280/20000 (6%)]\tLoss: 1.908199 testing loss: tensor(1.7770)\n",
      "Train Epoch: 1 [1920/20000 (10%)]\tLoss: 1.844978 testing loss: tensor(1.7768)\n",
      "Train Epoch: 1 [2560/20000 (13%)]\tLoss: 2.022465 testing loss: tensor(1.7765)\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 1.946095 testing loss: tensor(1.7772)\n",
      "Train Epoch: 1 [3840/20000 (19%)]\tLoss: 1.930745 testing loss: tensor(1.7768)\n",
      "Train Epoch: 1 [4480/20000 (22%)]\tLoss: 1.860880 testing loss: tensor(1.7770)\n",
      "Train Epoch: 1 [5120/20000 (25%)]\tLoss: 1.904917 testing loss: tensor(1.7767)\n",
      "Train Epoch: 1 [5760/20000 (29%)]\tLoss: 1.813513 testing loss: tensor(1.7776)\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 2.034342 testing loss: tensor(1.7794)\n",
      "Train Epoch: 1 [7040/20000 (35%)]\tLoss: 1.844824 testing loss: tensor(1.7787)\n",
      "Train Epoch: 1 [7680/20000 (38%)]\tLoss: 1.989602 testing loss: tensor(1.7783)\n",
      "Train Epoch: 1 [8320/20000 (41%)]\tLoss: 1.919297 testing loss: tensor(1.7788)\n",
      "Train Epoch: 1 [8960/20000 (45%)]\tLoss: 1.993357 testing loss: tensor(1.7794)\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 1.985386 testing loss: tensor(1.7776)\n",
      "Train Epoch: 1 [10240/20000 (51%)]\tLoss: 2.048754 testing loss: tensor(1.7780)\n",
      "Train Epoch: 1 [10880/20000 (54%)]\tLoss: 1.821165 testing loss: tensor(1.7787)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [11520/20000 (57%)]\tLoss: 1.916285 testing loss: tensor(1.7786)\n",
      "Train Epoch: 1 [12160/20000 (61%)]\tLoss: 1.965903 testing loss: tensor(1.7783)\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 2.017441 testing loss: tensor(1.7774)\n",
      "Train Epoch: 1 [13440/20000 (67%)]\tLoss: 1.987059 testing loss: tensor(1.7773)\n",
      "Train Epoch: 1 [14080/20000 (70%)]\tLoss: 1.978111 testing loss: tensor(1.7771)\n",
      "Train Epoch: 1 [14720/20000 (73%)]\tLoss: 1.941215 testing loss: tensor(1.7771)\n",
      "Train Epoch: 1 [15360/20000 (76%)]\tLoss: 1.945239 testing loss: tensor(1.7772)\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 1.912020 testing loss: tensor(1.7774)\n",
      "Train Epoch: 1 [16640/20000 (83%)]\tLoss: 1.984864 testing loss: tensor(1.7773)\n",
      "Train Epoch: 1 [17280/20000 (86%)]\tLoss: 1.861761 testing loss: tensor(1.7774)\n",
      "Train Epoch: 1 [17920/20000 (89%)]\tLoss: 1.984246 testing loss: tensor(1.7772)\n",
      "Train Epoch: 1 [18560/20000 (92%)]\tLoss: 1.923481 testing loss: tensor(1.7765)\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 1.894631 testing loss: tensor(1.7764)\n",
      "Train Epoch: 1 [19840/20000 (99%)]\tLoss: 1.973025 testing loss: tensor(1.7765)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.7761)\n",
      "CS 2 : 1.77625\n",
      "DP 2 : 1.746\n",
      "heuristic 2 : 1.7446\n",
      "DP: 1.7499999999999998\n",
      "tensor([0.3999, 0.3008, 0.2993])\n",
      "tensor([0.5165, 0.4835, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: beta heuristic\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.028855\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 0.001110\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 0.000055\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 0.000018\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.000009\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 0.000020\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 0.000006\n",
      "NN 1 : tensor(1.7528)\n",
      "CS 1 : 1.77625\n",
      "DP 1 : 1.746\n",
      "heuristic 1 : 1.7446\n",
      "DP: 1.7499999999999998\n",
      "tensor([0.0059, 0.4990, 0.4950])\n",
      "tensor([0.4988, 0.5012, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 2.011512 testing loss: tensor(1.7544)\n",
      "Train Epoch: 1 [640/20000 (3%)]\tLoss: 1.924151 testing loss: tensor(1.7551)\n",
      "Train Epoch: 1 [1280/20000 (6%)]\tLoss: 1.992090 testing loss: tensor(1.7534)\n",
      "Train Epoch: 1 [1920/20000 (10%)]\tLoss: 1.913041 testing loss: tensor(1.7536)\n",
      "Train Epoch: 1 [2560/20000 (13%)]\tLoss: 1.869287 testing loss: tensor(1.7529)\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 1.849437 testing loss: tensor(1.7528)\n",
      "Train Epoch: 1 [3840/20000 (19%)]\tLoss: 1.971377 testing loss: tensor(1.7522)\n",
      "Train Epoch: 1 [4480/20000 (22%)]\tLoss: 1.885126 testing loss: tensor(1.7526)\n",
      "Train Epoch: 1 [5120/20000 (25%)]\tLoss: 1.983688 testing loss: tensor(1.7526)\n",
      "Train Epoch: 1 [5760/20000 (29%)]\tLoss: 1.962507 testing loss: tensor(1.7521)\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 1.993868 testing loss: tensor(1.7516)\n",
      "Train Epoch: 1 [7040/20000 (35%)]\tLoss: 1.960478 testing loss: tensor(1.7507)\n",
      "Train Epoch: 1 [7680/20000 (38%)]\tLoss: 1.964198 testing loss: tensor(1.7508)\n",
      "Train Epoch: 1 [8320/20000 (41%)]\tLoss: 1.819332 testing loss: tensor(1.7507)\n",
      "Train Epoch: 1 [8960/20000 (45%)]\tLoss: 1.771653 testing loss: tensor(1.7500)\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 1.849814 testing loss: tensor(1.7503)\n",
      "Train Epoch: 1 [10240/20000 (51%)]\tLoss: 1.940164 testing loss: tensor(1.7498)\n",
      "Train Epoch: 1 [10880/20000 (54%)]\tLoss: 1.880521 testing loss: tensor(1.7475)\n",
      "Train Epoch: 1 [11520/20000 (57%)]\tLoss: 2.016212 testing loss: tensor(1.7470)\n",
      "Train Epoch: 1 [12160/20000 (61%)]\tLoss: 1.874820 testing loss: tensor(1.7471)\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 1.869877 testing loss: tensor(1.7463)\n",
      "Train Epoch: 1 [13440/20000 (67%)]\tLoss: 1.741990 testing loss: tensor(1.7442)\n",
      "Train Epoch: 1 [14080/20000 (70%)]\tLoss: 1.922035 testing loss: tensor(1.7436)\n",
      "Train Epoch: 1 [14720/20000 (73%)]\tLoss: 1.895649 testing loss: tensor(1.7463)\n",
      "Train Epoch: 1 [15360/20000 (76%)]\tLoss: 2.019866 testing loss: tensor(1.7457)\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 1.904127 testing loss: tensor(1.7456)\n",
      "Train Epoch: 1 [16640/20000 (83%)]\tLoss: 1.972311 testing loss: tensor(1.7457)\n",
      "Train Epoch: 1 [17280/20000 (86%)]\tLoss: 1.929135 testing loss: tensor(1.7436)\n",
      "Train Epoch: 1 [17920/20000 (89%)]\tLoss: 1.815962 testing loss: tensor(1.7455)\n",
      "Train Epoch: 1 [18560/20000 (92%)]\tLoss: 1.913431 testing loss: tensor(1.7486)\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 1.897598 testing loss: tensor(1.7473)\n",
      "Train Epoch: 1 [19840/20000 (99%)]\tLoss: 1.796021 testing loss: tensor(1.7486)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.7476)\n",
      "CS 2 : 1.77625\n",
      "DP 2 : 1.746\n",
      "heuristic 2 : 1.7446\n",
      "DP: 1.7499999999999998\n",
      "tensor([2.7517e-04, 4.4495e-01, 5.5477e-01])\n",
      "tensor([0.1995, 0.8005, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "    \n",
    "for order in stage:\n",
    "    producedata(order)\n",
    "    #running\n",
    "    for order1 in order1name:\n",
    "        print(\"Supervised Aim:\",order,order1)\n",
    "        \n",
    "        # for mapping binary to payments before softmax\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(n, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, n),\n",
    "        )\n",
    "        model.apply(init_weights)\n",
    "        # optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr1)\n",
    "        \n",
    "        runningLossNN = []\n",
    "        runningLossCS = []\n",
    "        runningLossDP = []\n",
    "        runningLossHeuristic = []\n",
    "        #model=torch.load(\"save/pytorchNN=5dp1\");\n",
    "        #model.eval()\n",
    "        ##order1name=[\"costsharing\",\"dp\",\"heuristic\",\"random initializing\"]\n",
    "        for epoch in range(1, supervisionEpochs + 1):\n",
    "#             print(\"distributionRatio\",distributionRatio)\n",
    "            if(order1==\"costsharing\"):\n",
    "                supervisionTrain(epoch, costSharingSupervisionRule)\n",
    "            elif(order1==\"dp\"):\n",
    "                supervisionTrain(epoch, dpSupervisionRule)\n",
    "            elif(order1==\"heuristic\"):\n",
    "                supervisionTrain(epoch, heuristicSupervisionRule)\n",
    "            elif(order1==\"random initializing\"):\n",
    "                print(\"do nothing\");\n",
    "\n",
    "        test()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr2)\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train(epoch)\n",
    "            test()\n",
    "        losslistname.append(order+\" \"+order1);\n",
    "        losslist.append(losslisttemp);\n",
    "        losslisttemp=[];\n",
    "        savepath=\"save/pytorchNN=5all-beta\"+order+str(order1)\n",
    "        torch.save(model, savepath);\n",
    "        print(\"end\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colorlist=[\"#D2691E\",'#4169E1',\"#9ACD32\",\"#B22222\",\"#FF00FF\",\"#708090\"]\n",
    "for i in range(len(losslist)):\n",
    "    plt.plot(losslist[i], '.-', color=colorlist[i], alpha=0.8, label=losslistname[i])\n",
    "\n",
    "# 显示标签，如果不加这句，即使加了label='一些数字'的参数，最终还是不会显示标签\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Trianing Times')\n",
    "plt.ylabel('Delay')\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('pytorchNN=3_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
