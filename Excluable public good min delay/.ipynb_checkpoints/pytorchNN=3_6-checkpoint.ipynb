{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40058530825361593\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from random import randint\n",
    "import random\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "from pylab import *\n",
    "from scipy.stats import beta\n",
    "import math\n",
    "n = 3\n",
    "epochs = 1\n",
    "supervisionEpochs = 1\n",
    "lr1 = 0.01\n",
    "lr2 = 0.0005\n",
    "log_interval = 5\n",
    "trainSize = 40000#100000\n",
    "percentage_train_test= 0.5\n",
    "penaltyLambda = 10\n",
    "doublePeakHighMean = 0.85\n",
    "doublePeakLowMean = 0.15\n",
    "doublePeakStd = 0.1\n",
    "uniformlow=0\n",
    "uniformhigh=1.0\n",
    "normalloc = 0.2\n",
    "normalscale = 0.1\n",
    "\n",
    "cauchyloc = 1/n\n",
    "cauchyscalen = 0.004\n",
    "\n",
    "exponentialhigh = 15 #Symbol(\"b\", real=True)\n",
    "exponentiallow  = 15 #Symbol(\"a\", real=True)\n",
    "\n",
    "\n",
    "beta_a = 0.3\n",
    "beta_b  = 0.2\n",
    "kumaraswamy_a = beta_a \n",
    "kumaraswamy_b = (1.0+(beta_a-1.0)*math.pow( (beta_a+beta_b-2.0)/(beta_a-1.0), beta_a) )/beta_a \n",
    "print(kumaraswamy_b)\n",
    "\n",
    "\n",
    "independentnormalloc1=[(float(ii)+1)/(2*n+1) for ii in range(n,0,-1)]\n",
    "independentnormalscale1=[0.05 for ii in range(n)]\n",
    "\n",
    "independentnormalloc2=[(float(ii)+1)/(2*n+1) for ii in range(1,n+1,1)]\n",
    "independentnormalscale2=[0.05 for ii in range(n)]\n",
    "stage=[\"twopeak\"]\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"beta\",\"U-exponential\",\"arcsine\"\n",
    "order1name=[\"dp\",\"random initializing\",\"costsharing\",\"heuristic\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = D.normal.Normal(doublePeakLowMean, doublePeakStd)\n",
    "d2 = D.normal.Normal(doublePeakHighMean, doublePeakStd)\n",
    "distributionRatio1 = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase1 = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(normalloc, normalscale)\n",
    "distributionRatio3 = d3.cdf(1) - d3.cdf(0)\n",
    "distributionBase3 = d3.cdf(0)\n",
    "\n",
    "d4 = D.uniform.Uniform(uniformlow,uniformhigh)\n",
    "distributionRatio4 = d4.cdf(1) - d4.cdf(0)\n",
    "distributionBase4 = d4.cdf(0)\n",
    "\n",
    "d5 = [D.normal.Normal(independentnormalloc1[ii], independentnormalscale1[ii]) for ii in range(n)]\n",
    "d6 = [D.normal.Normal(independentnormalloc2[ii], independentnormalscale2[ii]) for ii in range(n)]\n",
    "\n",
    "d7 = D.cauchy.Cauchy(cauchyloc,cauchyscalen)\n",
    "\n",
    "d81 = D.exponential.Exponential(exponentiallow)\n",
    "d82 = D.exponential.Exponential(exponentialhigh)\n",
    "\n",
    "d9 = D.beta.Beta(beta_a,beta_b)\n",
    "#sample_d9=d9.rsample(torch.Size([100000]))\n",
    "\n",
    "#d9_sample=np.linspace(0.0001, 0.9999, 10000)\n",
    "#d9_pdf=torch.exp(d9.log_prob(torch.tensor(d9_sample,dtype=torch.float32)))\n",
    "#d9_delta=d9_sample[1]-d9_sample[0]\n",
    "#d9_sum_pdf=torch.sum(d9_pdf*d9_delta)\n",
    "\n",
    "d10 = D.beta.Beta(0.5,0.5)\n",
    "\n",
    "def cdf(x,y, i=None):\n",
    "    if(y==\"twopeak\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) - distributionBase1) / 2 / distributionRatio1\n",
    "    elif(y==\"normal\"):\n",
    "        return (d3.cdf(x)-distributionBase3)/distributionRatio3;\n",
    "    elif(y==\"uniform\"):\n",
    "        return (d4.cdf(x)-distributionBase4)/distributionRatio4;\n",
    "    elif(y==\"independent1\"):\n",
    "        return d5[i].cdf(x);\n",
    "    elif(y==\"independent2\"):\n",
    "        return d6[i].cdf(x);\n",
    "    elif(y==\"cauchy\"):\n",
    "        return d7.cdf(x);\n",
    "    elif(y==\"beta\"):\n",
    "#         sum_cdf=0.0;\n",
    "#         if(x<0.0001):\n",
    "#             x=0.00011;\n",
    "#         if(x>0.9999):\n",
    "#             x=0.99989;\n",
    "#         for i in range(len(d9_pdf)):\n",
    "#             if(d9_sample[i]<x):\n",
    "#                 sum_cdf+=d9_pdf[i]*d9_delta;\n",
    "#             else:\n",
    "#                 sum_cdf+=(d9_pdf[i]+d9_pdf[i-1])/ 2 *(x-d9_sample[i-1])\n",
    "#                 break;\n",
    "#         return sum_cdf/d9_sum_pdf\n",
    "#         cdf_v=torch.sum((sample_d9<(x)), dtype=torch.float32)/100000\n",
    "#         return cdf_v\n",
    "#    F(x|a,b)=1–(1–x^a)^b\n",
    "        if(x<0.0000001):\n",
    "            x=0.0000001\n",
    "        elif(x >0.9999999):\n",
    "            x=0.9999999\n",
    "        try:\n",
    "            return 1.0-torch.pow(1.0-torch.pow(x,kumaraswamy_a),kumaraswamy_b);\n",
    "        except:\n",
    "            return 1.0-torch.pow(1.0-torch.pow(torch.tensor(x,dtype=torch.float32),kumaraswamy_a),kumaraswamy_b);\n",
    "    elif(y==\"arcsine\"):\n",
    "        #\n",
    "        if(x<0.0000001):\n",
    "            x=0.0000001\n",
    "        elif(x >0.9999999):\n",
    "            x=0.9999999\n",
    "        try:\n",
    "            res=2.0/math.pi * torch.asin(torch.sqrt(x))\n",
    "            #print(x)\n",
    "            return res# + 0.0001*1.0/(\n",
    "            #math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "        except:\n",
    "            return 2.0/math.pi * torch.asin(torch.sqrt(torch.tensor(x,dtype=torch.float32)))# + 0.0001*1.0/(\n",
    "            #math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "    elif(y==\"U-exponential\"):\n",
    "        return (d81.cdf(x) + (1.0 - d82.cdf(1.0-x)))  / 2 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    if torch.sum(bits).item() == 0:\n",
    "        return torch.ones(n)\n",
    "    bits = bits.type(torch.float32)\n",
    "    negBits = torch.ones(n) - bits\n",
    "    payments = model(bits)\n",
    "    payments = payments - 1000 * negBits\n",
    "    payments = torch.softmax(payments, 0)\n",
    "    payments = payments + negBits\n",
    "    return payments\n",
    "\n",
    "def tpToBits(tp, bits=torch.ones(n).type(torch.uint8)):\n",
    "    payments = bitsToPayments(bits)\n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return tpToBits(tp, newBits)#bits-bits#tpToBits(tp, newBits)\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp))\n",
    "\n",
    "\n",
    "def tpToTotalDelay(tp):\n",
    "    return n - torch.sum(tpToBits(tp).type(torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpSupervisionRule(tp):\n",
    "    global  dp,decision\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    money = dpPrecision\n",
    "    yes = 0\n",
    "    for i in range(n):\n",
    "        offerIndex = decision[n - i, money, yes]\n",
    "        offer = float(offerIndex) / dpPrecision\n",
    "        if tp[i] >= offer:\n",
    "            money -= offerIndex\n",
    "            yes += 1\n",
    "            bits[i] = 1\n",
    "            payments[i] = offer\n",
    "        else:\n",
    "            bits[i] = 0\n",
    "            payments[i] = 1\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "#     print()\n",
    "#     print(tp)\n",
    "#     print(bits)\n",
    "#     print(payments)\n",
    "#     print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def heuristicSupervisionRule(tp):\n",
    "    global  dp_H,decision_H\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    tempold=-1;\n",
    "    for turns in range(n,0,-1):\n",
    "        money = dpPrecision\n",
    "        j=0\n",
    "        tempo=sum(bits)\n",
    "        #print(\"bits\",tempo)\n",
    "        for i in range(n):\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            \n",
    "            offerIndex = decision_H[tempo ,tempo - i, money]\n",
    "            offer = float(offerIndex) / dpPrecision\n",
    "            while(j<n):\n",
    "                if(bits[j]!=0):\n",
    "                    break;\n",
    "                j+=1;\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            if tp[j] >= offer:\n",
    "                #print(money,j,tp[j],offer)\n",
    "                money -= offerIndex\n",
    "                bits[j] = 1\n",
    "                payments[j] = offer\n",
    "            else:\n",
    "                bits[j] = 0;\n",
    "                payments[j] = 1.0;\n",
    "            j+=1;\n",
    "        #print(\"money\",money)\n",
    "        if(money==0 and tempold==tempo):\n",
    "            break;\n",
    "        tempold=tempo;\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "\n",
    "    bits = torch.tensor(bits, dtype=torch.float32)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    # print()\n",
    "    # print(tp)\n",
    "    # print(bits)\n",
    "    # print(payments)\n",
    "    # print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "\n",
    "def costSharingSupervisionRule(tp):\n",
    "    tp = list(tp.numpy())\n",
    "    for k in range(n, -1, -1):\n",
    "        if k == 0:\n",
    "            break\n",
    "        bits = [1 if tp[ii] >= 1.0 / k else 0 for ii in range(n)]\n",
    "        if sum(bits) == k:\n",
    "            break\n",
    "    if k == 0:\n",
    "        payments = [1 for ii in range(n)]\n",
    "    else:\n",
    "        payments = [1.0 / k if bits[ii] == 1 else 1 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def costSharingDelay(tp):\n",
    "    return float(n - torch.sum(costSharingSupervisionRule(tp)[0]).item())\n",
    "\n",
    "def dpDelay(tp):\n",
    "    return float(n - torch.sum(dpSupervisionRule(tp)[0]).item())\n",
    "\n",
    "def heuristicDelay(tp):\n",
    "    return float(n - torch.sum(heuristicSupervisionRule(tp)[0]).item())\n",
    "\n",
    "\n",
    "# templire=0;\n",
    "# num=1\n",
    "# for i in range(num):\n",
    "#     temp=torch.tensor(samplesJoint[i])\n",
    "#     #print(temp)\n",
    "#     #print(temp);\n",
    "#     #print(heuristicSupervisionRule(temp))\n",
    "#     #print(dpSupervisionRule(temp))\n",
    "#     #print(dpDelay(temp))\n",
    "#     res=dpDelay(temp)\n",
    "#     templire+=res\n",
    "#     #print(\"Delay\",res)\n",
    "#     #print()\n",
    "# print(templire/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordAndReport(name, source, loss):\n",
    "    source.append(loss)\n",
    "    realLength = len(source)\n",
    "    #print(f\"{name} ({realLength}): {loss}\")\n",
    "    print(name,realLength,\":\" ,loss)\n",
    "\n",
    "def supervisionTrain(epoch, supervisionRule):\n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    \n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss = penalty * penaltyLambda /100000\n",
    "        \n",
    "        for tp in tp_batch:\n",
    "            bits, payments = supervisionRule(tp)\n",
    "            loss = loss + F.mse_loss(bitsToPayments(bits), payments)\n",
    "\n",
    "        loss = loss / len(tp_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % (log_interval*5) == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "losslist=[];\n",
    "losslistname=[];\n",
    "losslisttemp=[];\n",
    "def test_batch():\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        lenLoss= 0\n",
    "        nnLoss = 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "            for tp in tp_batch:\n",
    "                nnLoss += tpToTotalDelay(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        nnLoss/=lenLoss\n",
    "    return nnLoss\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    global losslisttemp; \n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss = penalty * penaltyLambda\n",
    "        for tp in tp_batch:\n",
    "            for i in range(n):\n",
    "                tp1 = tp.clone()\n",
    "                tp1[i] = 1\n",
    "                tp0 = tp.clone()\n",
    "                tp0[i] = 0\n",
    "                offer = tpToPayments(tp1)[i]\n",
    "                Delay1 = tpToTotalDelay(tp1)\n",
    "                Delay0 = tpToTotalDelay(tp0)\n",
    "                if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                    loss = loss + (1 - cdf(offer,order)) * Delay1 + cdf(offer,order) * Delay0\n",
    "                else:\n",
    "                    loss = loss + (1 - cdf(offer,order,i)) * Delay1 + cdf(offer,order,i) * Delay0\n",
    "\n",
    "        loss = loss / len(tp_batch) / n\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            losstemp=test_batch();\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                ),\"testing loss:\",losstemp\n",
    "            )\n",
    "            losslisttemp.append(losstemp);\n",
    "            \n",
    "    print(\"penalty:\",penalty.item())\n",
    "    \n",
    "allBits = [torch.tensor(bits, dtype=torch.int16) for bits in itertools.product([0, 1], repeat=n)]\n",
    "\n",
    "def test():\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        costSharingLoss = 0\n",
    "        dpLoss = 0\n",
    "        nnLoss = 0\n",
    "        heuristicLoss=0\n",
    "        lenLoss= 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "\n",
    "            for tp in tp_batch:\n",
    "                costSharingLoss += costSharingDelay(tp)\n",
    "                dpLoss += dpDelay(tp)\n",
    "                nnLoss += tpToTotalDelay(tp)\n",
    "                heuristicLoss+= heuristicDelay(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        costSharingLoss /= lenLoss\n",
    "        dpLoss /= lenLoss\n",
    "        nnLoss /= lenLoss\n",
    "        heuristicLoss /= lenLoss\n",
    "        #print(lenLoss)\n",
    "        losslisttemp.append(nnLoss);\n",
    "        recordAndReport(\"NN\", runningLossNN, nnLoss)\n",
    "        recordAndReport(\"CS\", runningLossCS, costSharingLoss)\n",
    "        recordAndReport(\"DP\", runningLossDP, dpLoss)\n",
    "        recordAndReport(\"heuristic\", runningLossHeuristic, heuristicLoss)\n",
    "        print(\"DP:\",dp[n, dpPrecision,0])\n",
    "        #for i in range(n, 0, -1):\n",
    "        #    print(\"Heuristic:\",i,5*(1-dp_H[i, i, dpPrecision]))\n",
    "        for i in range(n, 0, -1):\n",
    "            print(\n",
    "                    tpToPayments(\n",
    "                            torch.tensor([0 if ii >= i else 1 for ii in range(n)], dtype=torch.float32)\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "dpPrecision = 100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def producedata(order):\n",
    "    global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "    dpPrecision = 100 \n",
    "    if(order==\"twopeak\"):\n",
    "        print(\"loc\",doublePeakLowMean, \"scale\",doublePeakStd)\n",
    "        print(\"loc\",doublePeakHighMean, \"scale\",doublePeakStd)\n",
    "        signals = np.random.randint(2, size=(trainSize, n))\n",
    "        samples1 = np.random.normal(\n",
    "            loc=doublePeakLowMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=doublePeakLowMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samples2 = np.random.normal(\n",
    "            loc=doublePeakHighMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "                    samples2[i, j] = np.random.normal(\n",
    "                        loc=doublePeakHighMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samplesJoint = signals * samples1 - (signals - 1) * samples2\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "        # tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "    elif(order==\"normal\"):\n",
    "        print(\"loc\",normalloc, \"scale\",normalscale)\n",
    "        samples1 = np.random.normal(\n",
    "            loc=normalloc, scale=normalscale, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=normalloc, scale=normalscale\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"uniform\"):  \n",
    "        print(\"uniformlow\",uniformlow, \"uniformhigh\",uniformhigh)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        uniformlow, uniformhigh\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"independent1\"):\n",
    "        print(\"loc\",independentnormalloc1,\"scale\",independentnormalscale1)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc1[j], independentnormalscale1[j]\n",
    "                    )\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc1[j], independentnormalscale1[j]\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"independent2\"):\n",
    "        print(\"loc\",independentnormalloc2, \"scale\",independentnormalscale2)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc2[j], independentnormalscale2[j]\n",
    "                    )\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc2[j], independentnormalscale2[j]\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"cauchy\"):\n",
    "        print(\"cauchyloc\",cauchyloc, \"cauchyscale\",cauchyscalen)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = d7.rsample(torch.Size([1]))\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = d7.rsample(torch.Size([1]))\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"beta\"):\n",
    "        print(\"beta_a\",beta_a, \"beta_b\",beta_b)\n",
    "        print(\"kumaraswamy_a\",kumaraswamy_a, \"kumaraswamy_b\",kumaraswamy_b)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = beta.rvs(beta_a,beta_b,  size = 1)\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = beta.rvs(beta_a,beta_b,  size = 1)\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"arcsine\"):\n",
    "        print(\"betalow\",0.5, \"betahigh\",0.5)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = beta.rvs(0.5,0.5,  size = 1)\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = beta.rvs(0.5,0.5,  size = 1)\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"U-exponential\"):\n",
    "        print(\"loc\",doublePeakLowMean, \"scale\",doublePeakStd)\n",
    "        print(\"loc\",doublePeakHighMean, \"scale\",doublePeakStd)\n",
    "        signals = np.random.randint(2, size=(trainSize, n))\n",
    "        samples1 = d81.rsample(torch.Size([trainSize, n])).numpy()\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = d81.rsample(torch.Size([1])).numpy()\n",
    "                    \n",
    "        samples2 = d82.rsample(torch.Size([trainSize, n])).numpy()\n",
    "        \n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "                    samples2[i, j] = d82.rsample(torch.Size([1])).numpy()\n",
    "        samples2 = 1.0 - samples2\n",
    "        samplesJoint = signals * samples1 - (signals - 1.0) * samples2\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "\n",
    "        # tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "        \n",
    "    plt.hist(samplesJoint,bins=500)\n",
    "    plt.show()\n",
    "    \n",
    "    tp_dataset = TensorDataset(tp_tensor[: int(trainSize * percentage_train_test)])\n",
    "    tp_dataset_testing = TensorDataset(tp_tensor[int(trainSize * (1.0-percentage_train_test)) :])\n",
    "    tp_dataloader = DataLoader(tp_dataset, batch_size=128, shuffle=True)\n",
    "    tp_dataloader_testing = DataLoader(tp_dataset_testing, batch_size=256, shuffle=False)\n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp = np.zeros([n + 1, dpPrecision + 1, n + 1])\n",
    "    decision = np.zeros([n + 1, dpPrecision + 1, n + 1], dtype=np.uint8)\n",
    "    # ppl = 0 left\n",
    "    for yes in range(n + 1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            if money == 0:\n",
    "                dp[0, 0, yes] = 0\n",
    "            else:\n",
    "                dp[0, money, yes] = yes# + 1.0\n",
    "    for ppl in range(1,  n + 1):\n",
    "        for yes in range(n + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                minSoFar = 1000000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                        res = (1 - cdf(offer,order)) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes + 1, n)\n",
    "                        ] + cdf(offer,order) * (1 + dp[ppl - 1, money, yes])\n",
    "                    else:\n",
    "                        res = (1 - cdf(offer,order,n-ppl)) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes + 1, n)\n",
    "                        ] + cdf(offer,order,n-ppl) * (1 + dp[ppl - 1, money, yes])\n",
    "                    if minSoFar > res.item():\n",
    "                        minSoFar = res.item()\n",
    "                        decision[ppl, money, yes] = offerIndex\n",
    "                dp[ppl, money, yes] = minSoFar\n",
    "    \n",
    "    print(\"dp\",dp[n, dpPrecision, 0])\n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp_H = np.zeros([n + 1 , n + 1, dpPrecision + 1])\n",
    "    decision_H = np.zeros([n + 1 , n + 1, dpPrecision + 1], dtype=np.uint8)\n",
    "    # ppl = 0 left\n",
    "    for i in range(1,n+1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            if money == 0:\n",
    "                dp_H[i, 0, 0] = 1\n",
    "            else:\n",
    "                offer = money / dpPrecision\n",
    "                dp_H[i, 0, money] = 0#cdf(offer)# + 1.0\n",
    "    for i in range(1,n+1):\n",
    "        for ppl in range(1, i + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                maxSoFar = -1000000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                        res = (1-cdf(offer,order)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    else:\n",
    "                        res = (1-cdf(offer,order,ppl-1)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    if maxSoFar < res.item():\n",
    "                        maxSoFar = res.item()\n",
    "                        decision_H[i, ppl, money] = offerIndex\n",
    "                dp_H[i, ppl, money] = maxSoFar\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc 0.15 scale 0.1\n",
      "loc 0.85 scale 0.1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAATrUlEQVR4nO3df4xlZ33f8fenXkBNIcbEY8uyTceghcZ0YUmnDioFmbgUY1UYoiS1Gzlb6mqDiito8geGSsVSZYm2IVQVBbQEyxsJbFxsiiOTNJab4qIA7pisd9cYh7VxYPHKO0AEKESudv3tH3OWXtZ3du7MPffHOff9kkZz73POnft9du985jnP+ZWqQpLUL39j1gVIktpnuEtSDxnuktRDhrsk9ZDhLkk9tGPWBQCce+65tby8POsyJKlTHnzwwe9W1dKwZXMR7svLy6yurs66DEnqlCR/sdEyp2UkqYcMd0nqIcNdknrIcJekHjLcJamHDHdJ6iHDXZJ6yHCXpB4y3CWphwx3Seohw12Seshwl6QeMtwlqYcMd0nqoU3DPcnFSf4kySNJHk7yrqb9RUnuTfKN5vs5A695b5IjSR5N8qZJdkCS9GyjjNxPAL9dVT8PvAZ4Z5JLgRuB+6pqJ3Bf85xm2TXAK4ArgY8kOWsSxUuShts03KvqWFV9tXn8I+AR4ELgamB/s9p+4K3N46uB26vq6ar6JnAEuKztwiVJG9vSnHuSZeDVwFeA86vqGKz/AQDOa1a7EPj2wMuONm2n/6y9SVaTrK6trW29cknShkYO9yTPB+4E3l1VPzzTqkPa6lkNVfuqaqWqVpaWht4CUJK0TSOFe5LnsB7sn6yqu5rmp5Jc0Cy/ADjetB8FLh54+UXAk+2UK0kaxShHywT4BPBIVf3uwKK7gT3N4z3A5wbar0nyvCSXADuBB9orWZK0mR0jrPNa4DrgUJIDTdv7gA8AdyS5HvgW8KsAVfVwkjuAr7F+pM07q+pk65VLkja0abhX1RcZPo8OcMUGr7kZuHmMuiRJY/AMVUnqIcNdUu8s33jPrEuYOcNdknrIcJekHjLcJamHDHdJ6iHDXZJ6yHCXpB4y3FvmIViS5oHhLkk9ZLhLUg8Z7pLUQ4a7pLky9n6rm85up5COM9xnxQ+gtG0euLA5w12SemiUOzHdkuR4ksMDbZ9OcqD5euLUTTySLCf564FlH5tk8ZKk4Ua5E9OtwIeB3z/VUFX/9NTjJB8EfjCw/mNVtbutAiVJWzfKnZjuT7I8bFlzf9VfA36p3bIkSeMYd879dcBTVfWNgbZLkvxZki8ked2YP3+h7Nq/a9YlSJ3h78uZjRvu1wK3DTw/Bry4ql4N/BbwqSQ/O+yFSfYmWU2yura2NmYZPeJRNJJasO1wT7ID+GXg06faqurpqvpe8/hB4DHgZcNeX1X7qmqlqlaWlpa2W4YkaYhxRu7/CPh6VR091ZBkKclZzeOXADuBx8crsT/cjJQ0LaMcCnkb8CXg5UmOJrm+WXQNPz0lA/B64GCSh4DPAO+oqu+3WXDXnCnQPRFD2obtTl0u2JTnKEfLXLtB+z8f0nYncOf4ZUmSxuEZqhPg9IukWTPcJS2sPg/EDHdJ82/B5svbYLh3gR9sSVtkuHeQR9lI2ozhLqm73KrdkOEuST1kuLfAaRJJ88Zwl9Rrizr4Mtwlzac25tMXeE7ecG+T17yQWnX6qLvPJx21zXCfskXdRJTmXs8GWYZ7S7z6o6R5YrhLUg8Z7l3Ws81IyTn19hju27TpVEvLwbvR+znlI61r9XehBwOnUe7EdEuS40kOD7TdlOQ7SQ40X1cNLHtvkiNJHk3ypkkVLklbtUiDoVFG7rcCVw5p/1BV7W6+Pg+Q5FLWb7/3iuY1Hzl1T1Wd2dgfuh6MNCS1Z9Nwr6r7gVHvg3o1cHtVPV1V3wSOAJeNUd9CW6RRhjQtizKvP86c+w1JDjbTNuc0bRcC3x5Y52jT9ixJ9iZZTbK6trY2RhkLxhG6tGWLEuiDthvuHwVeCuwGjgEfbNozZN0a9gOqal9VrVTVytLS0jbLkCQNs61wr6qnqupkVT0DfJz/P/VyFLh4YNWLgCfHK7HfNhpRLOJIQ1J7thXuSS4YePo24NSRNHcD1yR5XpJLgJ3AA+OVKKmvtrJfyX1QW7NjsxWS3AZcDpyb5CjwfuDyJLtZn3J5AvhNgKp6OMkdwNeAE8A7q+rkZEqXJG1k03CvqmuHNH/iDOvfDNw8TlGSpPF4hqqk2RvzKLBx9lH1dbrHcN8Gd3ZKmneG+7g87lzasnkeIM1zbVthuEuanjkfDPVpisZw38ycfxglaRjDvQf6shkpqT2GuySdSUe33g33LejTfJy00Doa2FthuG/AIJfUZYa7pIk702DJfUaTYbhLUg8Z7h3laEeaH/M4jWu4j8gwldQlhrsk9ZDhLkk9ZLhLUg9tGu5JbklyPMnhgbb/lOTrSQ4m+WySFzbty0n+OsmB5utjkyx+Epxbl9QHo4zcbwWuPK3tXuDvVtUrgT8H3juw7LGq2t18vaOdMrUV87jnXtJ0bRruVXU/8P3T2v64qk40T78MXDSB2iRJ29TGnPu/AP5w4PklSf4syReSvG6jFyXZm2Q1yera2loLZbTPKRppcXV9C3iscE/yb4ETwCebpmPAi6vq1cBvAZ9K8rPDXltV+6pqpapWlpaWxilDkqajQxcc23a4J9kD/BPg16uqAKrq6ar6XvP4QeAx4GVtFCpJGt22wj3JlcB7gLdU1Y8H2peSnNU8fgmwE3i8jUIlSaMb5VDI24AvAS9PcjTJ9cCHgRcA9552yOPrgYNJHgI+A7yjqr4/9AfPmw5tbknSZnZstkJVXTuk+RMbrHsncOe4RUnSPNi1fxeHZl3ENnmG6oCu7x1/FrdGNM/8fE6U4d4zHr6peeNncjYM90XhKElaKIa7JPXQYob7Ao9i3USWFsNihvtmFjj8JfWD4S5JW9SFLWDDXZJ6aOHDvXfHtksShrskbWr5xns6MRUzyHCXpHHM6QEYhrukqerLVOi898NwXyDz/mFUD8zpKHYRGe6SWtG1Oem+M9wlqYcM955zKkZaTKPciemWJMeTHB5oe1GSe5N8o/l+zsCy9yY5kuTRJG+aVOGSpI2NMnK/FbjytLYbgfuqaidwX/OcJJcC1wCvaF7zkVP3VJ1HzhFK6qtNw72q7gdOvw/q1cD+5vF+4K0D7bdX1dNV9U3gCHBZS7VK6ggHTrO33Tn386vqGEDz/bym/ULg2wPrHW3aniXJ3iSrSVbX1ta2WYakeeX+ntlqe4dqhrTVsBWral9VrVTVytLSUstlDOHxt9LEGOTzZ7vh/lSSCwCa78eb9qPAxQPrXQQ8uf3yJEnbsd1wvxvY0zzeA3xuoP2aJM9LcgmwE3hgvBLVOrdipN7bsdkKSW4DLgfOTXIUeD/wAeCOJNcD3wJ+FaCqHk5yB/A14ATwzqo6OaHaJUkb2DTcq+raDRZdscH6NwM3j1OUJGk8C3GGqodlSVo0CxHukjRp8zaINNwlqUXzclio4S5JbZmjI9EMd0nqod6H+7xsIknSNPU+3DWcf/SkyZmHnasLF+7z8I8+L/y3kPpr4cJdG3M0L/WH4S5JPWS4S1IPGe6SNEXTmv403BfdHJ10oQ7xczOyWR24YLhLUg8Z7pK2bdf+XY7i55ThLkk9tO1wT/LyJAcGvn6Y5N1JbkrynYH2q9osWJI6YcZbNJveiWkjVfUosBsgyVnAd4DPAm8HPlRVv9NKhZKkLWtrWuYK4LGq+ouWfp4kaQxthfs1wG0Dz29IcjDJLUnOGfaCJHuTrCZZXVtba6kMSRK0EO5Jngu8BfhvTdNHgZeyPmVzDPjgsNdV1b6qWqmqlaWlpXHLGM69+JIWVBsj9zcDX62qpwCq6qmqOllVzwAfBy5r4T0kzdjpJ+N4obn51ka4X8vAlEySCwaWvQ043MJ7jM7R+rb81C+u/4ZSu2bwOzVWuCf5GeCNwF0Dzf8xyaEkB4E3AP9mnPeQpL6Y5qUIxgr3qvpxVf1cVf1goO26qtpVVa+sqrdU1bHxy9waNxclLTrPUJWkGZnkQNRwl7Qhrx3TXYa7JPVQb8Pdmz9L7XN/Vnf0NtwlaZEZ7tqQWz9SdxnuktRDhruGcm5V6jbDXZJ6yHCXpB4y3DU6T2aROsNwl6Qe6kW4e8ieJP20XoQ7eHTHxNx0tv+2Ugf1JtwltcMt4SmZ8D4sw12SemjHOC9O8gTwI+AkcKKqVpK8CPg0sAw8AfxaVf3leGVKkraijZH7G6pqd1WtNM9vBO6rqp3Afc1zddzgprqb7f31k/0rHvbaeZOYlrka2N883g+8dQLvoVnzl1+aa+OGewF/nOTBJHubtvNP3Te1+X7esBcm2ZtkNcnq2tramGVIkgaNNecOvLaqnkxyHnBvkq+P+sKq2gfsA1hZWakx65AkDRhr5F5VTzbfjwOfBS4DnkpyAUDz/fi4RUqStmbb4Z7kbyV5wanHwD8GDgN3A3ua1fYAnxu3SEnS1owzcj8f+GKSh4AHgHuq6o+ADwBvTPIN4I3Nc0nzyB3jvbXtOfeqehx41ZD27wFXjFOUpHbt2r+LQ3sOzboMTZFnqGpLvM5M951+noL/p/1kuEvyxLQeMtylBeRovf8Md43NU9al+WO4S1IPGe6S1EOGu1q1fOM97pyT5oDhrslw/r17/D/rFcNdknrIcJekHjLcNRbn16X5ZLhLUg8Z7poYz4KUZsdwl/ps8AgYj4ZZKIa7Jso5eWk2DHdJ6qFxbrN3cZI/SfJIkoeTvKtpvynJd5IcaL6uaq9cdZLTAdLUbftOTMAJ4Ler6qvNvVQfTHJvs+xDVfU745cnSdqOcW6zdww41jz+UZJHgAvbKkyStH2tzLknWQZeDXylabohycEktyQ5Z4PX7E2ymmR1bW2tjTKkhTe4A9ud2Ytt7HBP8nzgTuDdVfVD4KPAS4HdrI/sPzjsdVW1r6pWqmplaWlp3DIkSQPGCvckz2E92D9ZVXcBVNVTVXWyqp4BPg5cNn6ZkjbjSWMaNM7RMgE+ATxSVb870H7BwGpvAw5vvzwtEqcRWnLT2Qa9xjpa5rXAdcChJAeatvcB1ybZDRTwBPCbY1UoSdqycY6W+SKQIYs+v/1y1Ge79u/i0J5Dsy6jn246G/jUrKvQHPEMVc2MUwfS5Bjumgnn16XJMtw1XV6KQJoKw12Seshwl7rGrR+NwHDXXHDnqtQuw11zx6BvjDBC999KGzHcNb+cfjgjjzjSmRju0hw6FdyDI/PlG+8x0DUyw12zN2SEboidxq0YbZHhrvliiEmtMNylGXMrRZNguGvu9TH8ztSn04+A6WP/NXmGuzrn9J2MneK0k6bEcFfn7dq/6yc3qHCUK60z3NVdXRkFb1RnV+pXJ00s3JNcmeTRJEeS3Dip99GCaIJwqyPzUaZtJjK1c4bgHvZ+P2kz8NWSiYR7krOA/wq8GbiU9VvvXTqJ95KeZYM/BJPeUbnZz3PKSNM0qZH7ZcCRqnq8qv4vcDtw9YTeS9qawRtID/lDsGv/ruGj+dPm9bcyx9+5Hb/qvFRV+z80+RXgyqr6l83z64BfrKobBtbZC+xtnr4ceHSbb3cu8N0xyu0i+7wY7PNiGKfPf7uqloYt2PYNsjcx7MbZP/VXpKr2AfvGfqNktapWxv05XWKfF4N9XgyT6vOkpmWOAhcPPL8IeHJC7yVJOs2kwv3/ADuTXJLkucA1wN0Tei9J0mkmMi1TVSeS3AD8D+As4JaqengS70ULUzsdZJ8Xg31eDBPp80R2qEqSZsszVCWphwx3SeqhzoT7ZpczyLr/0iw/mOQXZlFnm0bo8683fT2Y5E+TvGoWdbZp1MtWJPn7SU4251R02ih9TnJ5kgNJHk7yhWnX2LYRPttnJ/mDJA81fX77LOpsS5JbkhxPcniD5e3nV1XN/RfrO2UfA14CPBd4CLj0tHWuAv6Q9WPsXwN8ZdZ1T6HP/wA4p3n85kXo88B6/xP4PPArs657Cv/PLwS+Bry4eX7erOueQp/fB/yH5vES8H3gubOufYw+vx74BeDwBstbz6+ujNxHuZzB1cDv17ovAy9McsG0C23Rpn2uqj+tqr9snn6Z9fMJumzUy1b8a+BO4Pg0i5uQUfr8z4C7qupbAFXV9X6P0ucCXpAkwPNZD/cT0y2zPVV1P+t92Ejr+dWVcL8Q+PbA86NN21bX6ZKt9ud61v/yd9mmfU5yIfA24GNTrGuSRvl/fhlwTpL/leTBJL8xteomY5Q+fxj4edZPfjwEvKuqnplOeTPRen5N6vIDbdv0cgYjrtMlI/cnyRtYD/d/ONGKJm+UPv9n4D1VdXJ9UNd5o/R5B/D3gCuAvwl8KcmXq+rPJ13chIzS5zcBB4BfAl4K3Jvkf1fVDydd3Iy0nl9dCfdRLmfQt0sejNSfJK8Efg94c1V9b0q1TcoofV4Bbm+C/VzgqiQnquq/T6fE1o362f5uVf0V8FdJ7gdeBXQ13Efp89uBD9T6hPSRJN8E/g7wwHRKnLrW86sr0zKjXM7gbuA3mr3OrwF+UFXHpl1oizbtc5IXA3cB13V4FDdo0z5X1SVVtVxVy8BngH/V4WCH0T7bnwNel2RHkp8BfhF4ZMp1tmmUPn+L9S0VkpzP+pVjH59qldPVen51YuReG1zOIMk7muUfY/3IiauAI8CPWf/L31kj9vnfAT8HfKQZyZ6oDl9Rb8Q+98oofa6qR5L8EXAQeAb4vaoaekhdF4z4//zvgVuTHGJ9yuI9VdXZSwEnuQ24HDg3yVHg/cBzYHL55eUHJKmHujItI0naAsNdknrIcJekHjLcJamHDHdJ6iHDXZJ6yHCXpB76fxcVi9v8Mi2AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp 1.7472788095474243\n",
      "Supervised Aim: twopeak dp\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.022639\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 0.000046\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 0.000007\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 0.000002\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 0.000000\n",
      "NN 1 : tensor(1.7126)\n",
      "CS 1 : 1.8636\n",
      "DP 1 : 1.7527\n",
      "heuristic 1 : 1.74715\n",
      "DP: 1.7472788095474243\n",
      "tensor([0.7200, 0.2100, 0.0700])\n",
      "tensor([0.7608, 0.2392, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 1.775836 testing loss: tensor(1.7125)\n",
      "Train Epoch: 1 [640/20000 (3%)]\tLoss: 1.637073 testing loss: tensor(1.7026)\n",
      "Train Epoch: 1 [1280/20000 (6%)]\tLoss: 1.729912 testing loss: tensor(1.6930)\n",
      "Train Epoch: 1 [1920/20000 (10%)]\tLoss: 1.686079 testing loss: tensor(1.6878)\n",
      "Train Epoch: 1 [2560/20000 (13%)]\tLoss: 1.753785 testing loss: tensor(1.6875)\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 1.699912 testing loss: tensor(1.6843)\n",
      "Train Epoch: 1 [3840/20000 (19%)]\tLoss: 1.659519 testing loss: tensor(1.6842)\n",
      "Train Epoch: 1 [4480/20000 (22%)]\tLoss: 1.594620 testing loss: tensor(1.6828)\n",
      "Train Epoch: 1 [5120/20000 (25%)]\tLoss: 1.723233 testing loss: tensor(1.6848)\n",
      "Train Epoch: 1 [5760/20000 (29%)]\tLoss: 1.632340 testing loss: tensor(1.6831)\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 1.625723 testing loss: tensor(1.6812)\n",
      "Train Epoch: 1 [7040/20000 (35%)]\tLoss: 1.629368 testing loss: tensor(1.6806)\n",
      "Train Epoch: 1 [7680/20000 (38%)]\tLoss: 1.754524 testing loss: tensor(1.6832)\n",
      "Train Epoch: 1 [8320/20000 (41%)]\tLoss: 1.739740 testing loss: tensor(1.6796)\n",
      "Train Epoch: 1 [8960/20000 (45%)]\tLoss: 1.654328 testing loss: tensor(1.6817)\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 1.746714 testing loss: tensor(1.6796)\n",
      "Train Epoch: 1 [10240/20000 (51%)]\tLoss: 1.651864 testing loss: tensor(1.6803)\n",
      "Train Epoch: 1 [10880/20000 (54%)]\tLoss: 1.664842 testing loss: tensor(1.6817)\n",
      "Train Epoch: 1 [11520/20000 (57%)]\tLoss: 1.733761 testing loss: tensor(1.6814)\n",
      "Train Epoch: 1 [12160/20000 (61%)]\tLoss: 1.594527 testing loss: tensor(1.6809)\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 1.573423 testing loss: tensor(1.6818)\n",
      "Train Epoch: 1 [13440/20000 (67%)]\tLoss: 1.663821 testing loss: tensor(1.6805)\n",
      "Train Epoch: 1 [14080/20000 (70%)]\tLoss: 1.650618 testing loss: tensor(1.6819)\n",
      "Train Epoch: 1 [14720/20000 (73%)]\tLoss: 1.733046 testing loss: tensor(1.6802)\n",
      "Train Epoch: 1 [15360/20000 (76%)]\tLoss: 1.759291 testing loss: tensor(1.6817)\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 1.646728 testing loss: tensor(1.6800)\n",
      "Train Epoch: 1 [16640/20000 (83%)]\tLoss: 1.700962 testing loss: tensor(1.6806)\n",
      "Train Epoch: 1 [17280/20000 (86%)]\tLoss: 1.621067 testing loss: tensor(1.6811)\n",
      "Train Epoch: 1 [17920/20000 (89%)]\tLoss: 1.709096 testing loss: tensor(1.6800)\n",
      "Train Epoch: 1 [18560/20000 (92%)]\tLoss: 1.632525 testing loss: tensor(1.6793)\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 1.716555 testing loss: tensor(1.6804)\n",
      "Train Epoch: 1 [19840/20000 (99%)]\tLoss: 1.651767 testing loss: tensor(1.6797)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.6793)\n",
      "CS 2 : 1.8636\n",
      "DP 2 : 1.7527\n",
      "heuristic 2 : 1.74715\n",
      "DP: 1.7472788095474243\n",
      "tensor([0.7177, 0.1407, 0.1416])\n",
      "tensor([0.7197, 0.2803, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: twopeak random initializing\n",
      "do nothing\n",
      "NN 1 : tensor(1.8434)\n",
      "CS 1 : 1.8636\n",
      "DP 1 : 1.7527\n",
      "heuristic 1 : 1.74715\n",
      "DP: 1.7472788095474243\n",
      "tensor([0.2456, 0.4564, 0.2980])\n",
      "tensor([0.3649, 0.6351, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 1.842709 testing loss: tensor(1.8321)\n",
      "Train Epoch: 1 [640/20000 (3%)]\tLoss: 1.787187 testing loss: tensor(1.7232)\n",
      "Train Epoch: 1 [1280/20000 (6%)]\tLoss: 1.750092 testing loss: tensor(1.7078)\n",
      "Train Epoch: 1 [1920/20000 (10%)]\tLoss: 1.794345 testing loss: tensor(1.6949)\n",
      "Train Epoch: 1 [2560/20000 (13%)]\tLoss: 1.796815 testing loss: tensor(1.6978)\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 1.667214 testing loss: tensor(1.6894)\n",
      "Train Epoch: 1 [3840/20000 (19%)]\tLoss: 1.527149 testing loss: tensor(1.6895)\n",
      "Train Epoch: 1 [4480/20000 (22%)]\tLoss: 1.705159 testing loss: tensor(1.6887)\n",
      "Train Epoch: 1 [5120/20000 (25%)]\tLoss: 1.689634 testing loss: tensor(1.6916)\n",
      "Train Epoch: 1 [5760/20000 (29%)]\tLoss: 1.783524 testing loss: tensor(1.6913)\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 1.683022 testing loss: tensor(1.6905)\n",
      "Train Epoch: 1 [7040/20000 (35%)]\tLoss: 1.579387 testing loss: tensor(1.6890)\n",
      "Train Epoch: 1 [7680/20000 (38%)]\tLoss: 1.650535 testing loss: tensor(1.6882)\n",
      "Train Epoch: 1 [8320/20000 (41%)]\tLoss: 1.676958 testing loss: tensor(1.6894)\n",
      "Train Epoch: 1 [8960/20000 (45%)]\tLoss: 1.633772 testing loss: tensor(1.6900)\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 1.783303 testing loss: tensor(1.6885)\n",
      "Train Epoch: 1 [10240/20000 (51%)]\tLoss: 1.651845 testing loss: tensor(1.6887)\n",
      "Train Epoch: 1 [10880/20000 (54%)]\tLoss: 1.699023 testing loss: tensor(1.6909)\n",
      "Train Epoch: 1 [11520/20000 (57%)]\tLoss: 1.798320 testing loss: tensor(1.6921)\n",
      "Train Epoch: 1 [12160/20000 (61%)]\tLoss: 1.652660 testing loss: tensor(1.6884)\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 1.630238 testing loss: tensor(1.6888)\n",
      "Train Epoch: 1 [13440/20000 (67%)]\tLoss: 1.678564 testing loss: tensor(1.6882)\n",
      "Train Epoch: 1 [14080/20000 (70%)]\tLoss: 1.726505 testing loss: tensor(1.6904)\n",
      "Train Epoch: 1 [14720/20000 (73%)]\tLoss: 1.671602 testing loss: tensor(1.6882)\n",
      "Train Epoch: 1 [15360/20000 (76%)]\tLoss: 1.687020 testing loss: tensor(1.6895)\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 1.586013 testing loss: tensor(1.6897)\n",
      "Train Epoch: 1 [16640/20000 (83%)]\tLoss: 1.751332 testing loss: tensor(1.6894)\n",
      "Train Epoch: 1 [17280/20000 (86%)]\tLoss: 1.789798 testing loss: tensor(1.6887)\n",
      "Train Epoch: 1 [17920/20000 (89%)]\tLoss: 1.710974 testing loss: tensor(1.6896)\n",
      "Train Epoch: 1 [18560/20000 (92%)]\tLoss: 1.732372 testing loss: tensor(1.6889)\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 1.612418 testing loss: tensor(1.6925)\n",
      "Train Epoch: 1 [19840/20000 (99%)]\tLoss: 1.729452 testing loss: tensor(1.6911)\n",
      "penalty: 0.01620352268218994\n",
      "NN 2 : tensor(1.6900)\n",
      "CS 2 : 1.8636\n",
      "DP 2 : 1.7527\n",
      "heuristic 2 : 1.74715\n",
      "DP: 1.7472788095474243\n",
      "tensor([0.1422, 0.7152, 0.1426])\n",
      "tensor([0.2941, 0.7059, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: twopeak costsharing\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.004154\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 0.000020\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 0.000001\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 0.000000\n",
      "NN 1 : tensor(1.8636)\n",
      "CS 1 : 1.8636\n",
      "DP 1 : 1.7527\n",
      "heuristic 1 : 1.74715\n",
      "DP: 1.7472788095474243\n",
      "tensor([0.3333, 0.3333, 0.3333])\n",
      "tensor([0.5000, 0.5000, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 1.840672 testing loss: tensor(1.8642)\n",
      "Train Epoch: 1 [640/20000 (3%)]\tLoss: 1.888749 testing loss: tensor(1.8630)\n",
      "Train Epoch: 1 [1280/20000 (6%)]\tLoss: 1.773958 testing loss: tensor(1.8621)\n",
      "Train Epoch: 1 [1920/20000 (10%)]\tLoss: 1.823107 testing loss: tensor(1.8601)\n",
      "Train Epoch: 1 [2560/20000 (13%)]\tLoss: 1.861813 testing loss: tensor(1.8585)\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 1.915169 testing loss: tensor(1.8559)\n",
      "Train Epoch: 1 [3840/20000 (19%)]\tLoss: 1.818564 testing loss: tensor(1.8525)\n",
      "Train Epoch: 1 [4480/20000 (22%)]\tLoss: 1.937094 testing loss: tensor(1.8492)\n",
      "Train Epoch: 1 [5120/20000 (25%)]\tLoss: 1.767126 testing loss: tensor(1.8436)\n",
      "Train Epoch: 1 [5760/20000 (29%)]\tLoss: 1.845744 testing loss: tensor(1.8355)\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 1.781077 testing loss: tensor(1.8259)\n",
      "Train Epoch: 1 [7040/20000 (35%)]\tLoss: 1.727888 testing loss: tensor(1.8132)\n",
      "Train Epoch: 1 [7680/20000 (38%)]\tLoss: 1.928488 testing loss: tensor(1.8095)\n",
      "Train Epoch: 1 [8320/20000 (41%)]\tLoss: 1.761112 testing loss: tensor(1.8072)\n",
      "Train Epoch: 1 [8960/20000 (45%)]\tLoss: 1.734119 testing loss: tensor(1.8071)\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 1.682910 testing loss: tensor(1.8069)\n",
      "Train Epoch: 1 [10240/20000 (51%)]\tLoss: 1.853128 testing loss: tensor(1.8048)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [10880/20000 (54%)]\tLoss: 1.770737 testing loss: tensor(1.8031)\n",
      "Train Epoch: 1 [11520/20000 (57%)]\tLoss: 1.894452 testing loss: tensor(1.8019)\n",
      "Train Epoch: 1 [12160/20000 (61%)]\tLoss: 1.772075 testing loss: tensor(1.7981)\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 1.774611 testing loss: tensor(1.7968)\n",
      "Train Epoch: 1 [13440/20000 (67%)]\tLoss: 1.795371 testing loss: tensor(1.7928)\n",
      "Train Epoch: 1 [14080/20000 (70%)]\tLoss: 1.649301 testing loss: tensor(1.7901)\n",
      "Train Epoch: 1 [14720/20000 (73%)]\tLoss: 1.847235 testing loss: tensor(1.7844)\n",
      "Train Epoch: 1 [15360/20000 (76%)]\tLoss: 1.663887 testing loss: tensor(1.7771)\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 1.683437 testing loss: tensor(1.7663)\n",
      "Train Epoch: 1 [16640/20000 (83%)]\tLoss: 1.789751 testing loss: tensor(1.7468)\n",
      "Train Epoch: 1 [17280/20000 (86%)]\tLoss: 1.746205 testing loss: tensor(1.7260)\n",
      "Train Epoch: 1 [17920/20000 (89%)]\tLoss: 1.675503 testing loss: tensor(1.7134)\n",
      "Train Epoch: 1 [18560/20000 (92%)]\tLoss: 1.796027 testing loss: tensor(1.7044)\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 1.670223 testing loss: tensor(1.7033)\n",
      "Train Epoch: 1 [19840/20000 (99%)]\tLoss: 1.673279 testing loss: tensor(1.6996)\n",
      "penalty: 0.040495872497558594\n",
      "NN 2 : tensor(1.6991)\n",
      "CS 2 : 1.8636\n",
      "DP 2 : 1.7527\n",
      "heuristic 2 : 1.74715\n",
      "DP: 1.7472788095474243\n",
      "tensor([0.7048, 0.1832, 0.1121])\n",
      "tensor([0.7872, 0.2128, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: twopeak heuristic\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.009856\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 0.000103\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 0.000014\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 0.000001\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.000001\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 0.000000\n",
      "NN 1 : tensor(1.7151)\n",
      "CS 1 : 1.8636\n",
      "DP 1 : 1.7527\n",
      "heuristic 1 : 1.74715\n",
      "DP: 1.7472788095474243\n",
      "tensor([0.1300, 0.1300, 0.7401])\n",
      "tensor([0.4899, 0.5101, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 1.702728 testing loss: tensor(1.7021)\n",
      "Train Epoch: 1 [640/20000 (3%)]\tLoss: 1.634509 testing loss: tensor(1.7021)\n",
      "Train Epoch: 1 [1280/20000 (6%)]\tLoss: 1.704517 testing loss: tensor(1.7032)\n",
      "Train Epoch: 1 [1920/20000 (10%)]\tLoss: 1.610397 testing loss: tensor(1.7005)\n",
      "Train Epoch: 1 [2560/20000 (13%)]\tLoss: 1.773426 testing loss: tensor(1.6989)\n",
      "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 1.707083 testing loss: tensor(1.6964)\n",
      "Train Epoch: 1 [3840/20000 (19%)]\tLoss: 1.750323 testing loss: tensor(1.6932)\n",
      "Train Epoch: 1 [4480/20000 (22%)]\tLoss: 1.713402 testing loss: tensor(1.6902)\n",
      "Train Epoch: 1 [5120/20000 (25%)]\tLoss: 1.719943 testing loss: tensor(1.6913)\n",
      "Train Epoch: 1 [5760/20000 (29%)]\tLoss: 1.856338 testing loss: tensor(1.6894)\n",
      "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 1.664962 testing loss: tensor(1.6882)\n",
      "Train Epoch: 1 [7040/20000 (35%)]\tLoss: 1.752604 testing loss: tensor(1.6863)\n",
      "Train Epoch: 1 [7680/20000 (38%)]\tLoss: 1.676584 testing loss: tensor(1.6868)\n",
      "Train Epoch: 1 [8320/20000 (41%)]\tLoss: 1.762480 testing loss: tensor(1.6857)\n",
      "Train Epoch: 1 [8960/20000 (45%)]\tLoss: 1.748711 testing loss: tensor(1.6847)\n",
      "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 1.643052 testing loss: tensor(1.6851)\n",
      "Train Epoch: 1 [10240/20000 (51%)]\tLoss: 1.780040 testing loss: tensor(1.6866)\n",
      "Train Epoch: 1 [10880/20000 (54%)]\tLoss: 1.706776 testing loss: tensor(1.6868)\n",
      "Train Epoch: 1 [11520/20000 (57%)]\tLoss: 1.591985 testing loss: tensor(1.6862)\n",
      "Train Epoch: 1 [12160/20000 (61%)]\tLoss: 1.591999 testing loss: tensor(1.6849)\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 1.657069 testing loss: tensor(1.6884)\n",
      "Train Epoch: 1 [13440/20000 (67%)]\tLoss: 1.738265 testing loss: tensor(1.6838)\n",
      "Train Epoch: 1 [14080/20000 (70%)]\tLoss: 1.627926 testing loss: tensor(1.6846)\n",
      "Train Epoch: 1 [14720/20000 (73%)]\tLoss: 1.834318 testing loss: tensor(1.6859)\n",
      "Train Epoch: 1 [15360/20000 (76%)]\tLoss: 1.642294 testing loss: tensor(1.6873)\n",
      "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 1.681403 testing loss: tensor(1.6855)\n",
      "Train Epoch: 1 [16640/20000 (83%)]\tLoss: 1.729408 testing loss: tensor(1.6854)\n",
      "Train Epoch: 1 [17280/20000 (86%)]\tLoss: 1.632924 testing loss: tensor(1.6846)\n",
      "Train Epoch: 1 [17920/20000 (89%)]\tLoss: 1.674430 testing loss: tensor(1.6858)\n",
      "Train Epoch: 1 [18560/20000 (92%)]\tLoss: 1.718955 testing loss: tensor(1.6848)\n",
      "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 1.653642 testing loss: tensor(1.6849)\n",
      "Train Epoch: 1 [19840/20000 (99%)]\tLoss: 1.772755 testing loss: tensor(1.6859)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.6863)\n",
      "CS 2 : 1.8636\n",
      "DP 2 : 1.7527\n",
      "heuristic 2 : 1.74715\n",
      "DP: 1.7472788095474243\n",
      "tensor([0.1438, 0.1454, 0.7108])\n",
      "tensor([0.4937, 0.5063, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "    \n",
    "for order in stage:\n",
    "    producedata(order)\n",
    "    #running\n",
    "    for order1 in order1name:\n",
    "        print(\"Supervised Aim:\",order,order1)\n",
    "        \n",
    "        # for mapping binary to payments before softmax\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(n, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, n),\n",
    "        )\n",
    "        model.apply(init_weights)\n",
    "        # optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr1)\n",
    "        \n",
    "        runningLossNN = []\n",
    "        runningLossCS = []\n",
    "        runningLossDP = []\n",
    "        runningLossHeuristic = []\n",
    "        #model=torch.load(\"save/pytorchNN=5dp1\");\n",
    "        #model.eval()\n",
    "        ##order1name=[\"costsharing\",\"dp\",\"heuristic\",\"random initializing\"]\n",
    "        for epoch in range(1, supervisionEpochs + 1):\n",
    "#             print(\"distributionRatio\",distributionRatio)\n",
    "            if(order1==\"costsharing\"):\n",
    "                supervisionTrain(epoch, costSharingSupervisionRule)\n",
    "            elif(order1==\"dp\"):\n",
    "                supervisionTrain(epoch, dpSupervisionRule)\n",
    "            elif(order1==\"heuristic\"):\n",
    "                supervisionTrain(epoch, heuristicSupervisionRule)\n",
    "            elif(order1==\"random initializing\"):\n",
    "                print(\"do nothing\");\n",
    "\n",
    "        test()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr2)\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train(epoch)\n",
    "            test()\n",
    "        losslistname.append(order+\" \"+order1);\n",
    "        losslist.append(losslisttemp);\n",
    "        losslisttemp=[];\n",
    "        savepath=\"save/pytorchNN=5all-beta\"+order+str(order1)\n",
    "        torch.save(model, savepath);\n",
    "        print(\"end\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colorlist=[\"#D2691E\",'#4169E1',\"#9ACD32\",\"#B22222\",\"#FF00FF\",\"#708090\"]\n",
    "for i in range(len(losslist)):\n",
    "    plt.plot(losslist[i], '.-', color=colorlist[i], alpha=0.8, label=losslistname[i])\n",
    "\n",
    "# 显示标签，如果不加这句，即使加了label='一些数字'的参数，最终还是不会显示标签\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Trianing Times')\n",
    "plt.ylabel('Delay')\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('pytorchNN=3_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
