{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.stats as st\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import copy\n",
    "n=5\n",
    "nn=5\n",
    "divide_number=1000;\n",
    "object_number=1.0\n",
    "batch_size=128\n",
    "width=0.001\n",
    "width1=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06459733 0.17325355 0.15883797 0.38951425 0.37308458]\n"
     ]
    }
   ],
   "source": [
    "def distribution1(i):\n",
    "    x=0;\n",
    "    #x=np.random.uniform(0, 1, size=1);\n",
    "    #R=np.random.randint(2);\n",
    "    if (i==0):\n",
    "        x=np.random.normal(0.1, 0.1, size=1);\n",
    "    elif(i==1):\n",
    "        x=np.random.normal(0.2, 0.1, size=1);\n",
    "    elif(i==2):\n",
    "        x=np.random.normal(0.3, 0.1, size=1);\n",
    "    elif(i==3):\n",
    "        x=np.random.normal(0.4, 0.1, size=1);\n",
    "    else:\n",
    "        x=np.random.normal(0.5, 0.1, size=1);\n",
    "    if(x<=0):\n",
    "        x=0;\n",
    "    return x;\n",
    "\n",
    "def distribution():\n",
    "    list_temp=np.random.rand(nn);\n",
    "    for ii in range(len(list_temp)):\n",
    "        list_temp[ii]=distribution1(ii)\n",
    "    list_temp=np.array(list_temp)\n",
    "    #list_temp=sorted(list_temp,reverse=1);\n",
    "    return list_temp;\n",
    "print(distribution())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible = np.zeros((n,divide_number+1), dtype=np.double)\n",
    "for j in range(0,n):\n",
    "    for i in range(100000):#100000\n",
    "        x=distribution1(j%5)*divide_number\n",
    "        temp=int(x)\n",
    "        #print(o,temp)\n",
    "        if(temp>divide_number):\n",
    "            temp=divide_number\n",
    "        possible[j][temp]+=1/100000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.6094e-01 1.6320e-01 1.6566e-01 ... 1.0000e+00 1.0000e+00 1.0000e+00]\n",
      " [2.4310e-02 2.5020e-02 2.5560e-02 ... 1.0000e+00 1.0000e+00 1.0000e+00]\n",
      " [1.5400e-03 1.6100e-03 1.6800e-03 ... 1.0000e+00 1.0000e+00 1.0000e+00]\n",
      " [3.0000e-05 3.0000e-05 3.0000e-05 ... 1.0000e+00 1.0000e+00 1.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 ... 1.0000e+00 1.0000e+00 1.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "P = np.zeros((n,divide_number+1), dtype=np.double)\n",
    "for j in range(0,n):\n",
    "    P[j][0]=possible[j][0]\n",
    "    for i in range(1,divide_number+1):\n",
    "        P[j][i]=P[j][i-1]+possible[j][i];\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = np.zeros(((nn+2), (nn+2), divide_number+1), dtype=np.double)\n",
    "record_dp = np.zeros(((nn+2), (nn+2), divide_number+1), dtype=np.double)\n",
    "for yes in range(0,nn+1):\n",
    "    for i in range(0,divide_number+1):\n",
    "        dp[1][yes][i]=(1.0-P[nn-1][i])*(0.0)+P[nn-1][i]*(yes+1.0);\n",
    "        record_dp[1][yes][i]=i;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,nn+1):\n",
    "    for yes in range(0,nn+1):\n",
    "        for j in range(divide_number+1):\n",
    "            min_num=99999;\n",
    "            for o in range(0,j+1):\n",
    "                if( min_num>(1.0-P[nn-i][o])*dp[i-1][yes+1][j-o]+P[nn-i][o]*(dp[i-1][yes][j]+1)):\n",
    "                    record_dp[i][yes][j]=o;\n",
    "                    min_num=(1.0-P[nn-i][o])*dp[i-1][yes+1][j-o]+P[nn-i][o]*(dp[i-1][yes][j]+1)\n",
    "                #min_num=min(min_num,(1.0-P[o])*dp[i-1][yes+1][j-o]+\n",
    "                #            P[o]*(dp[i-1][yes][j]+1));\n",
    "                \n",
    "                #print(i,yes,j,o,(divide_number-o)/divide_number*dp[i-1][yes+1][j-o]+\n",
    "                #            (o)/divide_number*(dp[i-1][yes][j]+1));\n",
    "            dp[i][yes][j]=min_num;\n",
    "        dp[i][yes][0]=0;\n",
    "        record_dp[i][yes][0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.889787745774146\n",
      "67.0\n",
      "405\n"
     ]
    }
   ],
   "source": [
    "print(dp[nn][0][divide_number]);\n",
    "print(record_dp[nn][0][divide_number]);\n",
    "print(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_dp(temp):\n",
    "    #print(temp)\n",
    "    remain=divide_number\n",
    "    yes=0;\n",
    "    ans =0;\n",
    "    o_list=[];\n",
    "    remain_list=[];\n",
    "    for i in range(nn,0,-1):\n",
    "        o=record_dp[i][yes][remain]\n",
    "        #print(o,remain)\n",
    "        o_list.append(o)\n",
    "        remain_list.append(remain);\n",
    "        if(o<temp[nn-i]):\n",
    "            remain-=int(o);\n",
    "            \n",
    "            yes+=1;\n",
    "        elif (remain>0):\n",
    "            ans+=1;\n",
    "    if(remain<=0):\n",
    "        return ans,o_list;\n",
    "    else:\n",
    "        return nn,o_list;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8385\n"
     ]
    }
   ],
   "source": [
    "ans_list=[];\n",
    "for i in range(10000):\n",
    "    temp=distribution()*divide_number   \n",
    "    ans_list.append(plan_dp(temp)[0]);\n",
    "    #print(plan_dp(temp)[0])\n",
    "print(sum(ans_list)/len(ans_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2871\n"
     ]
    }
   ],
   "source": [
    "#Cost Sharing\n",
    "def cost_sharing(test):\n",
    "    kk=100;\n",
    "    total_delay1=0;\n",
    "    for k in range(nn,0,-1):\n",
    "        count=0;\n",
    "        delay=0;\n",
    "        for item in test:\n",
    "            if(item>=1.0/k):\n",
    "                count+=1;\n",
    "            else:\n",
    "                delay+=1;\n",
    "        if(count>=k):\n",
    "            total_delay1+=delay;\n",
    "            break;\n",
    "        if(k<=1):\n",
    "            #print(test);\n",
    "            total_delay1+=nn;\n",
    "    return total_delay1;\n",
    "\n",
    "def cost_sharing_label(test):\n",
    "    kk=100;\n",
    "    total_delay1=0;\n",
    "    temp=[]\n",
    "    for item in test:\n",
    "        if(item!=-1):\n",
    "            temp.append(item);\n",
    "    for k in range(nn,0,-1):\n",
    "        count=0;\n",
    "        delay=0;\n",
    "        for item in test:\n",
    "            if(item>=1.0/k):\n",
    "                count+=1;\n",
    "            else:\n",
    "                delay+=1;\n",
    "        if(count>=k-1):\n",
    "            return 1.0/k\n",
    "            break;\n",
    "\n",
    "\n",
    "total_delay_cost=0;\n",
    "test_number_cost=10000\n",
    "for i in range(test_number_cost):\n",
    "    test=distribution();\n",
    "    kk=100;\n",
    "    for k in range(nn,0,-1):\n",
    "        count=0;\n",
    "        delay=0;\n",
    "        for item in test:\n",
    "            if(item>=1.0/k):\n",
    "                count+=1;\n",
    "            else:\n",
    "                delay+=1;\n",
    "        if(count>=k):\n",
    "            total_delay_cost+=delay;\n",
    "            break;\n",
    "        if(k<=1):\n",
    "            #print(test);\n",
    "            total_delay_cost+=nn;\n",
    "            \n",
    "\n",
    "print(total_delay_cost/test_number_cost);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#print(trainingdata)\n",
    "\n",
    "import tensorflow as tf\n",
    "#导入TensorFlow工具包并简称为tf\n",
    " \n",
    "from numpy.random import RandomState\n",
    "#导入numpy工具包，生成模拟数据集\n",
    "keep_prob=1\n",
    "tensor_number=200\n",
    "w1 = tf.Variable(tf.truncated_normal([n,tensor_number],stddev=0.1))\n",
    "w2 = tf.Variable(tf.truncated_normal([tensor_number,tensor_number],stddev=0.1))\n",
    "w3 = tf.Variable(tf.truncated_normal([tensor_number,tensor_number],stddev=0.1))\n",
    "w4 = tf.Variable(tf.truncated_normal([tensor_number,tensor_number],stddev=0.1))\n",
    "w5 = tf.Variable(tf.truncated_normal([tensor_number,tensor_number],stddev=0.1))\n",
    "w6 = tf.Variable(tf.truncated_normal([tensor_number,n],stddev=0.1))\n",
    "\n",
    "\n",
    "biases1 = tf.Variable(tf.zeros([1,tensor_number])+0.01)\n",
    "biases2 = tf.Variable(tf.zeros([1,tensor_number])+0.01)\n",
    "biases3 = tf.Variable(tf.zeros([1,tensor_number])+0.01)\n",
    "biases4 = tf.Variable(tf.zeros([1,tensor_number])+0.01)\n",
    "biases5 = tf.Variable(tf.zeros([1,tensor_number])+0.01)\n",
    "biases6 = tf.Variable(tf.zeros([1,n])+0.01)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lr1 = tf.Variable(0.00000001,dtype=tf.float32)\n",
    "lr2 = tf.Variable(0.0000001,dtype=tf.float32)\n",
    "#分别定义一二层和二三层之间的网络参数，标准差为1，随机产生的数保持一致\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32,shape=(None,n),name='x-input1')\n",
    "    xx = tf.placeholder(tf.float32,shape=(None,n),name='x-input2')\n",
    "    y = tf.placeholder(tf.float32,shape=(None,n),name='y-input1')\n",
    "\n",
    "    \n",
    "\n",
    "#定义神经网络前向传播过程\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-93e042855af8>:6: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#输入为两个维度，即两个特征，输出为一个标签,声明数据类型float32，None即一个batch大小\n",
    "#y_是真实的标签\n",
    "\n",
    "xor0=tf.sigmoid((1e3-x) / 0.00001)\n",
    "\n",
    "x1_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(xor0,w1))+biases1,keep_prob)\n",
    "x1_2 = tf.nn.dropout(tf.nn.relu(tf.matmul(x1_1,w2))+biases2,keep_prob)\n",
    "x1_3 = tf.nn.dropout(tf.nn.relu(tf.matmul(x1_2,w3))+biases3,keep_prob)\n",
    "x1_4 = tf.nn.dropout(tf.nn.relu(tf.matmul(x1_3,w4))+biases4,keep_prob)\n",
    "x1_5 = tf.nn.dropout(tf.nn.relu(tf.matmul(x1_4,w5))+biases5,keep_prob)\n",
    "#y1_1  = tf.nn.l2_normalize(tf.nn.dropout(tf.nn.relu(tf.matmul(x1_5,w61)+biases61),keep_prob))\n",
    "y1_1 = tf.nn.softmax((tf.nn.relu(tf.matmul(x1_5,w6))+biases6))\n",
    "xor1 = tf.sigmoid((x+0.001-y1_1) / width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(xor1,w1))+biases1,keep_prob)\n",
    "x2_2 = tf.nn.dropout(tf.nn.relu(tf.matmul(x2_1,w2))+biases2,keep_prob)\n",
    "x2_3 = tf.nn.dropout(tf.nn.relu(tf.matmul(x2_2,w3))+biases3,keep_prob)\n",
    "x2_4 = tf.nn.dropout(tf.nn.relu(tf.matmul(x2_3,w4))+biases4,keep_prob)\n",
    "x2_5 = tf.nn.dropout(tf.nn.relu(tf.matmul(x2_4,w5))+biases5,keep_prob)\n",
    "#y1_1  = tf.nn.l2_normalize(tf.nn.dropout(tf.nn.relu(tf.matmul(x1_5,w61)+biases61),keep_prob))\n",
    "y2_1 = tf.nn.softmax((tf.nn.relu(tf.matmul(x2_5,w6))+biases6)-(1.0-xor1)*1000)\n",
    "xor2 = tf.sigmoid((x+0.001-y2_1) / width) * xor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(xor2,w1))+biases1,keep_prob)\n",
    "x3_2 = tf.nn.dropout(tf.nn.relu(tf.matmul(x3_1,w2))+biases2,keep_prob)\n",
    "x3_3 = tf.nn.dropout(tf.nn.relu(tf.matmul(x3_2,w3))+biases3,keep_prob)\n",
    "x3_4 = tf.nn.dropout(tf.nn.relu(tf.matmul(x3_3,w4))+biases4,keep_prob)\n",
    "x3_5 = tf.nn.dropout(tf.nn.relu(tf.matmul(x3_4,w5))+biases5,keep_prob)\n",
    "#y1_1  = tf.nn.l2_normalize(tf.nn.dropout(tf.nn.relu(tf.matmul(x1_5,w61)+biases61),keep_prob))\n",
    "y3_1 = tf.nn.softmax((tf.nn.relu(tf.matmul(x3_5,w6))+biases6)-(1.0-xor2)*1000)\n",
    "xor3 = tf.sigmoid((x+0.001-y3_1) / width) * xor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(xor3,w1))+biases1,keep_prob)\n",
    "x4_2 = tf.nn.dropout(tf.nn.relu(tf.matmul(x4_1,w2))+biases2,keep_prob)\n",
    "x4_3 = tf.nn.dropout(tf.nn.relu(tf.matmul(x4_2,w3))+biases3,keep_prob)\n",
    "x4_4 = tf.nn.dropout(tf.nn.relu(tf.matmul(x4_3,w4))+biases4,keep_prob)\n",
    "x4_5 = tf.nn.dropout(tf.nn.relu(tf.matmul(x4_4,w5))+biases5,keep_prob)\n",
    "#y1_1  = tf.nn.l2_normalize(tf.nn.dropout(tf.nn.relu(tf.matmul(x1_5,w61)+biases61),keep_prob))\n",
    "y4_1 = tf.nn.softmax((tf.nn.relu(tf.matmul(x4_5,w6))+biases6)-(1.0-xor3)*1000)\n",
    "xor4 = tf.sigmoid((x+0.001-y4_1) / width) * xor3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(xor4,w1))+biases1,keep_prob)\n",
    "x5_2 = tf.nn.dropout(tf.nn.relu(tf.matmul(x5_1,w2))+biases2,keep_prob)\n",
    "x5_3 = tf.nn.dropout(tf.nn.relu(tf.matmul(x5_2,w3))+biases3,keep_prob)\n",
    "x5_4 = tf.nn.dropout(tf.nn.relu(tf.matmul(x5_3,w4))+biases4,keep_prob)\n",
    "x5_5 = tf.nn.dropout(tf.nn.relu(tf.matmul(x5_4,w5))+biases5,keep_prob)\n",
    "#y1_1  = tf.nn.l2_normalize(tf.nn.dropout(tf.nn.relu(tf.matmul(x1_5,w61)+biases61),keep_prob))\n",
    "y5_1 = tf.nn.softmax((tf.nn.relu(tf.matmul(x5_5,w6))+biases6)-(1.0-xor4)*1000)\n",
    "xor5 = tf.sigmoid((x+0.001-y5_1) / width) * xor4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x0_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(xx,w1))+biases1,keep_prob)\n",
    "x0_2 = tf.nn.dropout(tf.nn.relu(tf.matmul(x0_1,w2))+biases2,keep_prob)\n",
    "x0_3 = tf.nn.dropout(tf.nn.relu(tf.matmul(x0_2,w3))+biases3,keep_prob)\n",
    "x0_4 = tf.nn.dropout(tf.nn.relu(tf.matmul(x0_3,w4))+biases4,keep_prob)\n",
    "x0_5 = tf.nn.dropout(tf.nn.relu(tf.matmul(x0_4,w5))+biases5,keep_prob)\n",
    "#y1_1  = tf.nn.l2_normalize(tf.nn.dropout(tf.nn.relu(tf.matmul(x1_5,w61)+biases61),keep_prob))\n",
    "y0_1 = tf.nn.softmax((tf.nn.relu(tf.matmul(x0_5,w6))+biases6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer= y5_1 * xor5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible=1.0-offer\n",
    "delay = tf.reduce_sum(offer,reduction_indices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_payment = tf.reduce_sum(offer,reduction_indices=1)\n",
    "delta = tf.sigmoid((output_payment+0.001-1.0) / width1)\n",
    "tf_delay = delta * tf.reduce_sum((1.0-xor5),reduction_indices=1) + (1.0 - delta) * n;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Tensor(\"mul_11:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#定义损失函数和反向传播算法\n",
    "\n",
    "loss= 1.0*(tf.reduce_sum(tf_delay))\n",
    "#loss= tf.reduce_sum(x5_1)\n",
    "loss_dp= 1.0*(tf.reduce_sum(tf.square(y0_1-y*xx)))\n",
    "\n",
    "train_step1=tf.train.AdamOptimizer(lr1).minimize(loss)\n",
    "train_step2=tf.train.GradientDescentOptimizer(lr2).minimize(loss)\n",
    "train_step3=tf.train.AdadeltaOptimizer(lr1).minimize(loss)\n",
    "train_step4=tf.train.AdamOptimizer(lr1).minimize(loss_dp)\n",
    "#train_step4=tf.train.AdagradDAOptimizer(lr2).minimize(loss)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "#创建会话来运行TensorFlow程序\n",
    "sess = tf.Session()\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "writer=tf.summary.FileWriter('logs/',sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_appen(list_x):\n",
    "    x1=list_x[0];\n",
    "    x2=list_x[1];\n",
    "    x3=list_x[2];\n",
    "    x4=list_x[3];\n",
    "    x5=list_x[4];\n",
    "    ans,S=plan_dp([x1*divide_number,x2*divide_number,x3*divide_number,\n",
    "                  x4*divide_number,x5*divide_number]);\n",
    "    #print(S[0]/divide_number)\n",
    "    SS=copy.deepcopy(S);\n",
    "    if(S[0]/divide_number>=x1):\n",
    "        SS[0]=1;\n",
    "    else:\n",
    "        SS[0]=0;\n",
    "    if(S[1]/divide_number>=x2):\n",
    "        SS[1]=1;\n",
    "    else:\n",
    "        SS[1]=0;\n",
    "    if(S[2]/divide_number>=x3):\n",
    "        SS[2]=1;\n",
    "    else:\n",
    "        SS[2]=0;\n",
    "    if(S[3]/divide_number>=x4):\n",
    "        SS[3]=1;\n",
    "    else:\n",
    "        SS[3]=0;\n",
    "    if(S[4]/divide_number>=x5):\n",
    "        SS[4]=1;\n",
    "    else:\n",
    "        SS[4]=0;\n",
    "    trainingdata1.append(SS)\n",
    "    trainingdata.append(list_x)\n",
    "    #traininglabel1.append([cost_sharing_label(test)])\n",
    "    traininglabel.append([S[0]/divide_number,\n",
    "                          S[1]/divide_number,S[2]/divide_number,S[3]/divide_number,S[4]/divide_number])\n",
    "def readdata():\n",
    "    for i in range(50000):#50000):\n",
    "        list_x=distribution();\n",
    "        newX.append(list_x)\n",
    "    for i in range(len(newX)):\n",
    "        run_appen(newX[i]);\n",
    "        \n",
    "                            \n",
    "newX=[];\n",
    "trainingdata1=[];\n",
    "trainingdata=[];\n",
    "traininglabel=[];\n",
    "def produce_training_data():\n",
    "    newX=[];\n",
    "    trainingdata=[];\n",
    "    S=1.0\n",
    "    readdata();\n",
    "\n",
    "produce_training_data();\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.1467, 0.2313, 0.3875, 0.4689, 0.6055])]\n",
      "2.8067966\n",
      "[[0.1467 0.2313 0.3875 0.4689 0.6055]]\n",
      "[[0. 0. 1. 1. 1.]]\n",
      "[[0.     0.     0.3333 0.3333 0.3333]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_size=len(trainingdata)\n",
    "j1=1\n",
    "j2=2\n",
    "print(trainingdata[j1:j2])\n",
    "print(sess.run(loss,feed_dict={\n",
    "    x:trainingdata[j1:j2]\n",
    "}\n",
    "              )\n",
    "     )\n",
    "print(sess.run(x,feed_dict={\n",
    "    x:trainingdata[j1:j2]\n",
    "}\n",
    "              )\n",
    "     )\n",
    "print(sess.run(xor2,feed_dict={\n",
    "    x:trainingdata[j1:j2]\n",
    "}\n",
    "              )\n",
    "     )\n",
    "print(sess.run(offer,feed_dict={\n",
    "    x:trainingdata[j1:j2]\n",
    "}\n",
    "              )\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.2 0.2 0.2 0.2]]\n",
      "[[0.   0.25 0.25 0.25 0.25]]\n",
      "[[0.     0.     0.3333 0.3333 0.3333]]\n",
      "[[0. 1. 1. 1. 1.]]\n",
      "[[0. 0. 1. 1. 1.]]\n",
      "[[0.     0.     0.3333 0.3333 0.3333]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(y1_1,feed_dict={\n",
    "    x:trainingdata[j1:j2]\n",
    "}\n",
    "              )\n",
    "     )\n",
    "\n",
    "print(sess.run(y2_1,feed_dict={\n",
    "    x:trainingdata[j1:j2]\n",
    "}\n",
    "              )\n",
    "     )\n",
    "print(sess.run(y3_1,feed_dict={\n",
    "    x:trainingdata[j1:j2]\n",
    "}\n",
    "              )\n",
    "     )\n",
    "\n",
    "\n",
    "print(sess.run(xor1,feed_dict={\n",
    "    x:trainingdata[j1:j2]\n",
    "}\n",
    "              )\n",
    "     )\n",
    "\n",
    "print(sess.run(xor2,feed_dict={\n",
    "    x:trainingdata[j1:j2]\n",
    "}\n",
    "              )\n",
    "     )\n",
    "print(sess.run(offer,feed_dict={\n",
    "    x:trainingdata[j1:j2]\n",
    "}\n",
    "              )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from Tensorflow-new-5-difference2/1.ckpt\n",
      "After 0 training step(s),loss on data is 4.92626\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'input/x-input2' with dtype float and shape [?,5]\n\t [[node input/x-input2 (defined at <ipython-input-11-46ad69fd2900>:34) ]]\n\nCaused by op 'input/x-input2', defined at:\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 378, in dispatch_queue\n    yield self.process_one()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 708, in __init__\n    self.run()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-46ad69fd2900>\", line 34, in <module>\n    xx = tf.placeholder(tf.float32,shape=(None,n),name='x-input2')\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5790, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input/x-input2' with dtype float and shape [?,5]\n\t [[node input/x-input2 (defined at <ipython-input-11-46ad69fd2900>:34) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input/x-input2' with dtype float and shape [?,5]\n\t [[{{node input/x-input2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-a7868338755d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrainingdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"After %d training step(s),loss on data is %g\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj2\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mj1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"After %d training step(s),loss_dp on data is %g\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_dp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrainingdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj2\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mj1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input/x-input2' with dtype float and shape [?,5]\n\t [[node input/x-input2 (defined at <ipython-input-11-46ad69fd2900>:34) ]]\n\nCaused by op 'input/x-input2', defined at:\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 378, in dispatch_queue\n    yield self.process_one()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 708, in __init__\n    self.run()\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-46ad69fd2900>\", line 34, in <module>\n    xx = tf.placeholder(tf.float32,shape=(None,n),name='x-input2')\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5790, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input/x-input2' with dtype float and shape [?,5]\n\t [[node input/x-input2 (defined at <ipython-input-11-46ad69fd2900>:34) ]]\n"
     ]
    }
   ],
   "source": [
    "save_path = saver.restore(sess, \"Tensorflow-new-5-difference2/1.ckpt\")\n",
    "STEPS = 10001\n",
    "#设置训练的轮数\n",
    "flag=0;\n",
    "training=1;\n",
    "for i in range(STEPS):\n",
    "\n",
    "    \t#通过选取的样本训练神经网络并更新参数\n",
    "    if i%1000 == 0:\n",
    "        sess.run(tf.assign(lr1,0.000001*(0.99**(i/1000))))\n",
    "        sess.run(tf.assign(lr2,0.000001*(0.99**(i/1000))))\n",
    "        loss_value=0;\n",
    "        if i%1000 == 0:\n",
    "            ii=10;\n",
    "            j1=(ii-1)*batch_size\n",
    "            j2=ii*batch_size\n",
    "            loss_value += sess.run(loss,feed_dict={x:trainingdata[j1:j2]})\n",
    "            print(\"After %d training step(s),loss on data is %g\" % (i,loss_value/(j2-j1)))\n",
    "            print(\"After %d training step(s),loss_dp on data is %g\" % (i,sess.run(loss_dp,feed_dict={x:trainingdata[j1:j2],xx:trainingdata1[j1:j2],y:traininglabel[j1:j2]})/(j2-j1)))\n",
    "    if i%10000 == -100:\n",
    "        if((i/100)%3==0):\n",
    "            flag=0\n",
    "        elif((i/100)%3==1):\n",
    "            flag=1\n",
    "        else:\n",
    "            flag=1#flag=2\n",
    "\n",
    "    randomi = random.randint(0,200000);\n",
    "    start = (randomi) % dataset_size\n",
    "    end = min(start+batch_size,dataset_size)\n",
    "    if(flag==0):\n",
    "        sess.run(train_step4,feed_dict={x:trainingdata[j1:j2],xx:trainingdata1[j1:j2],y:traininglabel[j1:j2]})                                                                                                                \n",
    "        #sess.run(train_step1,feed_dict={x:trainingdata[j1:j2]})\n",
    "    elif(flag==1):\n",
    "        sess.run(train_step2,feed_dict={\n",
    "                x:trainingdata[j1:j2]\n",
    "        })\n",
    "    else:\n",
    "        sess.run(train_step3,feed_dict={\n",
    "                x:trainingdata[j1:j2]\n",
    "        })\n",
    "\n",
    "    \n",
    "\n",
    "save_path = saver.save(sess, \"Tensorflow-new-5-difference2/2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "global list_payment\n",
    "list_payment=[];\n",
    "def judgement(list_x):\n",
    "    delay=sess.run(tf_delay,feed_dict={\n",
    "                                       x:[list_x]\n",
    "                                      })\n",
    "    ans = sess.run(output_payment,feed_dict={\n",
    "                                       x:[list_x]\n",
    "                                      })\n",
    "    #print(delay,ans)\n",
    "    list_payment.append(ans);\n",
    "    return delay\n",
    "def judgement_detail(list_x):\n",
    "    global list_payment\n",
    "    offerxor1= sess.run(xor1,feed_dict={\n",
    "                                      x:[list_x]\n",
    "                                      })\n",
    "    offerxor2= sess.run(xor2,feed_dict={\n",
    "                                      x:[list_x]\n",
    "                                      })\n",
    "    offerxor3= sess.run(xor3,feed_dict={\n",
    "                                      x:[list_x]\n",
    "                                      })\n",
    "    offerxor4= sess.run(xor4,feed_dict={\n",
    "                                      x:[list_x]\n",
    "                                      })\n",
    "    offerxor5= sess.run(xor5,feed_dict={\n",
    "                                      x:[list_x]\n",
    "                                      })\n",
    "    Y1= sess.run(y1_1,feed_dict={\n",
    "                                      x:[list_x]\n",
    "                                      })\n",
    "    Y2= sess.run(y2_1,feed_dict={\n",
    "                                      x:[list_x]\n",
    "                                      })\n",
    "    Y3= sess.run(y3_1,feed_dict={\n",
    "                                      x:[list_x]\n",
    "                                      })\n",
    "    Y4= sess.run(y4_1,feed_dict={\n",
    "                                      x:[list_x]\n",
    "                                      })\n",
    "    Y5= sess.run(y5_1,feed_dict={\n",
    "                                      x:[list_x]\n",
    "                                      })\n",
    "    offer_= sess.run(offer,feed_dict={\n",
    "                                      x:[list_x]\n",
    "                                      })\n",
    "    payment=sess.run(output_payment,feed_dict={\n",
    "                                      x:[list_x]\n",
    "                                      })\n",
    "\n",
    "    delay=sess.run(tf_delay,feed_dict={\n",
    "                                      x:[list_x]\n",
    "                                      })\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    print('bid:            ',list_x)\n",
    "    print('Y1:             ',Y1[0])\n",
    "    print('xor1:           ',offerxor1[0])\n",
    "    print('Y2:             ',Y2[0])\n",
    "    print('xor2:           ',offerxor2[0])\n",
    "    print('Y3:             ',Y3[0])\n",
    "    print('xor3:           ',offerxor3[0])\n",
    "    print('Y4:             ',Y4[0])\n",
    "    print('xor4:           ',offerxor4[0])\n",
    "    print('Y5:             ',Y5[0])\n",
    "    print('xor5:           ',offerxor5[0])\n",
    "    print('offer:          ',offer_[0])\n",
    "    print('payment:        ',payment)\n",
    "    print('delay:          ',delay,\"\\n\")\n",
    "    \n",
    "    return delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_number=10000\n",
    " #打印出训练之后神经网络参数的值\n",
    "\n",
    "mi=10000000;\n",
    "ma=0;\n",
    "sum_list=[];\n",
    "ans_list=[];\n",
    "for i1 in range(test_number):\n",
    "    list_x=distribution()\n",
    "    #print(list_x)\n",
    "    sum_all =judgement(list_x);\n",
    "    mi= min(sum_all,mi);\n",
    "    ma= max(sum_all,ma);\n",
    "    sum_list.append(sum_all)\n",
    "    if(i1<=100):\n",
    "        sum_all =judgement_detail(list_x);\n",
    "        print(\"NN: \",sum_all,\" cost-sharing: \",cost_sharing(list_x),\" dp: \",plan_dp(list_x*divide_number)[0])\n",
    "        print(\"dp details:\",plan_dp(list_x*divide_number)[1])\n",
    "        print(\"***************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mi, ma)\n",
    "print(sum(sum_list)/len(sum_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array(sum_list)\n",
    "data=data.reshape(-1)\n",
    "#print(data.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(data,bins=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sum_list)):\n",
    "    sum_list[i]=np.round(sum_list[i]);\n",
    "print(mi, ma)\n",
    "print(\"NN:           \",sum(sum_list)/len(sum_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cost-sharing: \",total_delay_cost/test_number_cost);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dp:           \",dp[nn][0][divide_number]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(list_payment)/len(list_payment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
