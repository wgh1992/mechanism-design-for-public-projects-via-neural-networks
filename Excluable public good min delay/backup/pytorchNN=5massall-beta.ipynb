{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from random import randint\n",
    "import random\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "from pylab import *\n",
    "from scipy.stats import beta\n",
    "import math\n",
    "n = 3\n",
    "epochs = 5\n",
    "supervisionEpochs = 3\n",
    "lr = 0.0001\n",
    "log_interval = 20\n",
    "trainSize = 60000#100000\n",
    "percentage_train_test= 0.25\n",
    "penaltyLambda = 10\n",
    "doublePeakHighMean = 0.9\n",
    "doublePeakLowMean = 0.1\n",
    "doublePeakStd = 0.1\n",
    "uniformlow=0\n",
    "uniformhigh=1.0\n",
    "normalloc = 0.2\n",
    "normalscale = 0.1\n",
    "\n",
    "cauchyloc = 1/n\n",
    "cauchyscalen = 0.004\n",
    "\n",
    "exponentialhigh = 15 #Symbol(\"b\", real=True)\n",
    "exponentiallow  = 15 #Symbol(\"a\", real=True)\n",
    "\n",
    "\n",
    "betahigh = 0.5\n",
    "betalow  = 0.5\n",
    "\n",
    "\n",
    "independentnormalloc1=[(float(ii)+1)/(2*n+1) for ii in range(n,0,-1)]\n",
    "independentnormalscale1=[0.05 for ii in range(n)]\n",
    "\n",
    "independentnormalloc2=[(float(ii)+1)/(2*n+1) for ii in range(1,n+1,1)]\n",
    "independentnormalscale2=[0.05 for ii in range(n)]\n",
    "stage=[\"arcsine\"]\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"beta\",\"U-exponential\"\n",
    "order1name=[\"random initializing\",\"dp\",\"costsharing\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = D.normal.Normal(doublePeakLowMean, doublePeakStd)\n",
    "d2 = D.normal.Normal(doublePeakHighMean, doublePeakStd)\n",
    "distributionRatio1 = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase1 = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(normalloc, normalscale)\n",
    "distributionRatio3 = d3.cdf(1) - d3.cdf(0)\n",
    "distributionBase3 = d3.cdf(0)\n",
    "\n",
    "d4 = D.uniform.Uniform(uniformlow,uniformhigh)\n",
    "distributionRatio4 = d4.cdf(1) - d4.cdf(0)\n",
    "distributionBase4 = d4.cdf(0)\n",
    "\n",
    "d5 = [D.normal.Normal(independentnormalloc1[ii], independentnormalscale1[ii]) for ii in range(n)]\n",
    "d6 = [D.normal.Normal(independentnormalloc2[ii], independentnormalscale2[ii]) for ii in range(n)]\n",
    "\n",
    "d7 = D.cauchy.Cauchy(cauchyloc,cauchyscalen)\n",
    "\n",
    "d81 = D.exponential.Exponential(exponentiallow)\n",
    "d82 = D.exponential.Exponential(exponentialhigh)\n",
    "\n",
    "d9 = D.beta.Beta(betahigh,betalow)\n",
    "sample_d9=d9.rsample(torch.Size([100000]))\n",
    "\n",
    "d9_sample=np.linspace(0.0001, 0.9999, 10000)\n",
    "d9_pdf=torch.exp(d9.log_prob(torch.tensor(d9_sample,dtype=torch.float32)))\n",
    "d9_delta=d9_sample[1]-d9_sample[0]\n",
    "d9_sum_pdf=torch.sum(d9_pdf*d9_delta)\n",
    "\n",
    "d10 = D.beta.Beta(0.5,0.5)\n",
    "\n",
    "def cdf(x,y, i=None):\n",
    "    if(y==\"twopeak\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) - distributionBase1) / 2 / distributionRatio1\n",
    "    elif(y==\"normal\"):\n",
    "        return (d3.cdf(x)-distributionBase3)/distributionRatio3;\n",
    "    elif(y==\"uniform\"):\n",
    "        return (d4.cdf(x)-distributionBase4)/distributionRatio4;\n",
    "    elif(y==\"independent1\"):\n",
    "        return d5[i].cdf(x);\n",
    "    elif(y==\"independent2\"):\n",
    "        return d6[i].cdf(x);\n",
    "    elif(y==\"cauchy\"):\n",
    "        return d7.cdf(x);\n",
    "    elif(y==\"beta\"):\n",
    "#         sum_cdf=0.0;\n",
    "#         if(x<0.0001):\n",
    "#             x=0.00011;\n",
    "#         if(x>0.9999):\n",
    "#             x=0.99989;\n",
    "#         for i in range(len(d9_pdf)):\n",
    "#             if(d9_sample[i]<x):\n",
    "#                 sum_cdf+=d9_pdf[i]*d9_delta;\n",
    "#             else:\n",
    "#                 sum_cdf+=(d9_pdf[i]+d9_pdf[i-1])/ 2 *(x-d9_sample[i-1])\n",
    "#                 break;\n",
    "#         return sum_cdf/d9_sum_pdf\n",
    "        \n",
    "        cdf_v=torch.sum((sample_d9<(x)), dtype=torch.float32)/100000\n",
    "        if(x>0.00001 and x<0.99999):\n",
    "            cdf_v=torch.exp(d9.log_prob(torch.tensor(x,dtype=torch.float32,requires_grad=True)))*0.0001 + cdf_v\n",
    "        return cdf_v\n",
    "    elif(y==\"arcsine\"):\n",
    "        #\n",
    "        if(x<0.000001):\n",
    "            x=0.000001\n",
    "        elif(x >0.999999):\n",
    "            x=0.999999\n",
    "        try:\n",
    "            res=2.0/math.pi * torch.asin(torch.sqrt(x))\n",
    "            #print(x)\n",
    "            return res# + 0.0001*1.0/(\n",
    "            #math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "        except:\n",
    "            return 2.0/math.pi * torch.asin(torch.sqrt(torch.tensor(x,dtype=torch.float32,requires_grad=True)))# + 0.0001*1.0/(\n",
    "            #math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "    elif(y==\"U-exponential\"):\n",
    "        return (d81.cdf(x) + (1.0 - d82.cdf(1.0-x)))  / 2 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    if torch.sum(bits).item() == 0:\n",
    "        return torch.ones(n)\n",
    "    bits = bits.type(torch.float32)\n",
    "    negBits = torch.ones(n) - bits\n",
    "    payments = model(bits)\n",
    "    payments = payments - 1000 * negBits\n",
    "    payments = torch.softmax(payments, 0)\n",
    "    payments = payments + negBits\n",
    "    return payments\n",
    "\n",
    "def tpToBits(tp, bits=torch.ones(n).type(torch.uint8)):\n",
    "    payments = bitsToPayments(bits)\n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return tpToBits(tp, newBits)#bits-bits#tpToBits(tp, newBits)\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp))\n",
    "\n",
    "\n",
    "def tpToTotalDelay(tp):\n",
    "    return n - torch.sum(tpToBits(tp).type(torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpSupervisionRule(tp):\n",
    "    global  dp,decision\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    money = dpPrecision\n",
    "    yes = 0\n",
    "    for i in range(n):\n",
    "        offerIndex = decision[n - i, money, yes]\n",
    "        offer = float(offerIndex) / dpPrecision\n",
    "        if tp[i] >= offer:\n",
    "            money -= offerIndex\n",
    "            yes += 1\n",
    "            bits[i] = 1\n",
    "            payments[i] = offer\n",
    "        else:\n",
    "            bits[i] = 0\n",
    "            payments[i] = 1\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "#     print()\n",
    "#     print(tp)\n",
    "#     print(bits)\n",
    "#     print(payments)\n",
    "#     print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def heuristicSupervisionRule(tp):\n",
    "    global  dp_H,decision_H\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    tempold=-1;\n",
    "    for turns in range(n,0,-1):\n",
    "        money = dpPrecision\n",
    "        j=0\n",
    "        tempo=sum(bits)\n",
    "        #print(\"bits\",tempo)\n",
    "        for i in range(n):\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            \n",
    "            offerIndex = decision_H[tempo ,tempo - i, money]\n",
    "            offer = float(offerIndex) / dpPrecision\n",
    "            while(j<n):\n",
    "                if(bits[j]!=0):\n",
    "                    break;\n",
    "                j+=1;\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            if tp[j] >= offer:\n",
    "                #print(money,j,tp[j],offer)\n",
    "                money -= offerIndex\n",
    "                bits[j] = 1\n",
    "                payments[j] = offer\n",
    "            else:\n",
    "                bits[j] = 0;\n",
    "                payments[j] = 1.0;\n",
    "            j+=1;\n",
    "        #print(\"money\",money)\n",
    "        if(money==0 and tempold==tempo):\n",
    "            break;\n",
    "        tempold=tempo;\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "\n",
    "    bits = torch.tensor(bits, dtype=torch.float32)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    # print()\n",
    "    # print(tp)\n",
    "    # print(bits)\n",
    "    # print(payments)\n",
    "    # print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "\n",
    "def costSharingSupervisionRule(tp):\n",
    "    tp = list(tp.numpy())\n",
    "    for k in range(n, -1, -1):\n",
    "        if k == 0:\n",
    "            break\n",
    "        bits = [1 if tp[ii] >= 1.0 / k else 0 for ii in range(n)]\n",
    "        if sum(bits) == k:\n",
    "            break\n",
    "    if k == 0:\n",
    "        payments = [1 for ii in range(n)]\n",
    "    else:\n",
    "        payments = [1.0 / k if bits[ii] == 1 else 1 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def costSharingDelay(tp):\n",
    "    return float(n - torch.sum(costSharingSupervisionRule(tp)[0]).item())\n",
    "\n",
    "def dpDelay(tp):\n",
    "    return float(n - torch.sum(dpSupervisionRule(tp)[0]).item())\n",
    "\n",
    "def heuristicDelay(tp):\n",
    "    return float(n - torch.sum(heuristicSupervisionRule(tp)[0]).item())\n",
    "\n",
    "\n",
    "# templire=0;\n",
    "# num=1\n",
    "# for i in range(num):\n",
    "#     temp=torch.tensor(samplesJoint[i])\n",
    "#     #print(temp)\n",
    "#     #print(temp);\n",
    "#     #print(heuristicSupervisionRule(temp))\n",
    "#     #print(dpSupervisionRule(temp))\n",
    "#     #print(dpDelay(temp))\n",
    "#     res=dpDelay(temp)\n",
    "#     templire+=res\n",
    "#     #print(\"delay\",res)\n",
    "#     #print()\n",
    "# print(templire/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordAndReport(name, source, loss):\n",
    "    source.append(loss)\n",
    "    realLength = len(source)\n",
    "    #print(f\"{name} ({realLength}): {loss}\")\n",
    "    print(name,realLength,\":\" ,loss)\n",
    "\n",
    "def supervisionTrain(epoch, supervisionRule):\n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    \n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss = penalty * penaltyLambda /100000\n",
    "        \n",
    "        for tp in tp_batch:\n",
    "            bits, payments = supervisionRule(tp)\n",
    "            loss = loss + F.mse_loss(bitsToPayments(bits), payments)\n",
    "\n",
    "        loss = loss / len(tp_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "losslist=[];\n",
    "losslistname=[];\n",
    "losslisttemp=[];\n",
    "def test_batch():\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        lenLoss= 0\n",
    "        nnLoss = 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "            for tp in tp_batch:\n",
    "                nnLoss += tpToTotalDelay(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        nnLoss/=lenLoss\n",
    "    return nnLoss\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    global losslisttemp; \n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    penalty = penalty + torch.sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss = penalty * penaltyLambda\n",
    "        for tp in tp_batch:\n",
    "            for i in range(n):\n",
    "                tp1 = tp.clone()\n",
    "                tp1[i] = 1\n",
    "                tp0 = tp.clone()\n",
    "                tp0[i] = 0\n",
    "                offer = tpToPayments(tp1)[i]\n",
    "                delay1 = tpToTotalDelay(tp1)\n",
    "                delay0 = tpToTotalDelay(tp0)\n",
    "                if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                    loss = loss + (1 - cdf(offer,order)) * delay1 + cdf(offer,order) * delay0\n",
    "                else:\n",
    "                    loss = loss + (1 - cdf(offer,order,i)) * delay1 + cdf(offer,order,i) * delay0\n",
    "\n",
    "        loss = loss / len(tp_batch) / n\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            losstemp=test_batch();\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                ),\"testing loss:\",losstemp\n",
    "            )\n",
    "            losslisttemp.append(losstemp);\n",
    "            \n",
    "    print(\"penalty:\",penalty.item())\n",
    "    \n",
    "allBits = [torch.tensor(bits, dtype=torch.int16) for bits in itertools.product([0, 1], repeat=n)]\n",
    "\n",
    "def test():\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        costSharingLoss = 0\n",
    "        dpLoss = 0\n",
    "        nnLoss = 0\n",
    "        heuristicLoss=0\n",
    "        lenLoss= 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "\n",
    "            for tp in tp_batch:\n",
    "                costSharingLoss += costSharingDelay(tp)\n",
    "                dpLoss += dpDelay(tp)\n",
    "                nnLoss += tpToTotalDelay(tp)\n",
    "                heuristicLoss+= heuristicDelay(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        costSharingLoss /= lenLoss\n",
    "        dpLoss /= lenLoss\n",
    "        nnLoss /= lenLoss\n",
    "        heuristicLoss /= lenLoss\n",
    "        #print(lenLoss)\n",
    "        losslisttemp.append(nnLoss);\n",
    "        recordAndReport(\"NN\", runningLossNN, nnLoss)\n",
    "        recordAndReport(\"CS\", runningLossCS, costSharingLoss)\n",
    "        recordAndReport(\"DP\", runningLossDP, dpLoss)\n",
    "        recordAndReport(\"heuristic\", runningLossHeuristic, heuristicLoss)\n",
    "        print(\"DP:\",dp[n, dpPrecision,0])\n",
    "        #for i in range(n, 0, -1):\n",
    "        #    print(\"Heuristic:\",i,5*(1-dp_H[i, i, dpPrecision]))\n",
    "        for i in range(n, 0, -1):\n",
    "            print(\n",
    "                    tpToPayments(\n",
    "                            torch.tensor([0 if ii >= i else 1 for ii in range(n)], dtype=torch.float32)\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "dpPrecision = 100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def producedata(order):\n",
    "    global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "    dpPrecision = 100 \n",
    "    if(order==\"twopeak\"):\n",
    "        print(\"loc\",doublePeakLowMean, \"scale\",doublePeakStd)\n",
    "        print(\"loc\",doublePeakHighMean, \"scale\",doublePeakStd)\n",
    "        signals = np.random.randint(2, size=(trainSize, n))\n",
    "        samples1 = np.random.normal(\n",
    "            loc=doublePeakLowMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=doublePeakLowMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samples2 = np.random.normal(\n",
    "            loc=doublePeakHighMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "                    samples2[i, j] = np.random.normal(\n",
    "                        loc=doublePeakHighMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samplesJoint = signals * samples1 - (signals - 1) * samples2\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "        # tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "    elif(order==\"normal\"):\n",
    "        print(\"loc\",normalloc, \"scale\",normalscale)\n",
    "        samples1 = np.random.normal(\n",
    "            loc=normalloc, scale=normalscale, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=normalloc, scale=normalscale\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"uniform\"):  \n",
    "        print(\"uniformlow\",uniformlow, \"uniformhigh\",uniformhigh)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        uniformlow, uniformhigh\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"independent1\"):\n",
    "        print(\"loc\",independentnormalloc1,\"scale\",independentnormalscale1)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc1[j], independentnormalscale1[j]\n",
    "                    )\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc1[j], independentnormalscale1[j]\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"independent2\"):\n",
    "        print(\"loc\",independentnormalloc2, \"scale\",independentnormalscale2)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc2[j], independentnormalscale2[j]\n",
    "                    )\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        independentnormalloc2[j], independentnormalscale2[j]\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"cauchy\"):\n",
    "        print(\"cauchyloc\",cauchyloc, \"cauchyscale\",cauchyscalen)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = d7.rsample(torch.Size([1]))\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = d7.rsample(torch.Size([1]))\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"beta\"):\n",
    "        print(\"betalow\",betalow, \"betahigh\",betahigh)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = beta.rvs(betahigh,betalow,  size = 1)\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = beta.rvs(betahigh,betalow,  size = 1)\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"arcsine\"):\n",
    "        print(\"betalow\",0.5, \"betahigh\",0.5)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                samples1[i, j] = beta.rvs(0.5,0.5,  size = 1)\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = beta.rvs(0.5,0.5,  size = 1)\n",
    "                    \n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==\"U-exponential\"):\n",
    "        print(\"loc\",doublePeakLowMean, \"scale\",doublePeakStd)\n",
    "        print(\"loc\",doublePeakHighMean, \"scale\",doublePeakStd)\n",
    "        signals = np.random.randint(2, size=(trainSize, n))\n",
    "        samples1 = d81.rsample(torch.Size([trainSize, n])).numpy()\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = d81.rsample(torch.Size([1])).numpy()\n",
    "                    \n",
    "        samples2 = d82.rsample(torch.Size([trainSize, n])).numpy()\n",
    "        \n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "                    samples2[i, j] = d82.rsample(torch.Size([1])).numpy()\n",
    "        samples2 = 1.0 - samples2\n",
    "        samplesJoint = signals * samples1 - (signals - 1.0) * samples2\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "\n",
    "        # tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "        \n",
    "    plt.hist(samplesJoint,bins=500)\n",
    "    plt.show()\n",
    "    \n",
    "    tp_dataset = TensorDataset(tp_tensor[: int(trainSize * percentage_train_test)])\n",
    "    tp_dataset_testing = TensorDataset(tp_tensor[int(trainSize * (1.0-percentage_train_test)) :])\n",
    "    tp_dataloader = DataLoader(tp_dataset, batch_size=128, shuffle=True)\n",
    "    tp_dataloader_testing = DataLoader(tp_dataset_testing, batch_size=256, shuffle=False)\n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp = np.zeros([n + 1, dpPrecision + 1, n + 1])\n",
    "    decision = np.zeros([n + 1, dpPrecision + 1, n + 1], dtype=np.uint8)\n",
    "    # ppl = 0 left\n",
    "    for yes in range(n + 1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            if money == 0:\n",
    "                dp[0, 0, yes] = 0\n",
    "            else:\n",
    "                dp[0, money, yes] = yes# + 1.0\n",
    "    for ppl in range(1,  n + 1):\n",
    "        for yes in range(n + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                minSoFar = 1000000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                        res = (1 - cdf(offer,order)) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes + 1, n)\n",
    "                        ] + cdf(offer,order) * (1 + dp[ppl - 1, money, yes])\n",
    "                    else:\n",
    "                        res = (1 - cdf(offer,order,n-ppl)) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes + 1, n)\n",
    "                        ] + cdf(offer,order,n-ppl) * (1 + dp[ppl - 1, money, yes])\n",
    "                    if minSoFar > res.item():\n",
    "                        minSoFar = res.item()\n",
    "                        decision[ppl, money, yes] = offerIndex\n",
    "                dp[ppl, money, yes] = minSoFar\n",
    "    \n",
    "    print(\"dp\",dp[n, dpPrecision, 0])\n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp_H = np.zeros([n + 1 , n + 1, dpPrecision + 1])\n",
    "    decision_H = np.zeros([n + 1 , n + 1, dpPrecision + 1], dtype=np.uint8)\n",
    "    # ppl = 0 left\n",
    "    for i in range(1,n+1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            if money == 0:\n",
    "                dp_H[i, 0, 0] = 1\n",
    "            else:\n",
    "                offer = money / dpPrecision\n",
    "                dp_H[i, 0, money] = 0#cdf(offer)# + 1.0\n",
    "    for i in range(1,n+1):\n",
    "        for ppl in range(1, i + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                maxSoFar = -1000000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                        res = (1-cdf(offer,order)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    else:\n",
    "                        res = (1-cdf(offer,order,ppl-1)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    if maxSoFar < res.item():\n",
    "                        maxSoFar = res.item()\n",
    "                        decision_H[i, ppl, money] = offerIndex\n",
    "                dp_H[i, ppl, money] = maxSoFar\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betalow 0.5 betahigh 0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp 1.7499940395355225\n",
      "Supervised Aim: arcsine random initializing\n",
      "do nothing\n",
      "do nothing\n",
      "do nothing\n",
      "NN 1 : tensor(1.7668)\n",
      "CS 1 : 1.7428666666666666\n",
      "DP 1 : 1.7512\n",
      "heuristic 1 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.4325, 0.3894, 0.1781])\n",
      "tensor([0.5359, 0.4641, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: 1.774368 testing loss: tensor(1.7647)\n",
      "Train Epoch: 1 [2560/15000 (17%)]\tLoss: 1.731755 testing loss: tensor(1.7427)\n",
      "Train Epoch: 1 [5120/15000 (34%)]\tLoss: 1.750970 testing loss: tensor(1.7467)\n",
      "Train Epoch: 1 [7680/15000 (51%)]\tLoss: 1.727131 testing loss: tensor(1.7430)\n",
      "Train Epoch: 1 [10240/15000 (68%)]\tLoss: 1.685313 testing loss: tensor(1.7438)\n",
      "Train Epoch: 1 [12800/15000 (85%)]\tLoss: 1.638878 testing loss: tensor(1.7417)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.7408)\n",
      "CS 2 : 1.7428666666666666\n",
      "DP 2 : 1.7512\n",
      "heuristic 2 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3601, 0.3256, 0.3144])\n",
      "tensor([0.5132, 0.4868, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 2 [0/15000 (0%)]\tLoss: 1.670539 testing loss: tensor(1.7417)\n",
      "Train Epoch: 2 [2560/15000 (17%)]\tLoss: 1.641674 testing loss: tensor(1.7440)\n",
      "Train Epoch: 2 [5120/15000 (34%)]\tLoss: 1.669956 testing loss: tensor(1.7431)\n",
      "Train Epoch: 2 [7680/15000 (51%)]\tLoss: 1.725943 testing loss: tensor(1.7431)\n",
      "Train Epoch: 2 [10240/15000 (68%)]\tLoss: 1.699635 testing loss: tensor(1.7405)\n",
      "Train Epoch: 2 [12800/15000 (85%)]\tLoss: 1.717482 testing loss: tensor(1.7418)\n",
      "penalty: 0.0\n",
      "NN 3 : tensor(1.7403)\n",
      "CS 3 : 1.7428666666666666\n",
      "DP 3 : 1.7512\n",
      "heuristic 3 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3526, 0.3197, 0.3277])\n",
      "tensor([0.5227, 0.4773, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 3 [0/15000 (0%)]\tLoss: 1.761387 testing loss: tensor(1.7405)\n",
      "Train Epoch: 3 [2560/15000 (17%)]\tLoss: 1.676203 testing loss: tensor(1.7412)\n",
      "Train Epoch: 3 [5120/15000 (34%)]\tLoss: 1.683129 testing loss: tensor(1.7400)\n",
      "Train Epoch: 3 [7680/15000 (51%)]\tLoss: 1.828381 testing loss: tensor(1.7417)\n",
      "Train Epoch: 3 [10240/15000 (68%)]\tLoss: 1.905995 testing loss: tensor(1.7429)\n",
      "Train Epoch: 3 [12800/15000 (85%)]\tLoss: 1.776374 testing loss: tensor(1.7387)\n",
      "penalty: 0.0\n",
      "NN 4 : tensor(1.7445)\n",
      "CS 4 : 1.7428666666666666\n",
      "DP 4 : 1.7512\n",
      "heuristic 4 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3716, 0.3049, 0.3235])\n",
      "tensor([0.5404, 0.4596, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 4 [0/15000 (0%)]\tLoss: 1.687909 testing loss: tensor(1.7445)\n",
      "Train Epoch: 4 [2560/15000 (17%)]\tLoss: 1.873961 testing loss: tensor(1.7418)\n",
      "Train Epoch: 4 [5120/15000 (34%)]\tLoss: 1.673367 testing loss: tensor(1.7420)\n",
      "Train Epoch: 4 [7680/15000 (51%)]\tLoss: 1.674659 testing loss: tensor(1.7392)\n",
      "Train Epoch: 4 [10240/15000 (68%)]\tLoss: 1.646235 testing loss: tensor(1.7413)\n",
      "Train Epoch: 4 [12800/15000 (85%)]\tLoss: 1.744600 testing loss: tensor(1.7413)\n",
      "penalty: 0.0\n",
      "NN 5 : tensor(1.7419)\n",
      "CS 5 : 1.7428666666666666\n",
      "DP 5 : 1.7512\n",
      "heuristic 5 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3429, 0.3224, 0.3347])\n",
      "tensor([0.5129, 0.4871, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 5 [0/15000 (0%)]\tLoss: 1.714204 testing loss: tensor(1.7413)\n",
      "Train Epoch: 5 [2560/15000 (17%)]\tLoss: 1.842299 testing loss: tensor(1.7429)\n",
      "Train Epoch: 5 [5120/15000 (34%)]\tLoss: 1.745021 testing loss: tensor(1.7437)\n",
      "Train Epoch: 5 [7680/15000 (51%)]\tLoss: 1.744807 testing loss: tensor(1.7427)\n",
      "Train Epoch: 5 [10240/15000 (68%)]\tLoss: 1.688108 testing loss: tensor(1.7421)\n",
      "Train Epoch: 5 [12800/15000 (85%)]\tLoss: 1.726905 testing loss: tensor(1.7415)\n",
      "penalty: 0.0\n",
      "NN 6 : tensor(1.7421)\n",
      "CS 6 : 1.7428666666666666\n",
      "DP 6 : 1.7512\n",
      "heuristic 6 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3281, 0.3434, 0.3286])\n",
      "tensor([0.4837, 0.5163, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: arcsine dp\n",
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: 0.024204\n",
      "Train Epoch: 1 [2560/15000 (17%)]\tLoss: 0.010429\n",
      "Train Epoch: 1 [5120/15000 (34%)]\tLoss: 0.006544\n",
      "Train Epoch: 1 [7680/15000 (51%)]\tLoss: 0.006103\n",
      "Train Epoch: 1 [10240/15000 (68%)]\tLoss: 0.004101\n",
      "Train Epoch: 1 [12800/15000 (85%)]\tLoss: 0.003802\n",
      "Train Epoch: 2 [0/15000 (0%)]\tLoss: 0.003043\n",
      "Train Epoch: 2 [2560/15000 (17%)]\tLoss: 0.002535\n",
      "Train Epoch: 2 [5120/15000 (34%)]\tLoss: 0.002301\n",
      "Train Epoch: 2 [7680/15000 (51%)]\tLoss: 0.001550\n",
      "Train Epoch: 2 [10240/15000 (68%)]\tLoss: 0.001347\n",
      "Train Epoch: 2 [12800/15000 (85%)]\tLoss: 0.001049\n",
      "Train Epoch: 3 [0/15000 (0%)]\tLoss: 0.000834\n",
      "Train Epoch: 3 [2560/15000 (17%)]\tLoss: 0.000680\n",
      "Train Epoch: 3 [5120/15000 (34%)]\tLoss: 0.000605\n",
      "Train Epoch: 3 [7680/15000 (51%)]\tLoss: 0.000410\n",
      "Train Epoch: 3 [10240/15000 (68%)]\tLoss: 0.000612\n",
      "Train Epoch: 3 [12800/15000 (85%)]\tLoss: 0.000333\n",
      "NN 1 : tensor(1.7629)\n",
      "CS 1 : 1.7428666666666666\n",
      "DP 1 : 1.7512\n",
      "heuristic 1 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.4762, 0.4720, 0.0518])\n",
      "tensor([0.5279, 0.4721, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: 1.631916 testing loss: tensor(1.7627)\n",
      "Train Epoch: 1 [2560/15000 (17%)]\tLoss: 1.749874 testing loss: tensor(1.7627)\n",
      "Train Epoch: 1 [5120/15000 (34%)]\tLoss: 1.882965 testing loss: tensor(1.7609)\n",
      "Train Epoch: 1 [7680/15000 (51%)]\tLoss: 1.688702 testing loss: tensor(1.7609)\n",
      "Train Epoch: 1 [10240/15000 (68%)]\tLoss: 1.658067 testing loss: tensor(1.7523)\n",
      "Train Epoch: 1 [12800/15000 (85%)]\tLoss: 1.755697 testing loss: tensor(1.7549)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.7505)\n",
      "CS 2 : 1.7428666666666666\n",
      "DP 2 : 1.7512\n",
      "heuristic 2 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3890, 0.4175, 0.1935])\n",
      "tensor([0.4817, 0.5183, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 2 [0/15000 (0%)]\tLoss: 1.675725 testing loss: tensor(1.7509)\n",
      "Train Epoch: 2 [2560/15000 (17%)]\tLoss: 1.740412 testing loss: tensor(1.7458)\n",
      "Train Epoch: 2 [5120/15000 (34%)]\tLoss: 1.584262 testing loss: tensor(1.7397)\n",
      "Train Epoch: 2 [7680/15000 (51%)]\tLoss: 1.824553 testing loss: tensor(1.7413)\n",
      "Train Epoch: 2 [10240/15000 (68%)]\tLoss: 1.581002 testing loss: tensor(1.7431)\n",
      "Train Epoch: 2 [12800/15000 (85%)]\tLoss: 1.836462 testing loss: tensor(1.7398)\n",
      "penalty: 0.0\n",
      "NN 3 : tensor(1.7404)\n",
      "CS 3 : 1.7428666666666666\n",
      "DP 3 : 1.7512\n",
      "heuristic 3 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3411, 0.3512, 0.3078])\n",
      "tensor([0.5041, 0.4959, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 3 [0/15000 (0%)]\tLoss: 1.774604 testing loss: tensor(1.7397)\n",
      "Train Epoch: 3 [2560/15000 (17%)]\tLoss: 1.687861 testing loss: tensor(1.7411)\n",
      "Train Epoch: 3 [5120/15000 (34%)]\tLoss: 1.736410 testing loss: tensor(1.7399)\n",
      "Train Epoch: 3 [7680/15000 (51%)]\tLoss: 1.654334 testing loss: tensor(1.7407)\n",
      "Train Epoch: 3 [10240/15000 (68%)]\tLoss: 1.709293 testing loss: tensor(1.7407)\n",
      "Train Epoch: 3 [12800/15000 (85%)]\tLoss: 1.775651 testing loss: tensor(1.7426)\n",
      "penalty: 0.0\n",
      "NN 4 : tensor(1.7415)\n",
      "CS 4 : 1.7428666666666666\n",
      "DP 4 : 1.7512\n",
      "heuristic 4 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3409, 0.3399, 0.3192])\n",
      "tensor([0.5099, 0.4901, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 4 [0/15000 (0%)]\tLoss: 1.662170 testing loss: tensor(1.7414)\n",
      "Train Epoch: 4 [2560/15000 (17%)]\tLoss: 1.755278 testing loss: tensor(1.7429)\n",
      "Train Epoch: 4 [5120/15000 (34%)]\tLoss: 1.720213 testing loss: tensor(1.7402)\n",
      "Train Epoch: 4 [7680/15000 (51%)]\tLoss: 1.795779 testing loss: tensor(1.7418)\n",
      "Train Epoch: 4 [10240/15000 (68%)]\tLoss: 1.673411 testing loss: tensor(1.7416)\n",
      "Train Epoch: 4 [12800/15000 (85%)]\tLoss: 1.788292 testing loss: tensor(1.7416)\n",
      "penalty: 0.0\n",
      "NN 5 : tensor(1.7421)\n",
      "CS 5 : 1.7428666666666666\n",
      "DP 5 : 1.7512\n",
      "heuristic 5 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3122, 0.3440, 0.3438])\n",
      "tensor([0.4829, 0.5171, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 5 [0/15000 (0%)]\tLoss: 1.713810 testing loss: tensor(1.7415)\n",
      "Train Epoch: 5 [2560/15000 (17%)]\tLoss: 1.757273 testing loss: tensor(1.7411)\n",
      "Train Epoch: 5 [5120/15000 (34%)]\tLoss: 1.737216 testing loss: tensor(1.7419)\n",
      "Train Epoch: 5 [7680/15000 (51%)]\tLoss: 1.645940 testing loss: tensor(1.7418)\n",
      "Train Epoch: 5 [10240/15000 (68%)]\tLoss: 1.708682 testing loss: tensor(1.7399)\n",
      "Train Epoch: 5 [12800/15000 (85%)]\tLoss: 1.752477 testing loss: tensor(1.7400)\n",
      "penalty: 0.0\n",
      "NN 6 : tensor(1.7413)\n",
      "CS 6 : 1.7428666666666666\n",
      "DP 6 : 1.7512\n",
      "heuristic 6 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3413, 0.3272, 0.3316])\n",
      "tensor([0.5140, 0.4860, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: arcsine costsharing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: 0.000496\n",
      "Train Epoch: 1 [2560/15000 (17%)]\tLoss: 0.000020\n",
      "Train Epoch: 1 [5120/15000 (34%)]\tLoss: 0.000001\n",
      "Train Epoch: 1 [7680/15000 (51%)]\tLoss: 0.000001\n",
      "Train Epoch: 1 [10240/15000 (68%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [12800/15000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [0/15000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [2560/15000 (17%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [5120/15000 (34%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [7680/15000 (51%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [10240/15000 (68%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [12800/15000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [0/15000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [2560/15000 (17%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [5120/15000 (34%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [7680/15000 (51%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [10240/15000 (68%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [12800/15000 (85%)]\tLoss: 0.000000\n",
      "NN 1 : tensor(1.7429)\n",
      "CS 1 : 1.7428666666666666\n",
      "DP 1 : 1.7512\n",
      "heuristic 1 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3333, 0.3333, 0.3333])\n",
      "tensor([0.5000, 0.5000, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: 1.810080 testing loss: tensor(1.7407)\n",
      "Train Epoch: 1 [2560/15000 (17%)]\tLoss: 1.658672 testing loss: tensor(1.7418)\n",
      "Train Epoch: 1 [5120/15000 (34%)]\tLoss: 1.692296 testing loss: tensor(1.7417)\n",
      "Train Epoch: 1 [7680/15000 (51%)]\tLoss: 1.815538 testing loss: tensor(1.7409)\n",
      "Train Epoch: 1 [10240/15000 (68%)]\tLoss: 1.718882 testing loss: tensor(1.7409)\n",
      "Train Epoch: 1 [12800/15000 (85%)]\tLoss: 1.715654 testing loss: tensor(1.7447)\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.7416)\n",
      "CS 2 : 1.7428666666666666\n",
      "DP 2 : 1.7512\n",
      "heuristic 2 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3257, 0.3524, 0.3219])\n",
      "tensor([0.4762, 0.5238, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 2 [0/15000 (0%)]\tLoss: 1.690182 testing loss: tensor(1.7411)\n",
      "Train Epoch: 2 [2560/15000 (17%)]\tLoss: 1.790041 testing loss: tensor(1.7407)\n",
      "Train Epoch: 2 [5120/15000 (34%)]\tLoss: 1.675434 testing loss: tensor(1.7424)\n",
      "Train Epoch: 2 [7680/15000 (51%)]\tLoss: 1.803431 testing loss: tensor(1.7435)\n",
      "Train Epoch: 2 [10240/15000 (68%)]\tLoss: 1.746043 testing loss: tensor(1.7433)\n",
      "Train Epoch: 2 [12800/15000 (85%)]\tLoss: 1.679912 testing loss: tensor(1.7437)\n",
      "penalty: 0.0\n",
      "NN 3 : tensor(1.7403)\n",
      "CS 3 : 1.7428666666666666\n",
      "DP 3 : 1.7512\n",
      "heuristic 3 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3282, 0.3548, 0.3170])\n",
      "tensor([0.4836, 0.5164, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 3 [0/15000 (0%)]\tLoss: 1.750705 testing loss: tensor(1.7409)\n",
      "Train Epoch: 3 [2560/15000 (17%)]\tLoss: 1.831592 testing loss: tensor(1.7415)\n",
      "Train Epoch: 3 [5120/15000 (34%)]\tLoss: 1.863522 testing loss: tensor(1.7404)\n",
      "Train Epoch: 3 [7680/15000 (51%)]\tLoss: 1.705339 testing loss: tensor(1.7417)\n",
      "Train Epoch: 3 [10240/15000 (68%)]\tLoss: 1.601059 testing loss: tensor(1.7434)\n",
      "Train Epoch: 3 [12800/15000 (85%)]\tLoss: 1.639222 testing loss: tensor(1.7407)\n",
      "penalty: 0.0\n",
      "NN 4 : tensor(1.7425)\n",
      "CS 4 : 1.7428666666666666\n",
      "DP 4 : 1.7512\n",
      "heuristic 4 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3271, 0.3298, 0.3431])\n",
      "tensor([0.4991, 0.5009, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 4 [0/15000 (0%)]\tLoss: 1.777821 testing loss: tensor(1.7413)\n",
      "Train Epoch: 4 [2560/15000 (17%)]\tLoss: 1.721654 testing loss: tensor(1.7408)\n",
      "Train Epoch: 4 [5120/15000 (34%)]\tLoss: 1.738979 testing loss: tensor(1.7413)\n",
      "Train Epoch: 4 [7680/15000 (51%)]\tLoss: 1.755246 testing loss: tensor(1.7407)\n",
      "Train Epoch: 4 [10240/15000 (68%)]\tLoss: 1.666183 testing loss: tensor(1.7426)\n",
      "Train Epoch: 4 [12800/15000 (85%)]\tLoss: 1.741704 testing loss: tensor(1.7411)\n",
      "penalty: 0.0\n",
      "NN 5 : tensor(1.7436)\n",
      "CS 5 : 1.7428666666666666\n",
      "DP 5 : 1.7512\n",
      "heuristic 5 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3427, 0.3345, 0.3228])\n",
      "tensor([0.4993, 0.5007, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "Train Epoch: 5 [0/15000 (0%)]\tLoss: 1.692124 testing loss: tensor(1.7427)\n",
      "Train Epoch: 5 [2560/15000 (17%)]\tLoss: 1.738592 testing loss: tensor(1.7409)\n",
      "Train Epoch: 5 [5120/15000 (34%)]\tLoss: 1.597524 testing loss: tensor(1.7411)\n",
      "Train Epoch: 5 [7680/15000 (51%)]\tLoss: 1.707009 testing loss: tensor(1.7402)\n",
      "Train Epoch: 5 [10240/15000 (68%)]\tLoss: 1.731056 testing loss: tensor(1.7424)\n",
      "Train Epoch: 5 [12800/15000 (85%)]\tLoss: 1.682700 testing loss: tensor(1.7432)\n",
      "penalty: 0.0\n",
      "NN 6 : tensor(1.7419)\n",
      "CS 6 : 1.7428666666666666\n",
      "DP 6 : 1.7512\n",
      "heuristic 6 : 2.0124\n",
      "DP: 1.7499940395355225\n",
      "tensor([0.3281, 0.3250, 0.3469])\n",
      "tensor([0.4922, 0.5078, 1.0000])\n",
      "tensor([1., 1., 1.])\n",
      "end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n",
    "        #m.bias.data.fill_(0.1)\n",
    "    \n",
    "for order in stage:\n",
    "    producedata(order)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "    #running\n",
    "    for order1 in order1name:\n",
    "        print(\"Supervised Aim:\",order,order1)\n",
    "        \n",
    "        # for mapping binary to payments before softmax\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(n, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, n),\n",
    "        )\n",
    "        model.apply(init_weights)\n",
    "        # optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        runningLossNN = []\n",
    "        runningLossCS = []\n",
    "        runningLossDP = []\n",
    "        runningLossHeuristic = []\n",
    "        #model=torch.load(\"save/pytorchNN=5dp1\");\n",
    "        #model.eval()\n",
    "        ##order1name=[\"costsharing\",\"dp\",\"heuristic\",\"random initializing\"]\n",
    "        for epoch in range(1, supervisionEpochs + 1):\n",
    "#             print(\"distributionRatio\",distributionRatio)\n",
    "            if(order1==\"costsharing\"):\n",
    "                supervisionTrain(epoch, costSharingSupervisionRule)\n",
    "            elif(order1==\"dp\"):\n",
    "                supervisionTrain(epoch, dpSupervisionRule)\n",
    "            elif(order1==\"heuristic\"):\n",
    "                supervisionTrain(epoch, heuristicSupervisionRule)\n",
    "            elif(order1==\"random initializing\"):\n",
    "                print(\"do nothing\");\n",
    "\n",
    "        test()\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train(epoch)\n",
    "            test()\n",
    "        losslistname.append(order+\" \"+order1);\n",
    "        losslist.append(losslisttemp);\n",
    "        losslisttemp=[];\n",
    "        savepath=\"save/pytorchNN=5all-beta\"+order+str(order1)\n",
    "        torch.save(model, savepath);\n",
    "        print(\"end\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colorlist=[\"#D2691E\",'#4169E1',\"#9ACD32\",\"#B22222\",\"#FF00FF\",\"#708090\"]\n",
    "for i in range(len(losslist)):\n",
    "    plt.plot(losslist[i], 'ro-', color=colorlist[i], alpha=0.8, label=losslistname[i])\n",
    "\n",
    "# 显示标签，如果不加这句，即使加了label='一些数字'的参数，最终还是不会显示标签\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('trianing times')\n",
    "plt.ylabel('delay')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
