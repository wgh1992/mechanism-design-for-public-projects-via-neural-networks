{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1587)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "n = 5\n",
    "epochs = 10\n",
    "supervisionEpochs = 0\n",
    "lr = 0.001\n",
    "log_interval = 20\n",
    "trainSize = 100000\n",
    "penaltyLambda = 10\n",
    "doublePeakHighMean = 0.9\n",
    "doublePeakLowMean = 0.1\n",
    "doublePeakStd = 0.1\n",
    "\n",
    "d1 = D.normal.Normal(doublePeakLowMean, doublePeakStd)\n",
    "d2 = D.normal.Normal(doublePeakHighMean, doublePeakStd)\n",
    "distributionRatio = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "\n",
    "def cdf(x, i=None):\n",
    "    return (d1.cdf(x) + d2.cdf(x) - distributionBase) / 2 / distributionRatio\n",
    "\n",
    "# def cdf(x, i=None):\n",
    "#     if x < 0.1:\n",
    "#         return 0\n",
    "#     if x <= 0.2:\n",
    "#         return 0.5 * (x - 0.1) / 0.1\n",
    "#     if x < 0.8:\n",
    "#         return 0.5\n",
    "#     if x < 0.9:\n",
    "#         return 0.5 + 0.5 * (x - 0.8) / 0.1\n",
    "#     return 1\n",
    "\n",
    "\n",
    "print(distributionBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = np.random.randint(2, size=(trainSize, n))\n",
    "# samples1 = np.random.uniform(low=0.1, high=0.2, size=(trainSize, n))\n",
    "# samples2 = np.random.uniform(low=0.8, high=0.9, size=(trainSize, n))\n",
    "samples1 = np.random.normal(\n",
    "    loc=doublePeakLowMean, scale=doublePeakStd, size=(trainSize, n)\n",
    ")\n",
    "for i in range(trainSize):\n",
    "    for j in range(n):\n",
    "        while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "            samples1[i, j] = np.random.normal(\n",
    "                loc=doublePeakLowMean, scale=doublePeakStd\n",
    "            )\n",
    "samples2 = np.random.normal(\n",
    "    loc=doublePeakHighMean, scale=doublePeakStd, size=(trainSize, n)\n",
    ")\n",
    "for i in range(trainSize):\n",
    "    for j in range(n):\n",
    "        while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "            samples2[i, j] = np.random.normal(\n",
    "                loc=doublePeakHighMean, scale=doublePeakStd\n",
    "            )\n",
    "samplesJoint = signals * samples1 - (signals - 1) * samples2\n",
    "tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "# tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "tp_dataset = TensorDataset(tp_tensor[: round(trainSize * 0.3)])\n",
    "tp_dataset_testing = TensorDataset(tp_tensor[round(trainSize * 0.7) :])\n",
    "tp_dataloader = DataLoader(tp_dataset, batch_size=128, shuffle=True)\n",
    "tp_dataloader_testing = DataLoader(tp_dataset_testing, batch_size=256, shuffle=False)\n",
    "\n",
    "\n",
    "# for mapping binary to payments before softmax\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, n),\n",
    ")\n",
    "\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    if sum(bits).item() == 0:\n",
    "        return torch.ones(n)\n",
    "    bits = bits.type(torch.float32)\n",
    "    negBits = torch.ones(n) - bits\n",
    "    payments = model(bits)\n",
    "    payments = payments - 1000 * negBits\n",
    "    payments = torch.softmax(payments, 0)\n",
    "    payments = payments + negBits\n",
    "    return payments\n",
    "\n",
    "\n",
    "def tpToBits(tp, bits=torch.ones(n).type(torch.uint8)):\n",
    "    payments = bitsToPayments(bits)\n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    \n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return tpToBits(tp, newBits)#bits-bits#tpToBits(tp, newBits)\n",
    "\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp))\n",
    "\n",
    "\n",
    "def tpToTotalDelay(tp):\n",
    "    return n - sum(tpToBits(tp).type(torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "print(1_000_000)\n",
    "print(cdf(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpPrecision = 100\n",
    "# howManyPpl left, money left, yes already\n",
    "dp = np.zeros([n + 1, dpPrecision + 1, n + 1])\n",
    "decision = np.zeros([n + 1, dpPrecision + 1, n + 1], dtype=np.uint8)\n",
    "# ppl = 0 left\n",
    "for yes in range(n + 1):\n",
    "    for money in range(dpPrecision + 1):\n",
    "        if money == 0:\n",
    "            dp[0, 0, yes] = 0\n",
    "        else:\n",
    "            dp[0, money, yes] = yes# + 1.0\n",
    "for ppl in range(1, n + 1):\n",
    "    for yes in range(n + 1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            minSoFar = 1_000_000\n",
    "            for offerIndex in range(money + 1):\n",
    "                offer = offerIndex / dpPrecision\n",
    "                res = (1 - cdf(offer)) * dp[\n",
    "                    ppl - 1, money - offerIndex, min(yes + 1, n)\n",
    "                ] + cdf(offer) * (1 + dp[ppl - 1, money, yes])\n",
    "                if minSoFar > res:\n",
    "                    minSoFar = res\n",
    "                    decision[ppl, money, yes] = offerIndex\n",
    "            dp[ppl, money, yes] = minSoFar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8651759624481201\n"
     ]
    }
   ],
   "source": [
    "print(dp[n, dpPrecision, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28367453813552856\n",
      "3.581627309322357\n"
     ]
    }
   ],
   "source": [
    "# howManyPpl left, money left, yes already\n",
    "dp_H = np.zeros([n + 1, dpPrecision + 1])\n",
    "decision_H = np.zeros([n + 1, dpPrecision + 1], dtype=np.uint8)\n",
    "# ppl = 0 left\n",
    "for money in range(dpPrecision + 1):\n",
    "    if money == 0:\n",
    "        dp_H[0, 0] = 1\n",
    "    else:\n",
    "        offer = money / dpPrecision\n",
    "        dp_H[0, money] = 0#cdf(offer)# + 1.0\n",
    "for ppl in range(1, n + 1):\n",
    "    for money in range(dpPrecision + 1):\n",
    "        maxSoFar = -1_000_000\n",
    "        for offerIndex in range(money + 1):\n",
    "            offer = offerIndex / dpPrecision\n",
    "            res = (1-cdf(offer)) * dp_H[\n",
    "                 ppl - 1, money - offerIndex\n",
    "                ]\n",
    "            if maxSoFar < res:\n",
    "                maxSoFar = res\n",
    "                decision_H[ppl, money] = offerIndex\n",
    "        dp_H[ppl, money] = maxSoFar\n",
    "print(dp_H[n, dpPrecision])\n",
    "print(5*(1-dp_H[n, dpPrecision]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18034192 0.92015969 0.0806884  0.17887893 0.02430093]\n",
      " [0.96237549 0.09351275 0.95911953 0.22012127 0.96389697]\n",
      " [0.98718016 0.02469703 0.78104115 0.96758379 0.05342462]\n",
      " ...\n",
      " [0.15225455 0.13962683 0.13745683 0.23356596 0.05642131]\n",
      " [0.85601341 0.84067523 0.10099183 0.93241787 0.51645455]\n",
      " [0.75414403 0.85553079 0.01291764 0.1626883  0.09552752]]\n"
     ]
    }
   ],
   "source": [
    "print(samplesJoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_dp(temp):\n",
    "    #print(temp)\n",
    "    remain=dpPrecision\n",
    "    yes=0;\n",
    "    ans =0;\n",
    "    o_list=[];\n",
    "    remain_list=[];\n",
    "    for ppl in range(n,0,-1):\n",
    "        o=decision[ppl, remain, yes]\n",
    "        #print(o,remain)\n",
    "        o_list.append(o)\n",
    "        remain_list.append(remain);\n",
    "        if(o<temp[n-ppl]):\n",
    "            remain-=int(o);\n",
    "            yes+=1;\n",
    "        elif (remain>0):\n",
    "            ans+=1;\n",
    "    if(remain<=0):\n",
    "        return ans,o_list;\n",
    "    else:\n",
    "        return n,o_list;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9034\n"
     ]
    }
   ],
   "source": [
    "ans_list=[];\n",
    "for i in range(10000):\n",
    "    temp=samplesJoint[i]*dpPrecision\n",
    "    #print(temp)\n",
    "    ans_list.append(plan_dp(temp)[0]);\n",
    "    #print(\"\\n\",temp)\n",
    "    #print(plan_dp(temp))\n",
    "print(sum(ans_list)/len(ans_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpSupervisionRule(tp):\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0 for ii in range(n)]\n",
    "    money = dpPrecision\n",
    "    yes = 0\n",
    "    for i in range(n):\n",
    "        offerIndex = decision[n - i, money, yes]\n",
    "        offer = offerIndex / dpPrecision\n",
    "        if tp[i] >= offer:\n",
    "            money -= offerIndex\n",
    "            yes += 1\n",
    "            bits[i] = 1\n",
    "            payments[i] = offer\n",
    "        else:\n",
    "            bits[i] = 0\n",
    "            payments[i] = 1\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    # print()\n",
    "    # print(tp)\n",
    "    # print(bits)\n",
    "    # print(payments)\n",
    "    # print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def heuristicSupervisionRule(tp):\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0 for ii in range(n)]\n",
    "    money = dpPrecision\n",
    "    yes = 0\n",
    "    for i in range(n):\n",
    "        offerIndex = decision_H[n - i, money]\n",
    "        offer = offerIndex / dpPrecision\n",
    "        if tp[i] >= offer:\n",
    "            money -= offerIndex\n",
    "            yes += 1\n",
    "            bits[i] = 1\n",
    "            payments[i] = offer\n",
    "        else:\n",
    "            bits = [0 for ii in range(n)]\n",
    "            payments = [1 for ii in range(n)]\n",
    "            money=1\n",
    "            #bits[i] = 0\n",
    "            #payments[i] = 0#1\n",
    "            break\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1 for ii in range(n)]\n",
    "\n",
    "    bits = torch.tensor(bits, dtype=torch.float32)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    # print()\n",
    "    # print(tp)\n",
    "    # print(bits)\n",
    "    # print(payments)\n",
    "    # print()\n",
    "    return (bits, payments)\n",
    "\n",
    "def dpDelay(tp):\n",
    "    bits, payments = dpSupervisionRule(tp)\n",
    "    totalPayment = torch.dot(bits.type(torch.float32), payments).item()\n",
    "    if totalPayment < 1:\n",
    "        return n\n",
    "    else:\n",
    "        return n - sum(bits).item()\n",
    "\n",
    "\n",
    "def costSharingSupervisionRule(tp):\n",
    "    tp = list(tp.numpy())\n",
    "    for k in range(n, -1, -1):\n",
    "        if k == 0:\n",
    "            break\n",
    "        bits = [1 if tp[ii] >= 1 / k else 0 for ii in range(n)]\n",
    "        if sum(bits) == k:\n",
    "            break\n",
    "    if k == 0:\n",
    "        payments = [1 for ii in range(n)]\n",
    "    else:\n",
    "        payments = [1 / k if bits[ii] == 1 else 1 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def costSharingDelay(tp):\n",
    "    return n - sum(costSharingSupervisionRule(tp)[0]).item()\n",
    "\n",
    "def heuristicDelay(tp):\n",
    "    if(sum(heuristicSupervisionRule(tp)[0]).item()==n):\n",
    "        return 0;\n",
    "    else:\n",
    "        return n;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0]\n",
      "tensor([0.2309, 0.2092, 0.2066, 0.1558, 0.1975], grad_fn=<AddBackward0>)\n",
      "[0, 0, 0, 0, 1]\n",
      "tensor([0.2850, 0.2678, 0.2543, 0.1929, 1.0000], grad_fn=<AddBackward0>)\n",
      "[0, 0, 0, 1, 1]\n",
      "tensor([0.3512, 0.3319, 0.3169, 1.0000, 1.0000], grad_fn=<AddBackward0>)\n",
      "[0, 0, 1, 1, 1]\n",
      "tensor([0.5161, 0.4839, 1.0000, 1.0000, 1.0000], grad_fn=<AddBackward0>)\n",
      "[0, 1, 1, 1, 1]\n",
      "tensor([1., 1., 1., 1., 1.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(n, 0, -1):\n",
    "            print([1 if ii >= i else 0 for ii in range(n)])\n",
    "            print(\n",
    "                    tpToPayments(\n",
    "                            torch.tensor([0 if ii >= i else 1 for ii in range(n)], dtype=torch.float32)\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 1]), tensor([0, 0, 0, 1, 0]), tensor([0, 0, 0, 1, 1]), tensor([0, 0, 1, 0, 0]), tensor([0, 0, 1, 0, 1]), tensor([0, 0, 1, 1, 0]), tensor([0, 0, 1, 1, 1]), tensor([0, 1, 0, 0, 0]), tensor([0, 1, 0, 0, 1]), tensor([0, 1, 0, 1, 0]), tensor([0, 1, 0, 1, 1]), tensor([0, 1, 1, 0, 0]), tensor([0, 1, 1, 0, 1]), tensor([0, 1, 1, 1, 0]), tensor([0, 1, 1, 1, 1]), tensor([1, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 1]), tensor([1, 0, 0, 1, 0]), tensor([1, 0, 0, 1, 1]), tensor([1, 0, 1, 0, 0]), tensor([1, 0, 1, 0, 1]), tensor([1, 0, 1, 1, 0]), tensor([1, 0, 1, 1, 1]), tensor([1, 1, 0, 0, 0]), tensor([1, 1, 0, 0, 1]), tensor([1, 1, 0, 1, 0]), tensor([1, 1, 0, 1, 1]), tensor([1, 1, 1, 0, 0]), tensor([1, 1, 1, 0, 1]), tensor([1, 1, 1, 1, 0]), tensor([1, 1, 1, 1, 1])]\n",
      "\n",
      "tensor([0.9211, 0.2104, 0.0344, 0.8680, 0.2301])\n",
      "tensor(0.5738, grad_fn=<SelectBackward>)\n",
      "tensor([0.5738, 1.0000, 1.0000, 0.4262, 1.0000], grad_fn=<AddBackward0>)\n",
      "tensor(2.)\n",
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "allBits = [torch.tensor(bits) for bits in itertools.product([0, 1], repeat=n)]\n",
    "print(allBits)\n",
    "\n",
    "for batch_idx, (tp_batch,) in enumerate(tp_dataloader_testing):\n",
    "    penalty = 0\n",
    "    for bitsMoreOnes in allBits:\n",
    "        for i in range(n):\n",
    "            if bitsMoreOnes[i] == 1:\n",
    "                bitsLessOnes = bitsMoreOnes.clone()\n",
    "                bitsLessOnes[i] = 0\n",
    "                penalty = penalty + sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "    loss = penalty * penaltyLambda\n",
    "    for tp in tp_batch:\n",
    "            for i in range(n):\n",
    "                tp1 = tp.clone()\n",
    "                tp1[i] = 1\n",
    "                tp0 = tp.clone()\n",
    "                tp0[i] = 0\n",
    "                offer = tpToPayments(tp1)[i]\n",
    "                delay1 = tpToTotalDelay(tp1)\n",
    "                delay0 = tpToTotalDelay(tp0)\n",
    "                #loss = loss + (1 - cdf(offer)) * delay1 + cdf(offer) * delay0\n",
    "                loss = loss + (1 - cdf(offer)) * delay1 + cdf(offer) * delay0\n",
    "    print()\n",
    "    print(tp)\n",
    "    tp1 = tp.clone()\n",
    "    tp1[0] = 1\n",
    "    tp0 = tp.clone()\n",
    "    tp0[0] = 0\n",
    "    offer = tpToPayments(tp1)[0]\n",
    "    print(offer)\n",
    "    print(tpToPayments(tp1))\n",
    "    print(delay1)\n",
    "    print(delay0)\n",
    "    break;\n",
    "#print(loss)\n",
    "#print(penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "allBits = [torch.tensor(bits) for bits in itertools.product([0, 1], repeat=n)]\n",
    "\n",
    "runningLossNN = []\n",
    "runningLossCS = []\n",
    "runningLossDP = []\n",
    "runningLossHeuristic = []\n",
    "\n",
    "def recordAndReport(name, source, loss, n=100):\n",
    "    source.append(loss)\n",
    "    realLength = min(n, len(source))\n",
    "    avgLoss = sum(source[-n:]) / realLength\n",
    "    print(f\"{name} ({realLength}): {avgLoss}\")\n",
    "\n",
    "\n",
    "def supervisionTrain(epoch, supervisionRule):\n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0\n",
    "        for tp in tp_batch:\n",
    "            bits, payments = supervisionRule(tp)\n",
    "            # print()\n",
    "            # print(\"supervision\")\n",
    "            # print(tp)\n",
    "            # print(bits)\n",
    "            # print()\n",
    "            # print(payments)\n",
    "            # print(bitsToPayments(bits))\n",
    "            # print()\n",
    "            loss = loss + F.mse_loss(bitsToPayments(bits), payments)\n",
    "\n",
    "        loss = loss / len(tp_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    penalty = penalty + sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss = penalty * penaltyLambda\n",
    "        # costSharingLoss = 0\n",
    "        # dpLoss = 0\n",
    "        for tp in tp_batch:\n",
    "            # costSharingLoss += costSharingDelay(tp)\n",
    "            # dpLoss += dpDelay(tp)\n",
    "            # print()\n",
    "            # print(\"---\")\n",
    "            # print(tp)\n",
    "            # print(costSharingSupervisionRule(tp))\n",
    "            # print(dpSupervisionRule(tp))\n",
    "            # print(costSharingDelay(tp), dpDelay(tp))\n",
    "            # print()\n",
    "            for i in range(n):\n",
    "                tp1 = tp.clone()\n",
    "                tp1[i] = 1\n",
    "                tp0 = tp.clone()\n",
    "                tp0[i] = 0\n",
    "                offer = tpToPayments(tp1)[i]\n",
    "                delay1 = tpToTotalDelay(tp1)\n",
    "                delay0 = tpToTotalDelay(tp0)\n",
    "                loss = loss + (1 - cdf(offer)) * delay1 + cdf(offer) * delay0\n",
    "\n",
    "        loss = loss / len(tp_batch) / n\n",
    "        # costSharingLoss /= len(tp_batch)\n",
    "        # dpLoss /= len(tp_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "            # recordAndReport(\"NN\", runningLossNN, loss.item())\n",
    "            # recordAndReport(\"CS\", runningLossCS, costSharingLoss)\n",
    "            # recordAndReport(\"DP\", runningLossDP, dpLoss)\n",
    "            # print(dp[n, dpPrecision, 0])\n",
    "            print(\"penalty:\",penalty.item())\n",
    "            # print(distributionRatio)\n",
    "            # for i in range(n, 0, -1):\n",
    "            #     print(\n",
    "            #         tpToPayments(\n",
    "            #             torch.tensor([1] * i + [0] * (n - i), dtype=torch.float32)\n",
    "            #         )\n",
    "            #     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "NN (1): 2.524766683578491\n",
      "CS (1): 2.5370333333333335\n",
      "DP (1): 1.8649\n",
      "heuristic (1): 3.585166666666667\n",
      "1.8651759624481201\n",
      "tensor([0.2309, 0.2092, 0.2066, 0.1558, 0.1975])\n",
      "tensor([0.2850, 0.2678, 0.2543, 0.1929, 1.0000])\n",
      "tensor([0.3512, 0.3319, 0.3169, 1.0000, 1.0000])\n",
      "tensor([0.5161, 0.4839, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/30000 (0%)]\tLoss: 2.711947\n",
      "penalty: 0.0\n",
      "Train Epoch: 1 [2560/30000 (9%)]\tLoss: 2.075199\n",
      "penalty: 0.06699621677398682\n",
      "Train Epoch: 1 [5120/30000 (17%)]\tLoss: 1.964900\n",
      "penalty: 0.01714484393596649\n",
      "Train Epoch: 1 [7680/30000 (26%)]\tLoss: 2.103004\n",
      "penalty: 0.026439543813467026\n",
      "Train Epoch: 1 [10240/30000 (34%)]\tLoss: 1.800888\n",
      "penalty: 0.0011539459228515625\n",
      "Train Epoch: 1 [12800/30000 (43%)]\tLoss: 1.776842\n",
      "penalty: 0.021195389330387115\n",
      "Train Epoch: 1 [15360/30000 (51%)]\tLoss: 1.964517\n",
      "penalty: 0.015377651900053024\n",
      "Train Epoch: 1 [17920/30000 (60%)]\tLoss: 1.737738\n",
      "penalty: 0.013531327247619629\n",
      "Train Epoch: 1 [20480/30000 (68%)]\tLoss: 1.880577\n",
      "penalty: 0.005753546953201294\n",
      "Train Epoch: 1 [23040/30000 (77%)]\tLoss: 1.973509\n",
      "penalty: 0.01622921973466873\n",
      "Train Epoch: 1 [25600/30000 (85%)]\tLoss: 1.807936\n",
      "penalty: 0.02251790463924408\n",
      "Train Epoch: 1 [28160/30000 (94%)]\tLoss: 1.771716\n",
      "penalty: 0.008827276527881622\n",
      "30000\n",
      "NN (2): 2.1459665298461914\n",
      "CS (2): 2.5370333333333335\n",
      "DP (2): 1.8649\n",
      "heuristic (2): 3.585166666666667\n",
      "1.8651759624481201\n",
      "tensor([0.7517, 0.0627, 0.0596, 0.0619, 0.0642])\n",
      "tensor([0.7725, 0.0877, 0.0664, 0.0734, 1.0000])\n",
      "tensor([0.7878, 0.1090, 0.1032, 1.0000, 1.0000])\n",
      "tensor([0.8324, 0.1676, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/30000 (0%)]\tLoss: 1.535283\n",
      "penalty: 0.0\n",
      "Train Epoch: 2 [2560/30000 (9%)]\tLoss: 1.818540\n",
      "penalty: 0.0\n",
      "Train Epoch: 2 [5120/30000 (17%)]\tLoss: 1.724434\n",
      "penalty: 0.004619479179382324\n",
      "Train Epoch: 2 [7680/30000 (26%)]\tLoss: 1.841341\n",
      "penalty: 0.0016445517539978027\n",
      "Train Epoch: 2 [10240/30000 (34%)]\tLoss: 1.679290\n",
      "penalty: 0.0\n",
      "Train Epoch: 2 [12800/30000 (43%)]\tLoss: 1.713091\n",
      "penalty: 0.0\n",
      "Train Epoch: 2 [15360/30000 (51%)]\tLoss: 1.697452\n",
      "penalty: 0.002077758312225342\n",
      "Train Epoch: 2 [17920/30000 (60%)]\tLoss: 1.728511\n",
      "penalty: 0.0\n",
      "Train Epoch: 2 [20480/30000 (68%)]\tLoss: 1.799549\n",
      "penalty: 0.0\n",
      "Train Epoch: 2 [23040/30000 (77%)]\tLoss: 1.992085\n",
      "penalty: 0.0029522180557250977\n",
      "Train Epoch: 2 [25600/30000 (85%)]\tLoss: 1.822731\n",
      "penalty: 0.0009869933128356934\n",
      "Train Epoch: 2 [28160/30000 (94%)]\tLoss: 1.539041\n",
      "penalty: 0.0\n",
      "30000\n",
      "NN (3): 2.0185887813568115\n",
      "CS (3): 2.5370333333333335\n",
      "DP (3): 1.8648999999999998\n",
      "heuristic (3): 3.5851666666666673\n",
      "1.8651759624481201\n",
      "tensor([0.7219, 0.0663, 0.0705, 0.0699, 0.0714])\n",
      "tensor([0.7373, 0.0941, 0.0834, 0.0852, 1.0000])\n",
      "tensor([0.7495, 0.1224, 0.1281, 1.0000, 1.0000])\n",
      "tensor([0.8071, 0.1929, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 3 [0/30000 (0%)]\tLoss: 1.747580\n",
      "penalty: 0.0\n",
      "Train Epoch: 3 [2560/30000 (9%)]\tLoss: 1.868114\n",
      "penalty: 0.00015920400619506836\n",
      "Train Epoch: 3 [5120/30000 (17%)]\tLoss: 1.875368\n",
      "penalty: 0.008254051208496094\n",
      "Train Epoch: 3 [7680/30000 (26%)]\tLoss: 2.006004\n",
      "penalty: 0.0\n",
      "Train Epoch: 3 [10240/30000 (34%)]\tLoss: 1.866916\n",
      "penalty: 0.0\n",
      "Train Epoch: 3 [12800/30000 (43%)]\tLoss: 1.743133\n",
      "penalty: 0.0038997530937194824\n",
      "Train Epoch: 3 [15360/30000 (51%)]\tLoss: 1.627695\n",
      "penalty: 0.0007301568984985352\n",
      "Train Epoch: 3 [17920/30000 (60%)]\tLoss: 2.006782\n",
      "penalty: 0.0036568641662597656\n",
      "Train Epoch: 3 [20480/30000 (68%)]\tLoss: 1.909612\n",
      "penalty: 0.0\n",
      "Train Epoch: 3 [23040/30000 (77%)]\tLoss: 1.702315\n",
      "penalty: 0.0022731423377990723\n",
      "Train Epoch: 3 [25600/30000 (85%)]\tLoss: 1.688715\n",
      "penalty: 0.0007330179214477539\n",
      "Train Epoch: 3 [28160/30000 (94%)]\tLoss: 1.642334\n",
      "penalty: 0.0016890764236450195\n",
      "30000\n",
      "NN (4): 1.954808235168457\n",
      "CS (4): 2.5370333333333335\n",
      "DP (4): 1.8649\n",
      "heuristic (4): 3.585166666666667\n",
      "1.8651759624481201\n",
      "tensor([0.7404, 0.0637, 0.0654, 0.0658, 0.0647])\n",
      "tensor([0.7518, 0.0838, 0.0815, 0.0828, 1.0000])\n",
      "tensor([0.7610, 0.1127, 0.1263, 1.0000, 1.0000])\n",
      "tensor([0.7934, 0.2066, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 4 [0/30000 (0%)]\tLoss: 1.885876\n",
      "penalty: 0.0006707310676574707\n",
      "Train Epoch: 4 [2560/30000 (9%)]\tLoss: 1.787712\n",
      "penalty: 0.0\n",
      "Train Epoch: 4 [5120/30000 (17%)]\tLoss: 1.683039\n",
      "penalty: 0.0\n",
      "Train Epoch: 4 [7680/30000 (26%)]\tLoss: 1.702222\n",
      "penalty: 0.0\n",
      "Train Epoch: 4 [10240/30000 (34%)]\tLoss: 1.581389\n",
      "penalty: 0.0\n",
      "Train Epoch: 4 [12800/30000 (43%)]\tLoss: 1.797440\n",
      "penalty: 0.00840151309967041\n",
      "Train Epoch: 4 [15360/30000 (51%)]\tLoss: 1.927696\n",
      "penalty: 0.0015559196472167969\n",
      "Train Epoch: 4 [17920/30000 (60%)]\tLoss: 1.791331\n",
      "penalty: 0.0\n",
      "Train Epoch: 4 [20480/30000 (68%)]\tLoss: 1.916809\n",
      "penalty: 0.0011603236198425293\n",
      "Train Epoch: 4 [23040/30000 (77%)]\tLoss: 1.697600\n",
      "penalty: 0.0\n",
      "Train Epoch: 4 [25600/30000 (85%)]\tLoss: 1.753426\n",
      "penalty: 0.0\n",
      "Train Epoch: 4 [28160/30000 (94%)]\tLoss: 1.646288\n",
      "penalty: 0.0021986961364746094\n",
      "30000\n",
      "NN (5): 1.915326714515686\n",
      "CS (5): 2.5370333333333335\n",
      "DP (5): 1.8649\n",
      "heuristic (5): 3.585166666666667\n",
      "1.8651759624481201\n",
      "tensor([0.7291, 0.0644, 0.0694, 0.0694, 0.0676])\n",
      "tensor([0.7411, 0.0876, 0.0850, 0.0863, 1.0000])\n",
      "tensor([0.7591, 0.1137, 0.1272, 1.0000, 1.0000])\n",
      "tensor([0.7739, 0.2261, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 5 [0/30000 (0%)]\tLoss: 1.919558\n",
      "penalty: 0.0\n",
      "Train Epoch: 5 [2560/30000 (9%)]\tLoss: 1.762192\n",
      "penalty: 0.0\n",
      "Train Epoch: 5 [5120/30000 (17%)]\tLoss: 1.733935\n",
      "penalty: 0.0\n",
      "Train Epoch: 5 [7680/30000 (26%)]\tLoss: 1.740256\n",
      "penalty: 0.00014710426330566406\n",
      "Train Epoch: 5 [10240/30000 (34%)]\tLoss: 1.888164\n",
      "penalty: 0.0\n",
      "Train Epoch: 5 [12800/30000 (43%)]\tLoss: 1.734668\n",
      "penalty: 0.0\n",
      "Train Epoch: 5 [15360/30000 (51%)]\tLoss: 1.725575\n",
      "penalty: 0.0012747645378112793\n",
      "Train Epoch: 5 [17920/30000 (60%)]\tLoss: 1.853020\n",
      "penalty: 0.0029374361038208008\n",
      "Train Epoch: 5 [20480/30000 (68%)]\tLoss: 2.053710\n",
      "penalty: 8.052587509155273e-05\n",
      "Train Epoch: 5 [23040/30000 (77%)]\tLoss: 1.605010\n",
      "penalty: 0.0\n",
      "Train Epoch: 5 [25600/30000 (85%)]\tLoss: 1.691983\n",
      "penalty: 0.0006376504898071289\n",
      "Train Epoch: 5 [28160/30000 (94%)]\tLoss: 1.850954\n",
      "penalty: 0.011438906192779541\n",
      "30000\n",
      "NN (6): 1.8896222114562988\n",
      "CS (6): 2.5370333333333335\n",
      "DP (6): 1.8649000000000002\n",
      "heuristic (6): 3.5851666666666664\n",
      "1.8651759624481201\n",
      "tensor([0.7358, 0.0676, 0.0653, 0.0664, 0.0649])\n",
      "tensor([0.7407, 0.0915, 0.0831, 0.0848, 1.0000])\n",
      "tensor([0.7610, 0.1136, 0.1254, 1.0000, 1.0000])\n",
      "tensor([0.7837, 0.2163, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 6 [0/30000 (0%)]\tLoss: 1.732313\n",
      "penalty: 0.0\n",
      "Train Epoch: 6 [2560/30000 (9%)]\tLoss: 1.662416\n",
      "penalty: 0.002257406711578369\n",
      "Train Epoch: 6 [5120/30000 (17%)]\tLoss: 1.771652\n",
      "penalty: 0.0\n",
      "Train Epoch: 6 [7680/30000 (26%)]\tLoss: 1.766091\n",
      "penalty: 0.0069931745529174805\n",
      "Train Epoch: 6 [10240/30000 (34%)]\tLoss: 1.686576\n",
      "penalty: 0.0010387301445007324\n",
      "Train Epoch: 6 [12800/30000 (43%)]\tLoss: 1.782254\n",
      "penalty: 0.0\n",
      "Train Epoch: 6 [15360/30000 (51%)]\tLoss: 1.819441\n",
      "penalty: 0.0021929144859313965\n",
      "Train Epoch: 6 [17920/30000 (60%)]\tLoss: 1.627350\n",
      "penalty: 0.007611215114593506\n",
      "Train Epoch: 6 [20480/30000 (68%)]\tLoss: 1.774884\n",
      "penalty: 0.0014874935150146484\n",
      "Train Epoch: 6 [23040/30000 (77%)]\tLoss: 2.008645\n",
      "penalty: 0.0\n",
      "Train Epoch: 6 [25600/30000 (85%)]\tLoss: 1.851457\n",
      "penalty: 0.0\n",
      "Train Epoch: 6 [28160/30000 (94%)]\tLoss: 1.903737\n",
      "penalty: 0.0\n",
      "30000\n",
      "NN (7): 1.8707143068313599\n",
      "CS (7): 2.5370333333333335\n",
      "DP (7): 1.8649000000000002\n",
      "heuristic (7): 3.5851666666666664\n",
      "1.8651759624481201\n",
      "tensor([0.7294, 0.0670, 0.0691, 0.0660, 0.0685])\n",
      "tensor([0.7395, 0.0872, 0.0877, 0.0856, 1.0000])\n",
      "tensor([0.7598, 0.1109, 0.1293, 1.0000, 1.0000])\n",
      "tensor([0.7736, 0.2264, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 7 [0/30000 (0%)]\tLoss: 1.887056\n",
      "penalty: 0.0\n",
      "Train Epoch: 7 [2560/30000 (9%)]\tLoss: 1.619142\n",
      "penalty: 0.0\n",
      "Train Epoch: 7 [5120/30000 (17%)]\tLoss: 1.687964\n",
      "penalty: 0.0\n",
      "Train Epoch: 7 [7680/30000 (26%)]\tLoss: 1.758353\n",
      "penalty: 0.0\n",
      "Train Epoch: 7 [10240/30000 (34%)]\tLoss: 1.740312\n",
      "penalty: 0.0\n",
      "Train Epoch: 7 [12800/30000 (43%)]\tLoss: 1.810615\n",
      "penalty: 0.006886839866638184\n",
      "Train Epoch: 7 [15360/30000 (51%)]\tLoss: 1.826147\n",
      "penalty: 0.0013364553451538086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [17920/30000 (60%)]\tLoss: 1.614754\n",
      "penalty: 0.008042693138122559\n",
      "Train Epoch: 7 [20480/30000 (68%)]\tLoss: 1.836746\n",
      "penalty: 0.0019801855087280273\n",
      "Train Epoch: 7 [23040/30000 (77%)]\tLoss: 1.817667\n",
      "penalty: 0.0009642839431762695\n",
      "Train Epoch: 7 [25600/30000 (85%)]\tLoss: 1.762058\n",
      "penalty: 0.003320753574371338\n",
      "Train Epoch: 7 [28160/30000 (94%)]\tLoss: 1.691307\n",
      "penalty: 0.0017093420028686523\n",
      "30000\n",
      "NN (8): 1.857337474822998\n",
      "CS (8): 2.5370333333333335\n",
      "DP (8): 1.8649000000000002\n",
      "heuristic (8): 3.5851666666666664\n",
      "1.8651759624481201\n",
      "tensor([0.7444, 0.0624, 0.0627, 0.0657, 0.0647])\n",
      "tensor([0.7540, 0.0822, 0.0797, 0.0842, 1.0000])\n",
      "tensor([0.7726, 0.1079, 0.1195, 1.0000, 1.0000])\n",
      "tensor([0.7870, 0.2130, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 8 [0/30000 (0%)]\tLoss: 1.768989\n",
      "penalty: 0.0\n",
      "Train Epoch: 8 [2560/30000 (9%)]\tLoss: 1.714049\n",
      "penalty: 0.0\n",
      "Train Epoch: 8 [5120/30000 (17%)]\tLoss: 1.666453\n",
      "penalty: 0.0\n",
      "Train Epoch: 8 [7680/30000 (26%)]\tLoss: 1.903282\n",
      "penalty: 0.001390218734741211\n",
      "Train Epoch: 8 [10240/30000 (34%)]\tLoss: 1.633898\n",
      "penalty: 0.006040990352630615\n",
      "Train Epoch: 8 [12800/30000 (43%)]\tLoss: 1.772715\n",
      "penalty: 0.0\n",
      "Train Epoch: 8 [15360/30000 (51%)]\tLoss: 1.831395\n",
      "penalty: 0.0\n",
      "Train Epoch: 8 [17920/30000 (60%)]\tLoss: 1.840456\n",
      "penalty: 0.007110178470611572\n",
      "Train Epoch: 8 [20480/30000 (68%)]\tLoss: 1.874978\n",
      "penalty: 0.0\n",
      "Train Epoch: 8 [23040/30000 (77%)]\tLoss: 1.792444\n",
      "penalty: 0.0011994242668151855\n",
      "Train Epoch: 8 [25600/30000 (85%)]\tLoss: 1.726258\n",
      "penalty: 0.0\n",
      "Train Epoch: 8 [28160/30000 (94%)]\tLoss: 1.733296\n",
      "penalty: 0.00026237964630126953\n",
      "30000\n",
      "NN (9): 1.8464925289154053\n",
      "CS (9): 2.5370333333333335\n",
      "DP (9): 1.8649000000000002\n",
      "heuristic (9): 3.585166666666667\n",
      "1.8651759624481201\n",
      "tensor([0.7456, 0.0594, 0.0664, 0.0628, 0.0658])\n",
      "tensor([0.7579, 0.0771, 0.0843, 0.0807, 1.0000])\n",
      "tensor([0.7804, 0.0975, 0.1221, 1.0000, 1.0000])\n",
      "tensor([0.7832, 0.2168, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 9 [0/30000 (0%)]\tLoss: 1.513791\n",
      "penalty: 0.0\n",
      "Train Epoch: 9 [2560/30000 (9%)]\tLoss: 1.975267\n",
      "penalty: 0.0\n",
      "Train Epoch: 9 [5120/30000 (17%)]\tLoss: 1.753535\n",
      "penalty: 0.0\n",
      "Train Epoch: 9 [7680/30000 (26%)]\tLoss: 1.564695\n",
      "penalty: 0.0\n",
      "Train Epoch: 9 [10240/30000 (34%)]\tLoss: 1.711298\n",
      "penalty: 0.0\n",
      "Train Epoch: 9 [12800/30000 (43%)]\tLoss: 1.741083\n",
      "penalty: 0.0025852322578430176\n",
      "Train Epoch: 9 [15360/30000 (51%)]\tLoss: 1.778588\n",
      "penalty: 0.002848207950592041\n",
      "Train Epoch: 9 [17920/30000 (60%)]\tLoss: 1.896780\n",
      "penalty: 0.0049582719802856445\n",
      "Train Epoch: 9 [20480/30000 (68%)]\tLoss: 1.723205\n",
      "penalty: 0.0\n",
      "Train Epoch: 9 [23040/30000 (77%)]\tLoss: 1.734895\n",
      "penalty: 0.0\n",
      "Train Epoch: 9 [25600/30000 (85%)]\tLoss: 1.753930\n",
      "penalty: 0.0015352964401245117\n",
      "Train Epoch: 9 [28160/30000 (94%)]\tLoss: 1.740550\n",
      "penalty: 0.0\n",
      "30000\n",
      "NN (10): 1.837693214416504\n",
      "CS (10): 2.5370333333333335\n",
      "DP (10): 1.8649\n",
      "heuristic (10): 3.585166666666667\n",
      "1.8651759624481201\n",
      "tensor([0.7258, 0.0701, 0.0652, 0.0681, 0.0709])\n",
      "tensor([0.7339, 0.0944, 0.0835, 0.0882, 1.0000])\n",
      "tensor([0.7570, 0.1213, 0.1217, 1.0000, 1.0000])\n",
      "tensor([0.7661, 0.2339, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 10 [0/30000 (0%)]\tLoss: 1.848370\n",
      "penalty: 0.0\n",
      "Train Epoch: 10 [2560/30000 (9%)]\tLoss: 1.633989\n",
      "penalty: 0.0008843541145324707\n",
      "Train Epoch: 10 [5120/30000 (17%)]\tLoss: 1.828367\n",
      "penalty: 0.0005910396575927734\n",
      "Train Epoch: 10 [7680/30000 (26%)]\tLoss: 1.738432\n",
      "penalty: 0.0\n",
      "Train Epoch: 10 [10240/30000 (34%)]\tLoss: 1.794315\n",
      "penalty: 0.0\n",
      "Train Epoch: 10 [12800/30000 (43%)]\tLoss: 1.854502\n",
      "penalty: 0.0012938976287841797\n",
      "Train Epoch: 10 [15360/30000 (51%)]\tLoss: 1.822246\n",
      "penalty: 0.0\n",
      "Train Epoch: 10 [17920/30000 (60%)]\tLoss: 1.956506\n",
      "penalty: 0.0\n",
      "Train Epoch: 10 [20480/30000 (68%)]\tLoss: 1.808990\n",
      "penalty: 0.0\n",
      "Train Epoch: 10 [23040/30000 (77%)]\tLoss: 1.893601\n",
      "penalty: 0.0\n",
      "Train Epoch: 10 [25600/30000 (85%)]\tLoss: 1.840897\n",
      "penalty: 0.0026717185974121094\n",
      "Train Epoch: 10 [28160/30000 (94%)]\tLoss: 1.703104\n",
      "penalty: 0.0\n",
      "30000\n",
      "NN (11): 1.8304120302200317\n",
      "CS (11): 2.5370333333333335\n",
      "DP (11): 1.8649\n",
      "heuristic (11): 3.5851666666666664\n",
      "1.8651759624481201\n",
      "tensor([0.7380, 0.0663, 0.0662, 0.0630, 0.0665])\n",
      "tensor([0.7448, 0.0882, 0.0848, 0.0822, 1.0000])\n",
      "tensor([0.7648, 0.1123, 0.1230, 1.0000, 1.0000])\n",
      "tensor([0.7725, 0.2275, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        costSharingLoss = 0\n",
    "        dpLoss = 0\n",
    "        nnLoss = 0\n",
    "        heuristicLoss=0\n",
    "        lenLoss= 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "\n",
    "            for tp in tp_batch:\n",
    "                costSharingLoss += costSharingDelay(tp)\n",
    "                dpLoss += dpDelay(tp)\n",
    "                nnLoss += tpToTotalDelay(tp)\n",
    "                heuristicLoss+= heuristicDelay(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        costSharingLoss /= lenLoss\n",
    "        dpLoss /= lenLoss\n",
    "        nnLoss /= lenLoss\n",
    "        heuristicLoss /= lenLoss\n",
    "        print(lenLoss)\n",
    "        recordAndReport(\"NN\", runningLossNN, nnLoss)\n",
    "        recordAndReport(\"CS\", runningLossCS, costSharingLoss)\n",
    "        recordAndReport(\"DP\", runningLossDP, dpLoss)\n",
    "        recordAndReport(\"heuristic\", runningLossHeuristic, heuristicLoss)\n",
    "        print(dp[n, dpPrecision,0])\n",
    "        for i in range(n, 0, -1):\n",
    "            print(\n",
    "                    tpToPayments(\n",
    "                            torch.tensor([0 if ii >= i else 1 for ii in range(n)], dtype=torch.float32)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "#model=torch.load(\"save/pytorchNN=5dp1\");\n",
    "#model.eval()\n",
    "for epoch in range(1, supervisionEpochs + 1):\n",
    "    print(distributionRatio)\n",
    "#    #supervisionTrain(epoch, costSharingSupervisionRule)\n",
    "#    supervisionTrain(epoch, dpSupervisionRule)\n",
    "    supervisionTrain(epoch, heuristicSupervisionRule)\n",
    "test()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model, \"save/pytorchNN=5UN1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load(PATH)\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
