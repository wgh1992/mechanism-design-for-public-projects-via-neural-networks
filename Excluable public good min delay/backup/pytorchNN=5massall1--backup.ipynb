{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "n = 5\n",
    "epochs = 2\n",
    "supervisionEpochs = 2\n",
    "lr = 0.001\n",
    "log_interval = 20\n",
    "trainSize = 10000\n",
    "penaltyLambda = 10\n",
    "doublePeakHighMean = 0.9\n",
    "doublePeakLowMean = 0.1\n",
    "doublePeakStd = 0.1\n",
    "uniformlow=0\n",
    "uniformhigh=1.0\n",
    "normalloc = 0.2\n",
    "normalscale = 0.1\n",
    "\n",
    "#stage=[\"twopeak\",\"normal\",\"uniform\"]\n",
    "stage=[\"independent\"]\n",
    "#order1name=[\"costsharing\",\"dp\",\"heuristic\",\"random initializing\"]\n",
    "order1name=[\"costsharing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = D.normal.Normal(doublePeakLowMean, doublePeakStd)\n",
    "d2 = D.normal.Normal(doublePeakHighMean, doublePeakStd)\n",
    "distributionRatio = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(normalloc, normalscale)\n",
    "d4 = D.uniform.Uniform(uniformlow,uniformhigh)\n",
    "\n",
    "\n",
    "def cdf(x,y, i=None):\n",
    "    if(y==\"twopeak\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) - distributionBase) / 2 / distributionRatio\n",
    "    elif(y==\"normal\"):\n",
    "        return d3.cdf(x);\n",
    "    elif(y==\"uniform\"):\n",
    "        return d4.cdf(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    if sum(bits).item() == 0:\n",
    "        return torch.ones(n)\n",
    "    bits = bits.type(torch.float32)\n",
    "    negBits = torch.ones(n) - bits\n",
    "    payments = model(bits)\n",
    "    payments = payments - 1000 * negBits\n",
    "    payments = torch.softmax(payments, 0)\n",
    "    payments = payments + negBits\n",
    "    return payments\n",
    "\n",
    "def tpToBits(tp, bits=torch.ones(n).type(torch.uint8)):\n",
    "    payments = bitsToPayments(bits)\n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return tpToBits(tp, newBits)#bits-bits#tpToBits(tp, newBits)\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp))\n",
    "\n",
    "\n",
    "def tpToTotalDelay(tp):\n",
    "    return n - sum(tpToBits(tp).type(torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpSupervisionRule(tp):\n",
    "    global  dp,decision\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    money = dpPrecision\n",
    "    yes = 0\n",
    "    for i in range(n):\n",
    "        offerIndex = decision[n - i, money, yes]\n",
    "        offer = float(offerIndex) / dpPrecision\n",
    "        if tp[i] >= offer:\n",
    "            money -= offerIndex\n",
    "            yes += 1\n",
    "            bits[i] = 1\n",
    "            payments[i] = offer\n",
    "        else:\n",
    "            bits[i] = 0\n",
    "            payments[i] = 1\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "#     print()\n",
    "#     print(tp)\n",
    "#     print(bits)\n",
    "#     print(payments)\n",
    "#     print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def heuristicSupervisionRule(tp):\n",
    "    global  dp_H,decision_H\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0.0 for ii in range(n)]\n",
    "    tempold=-1;\n",
    "    for turns in range(n,0,-1):\n",
    "        money = dpPrecision\n",
    "        j=0\n",
    "        tempo=sum(bits)\n",
    "        #print(\"bits\",tempo)\n",
    "        for i in range(n):\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            \n",
    "            offerIndex = decision_H[tempo ,tempo - i, money]\n",
    "            offer = float(offerIndex) / dpPrecision\n",
    "            while(j<n):\n",
    "                if(bits[j]!=0):\n",
    "                    break;\n",
    "                j+=1;\n",
    "            if(j>=n):\n",
    "                break;\n",
    "            if tp[j] >= offer:\n",
    "                #print(money,j,tp[j],offer)\n",
    "                money -= offerIndex\n",
    "                bits[j] = 1\n",
    "                payments[j] = offer\n",
    "            else:\n",
    "                bits[j] = 0;\n",
    "                payments[j] = 1.0;\n",
    "            j+=1;\n",
    "        #print(\"money\",money)\n",
    "        if(money==0 and tempold==tempo):\n",
    "            break;\n",
    "        tempold=tempo;\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1.0 for ii in range(n)]\n",
    "\n",
    "    bits = torch.tensor(bits, dtype=torch.float32)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    # print()\n",
    "    # print(tp)\n",
    "    # print(bits)\n",
    "    # print(payments)\n",
    "    # print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "\n",
    "def costSharingSupervisionRule(tp):\n",
    "    tp = list(tp.numpy())\n",
    "    for k in range(n, -1, -1):\n",
    "        if k == 0:\n",
    "            break\n",
    "        bits = [1 if tp[ii] >= 1.0 / k else 0 for ii in range(n)]\n",
    "        if sum(bits) == k:\n",
    "            break\n",
    "    if k == 0:\n",
    "        payments = [1 for ii in range(n)]\n",
    "    else:\n",
    "        payments = [1.0 / k if bits[ii] == 1 else 1 for ii in range(n)]\n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def costSharingDelay(tp):\n",
    "    return float(n - sum(costSharingSupervisionRule(tp)[0]).item())\n",
    "\n",
    "def dpDelay(tp):\n",
    "    return float(n - sum(dpSupervisionRule(tp)[0]).item())\n",
    "\n",
    "def heuristicDelay(tp):\n",
    "    return float(n - sum(heuristicSupervisionRule(tp)[0]).item())\n",
    "\n",
    "\n",
    "# templire=0;\n",
    "# num=1\n",
    "# for i in range(num):\n",
    "#     temp=torch.tensor(samplesJoint[i])\n",
    "#     #print(temp)\n",
    "#     #print(temp);\n",
    "#     #print(heuristicSupervisionRule(temp))\n",
    "#     #print(dpSupervisionRule(temp))\n",
    "#     #print(dpDelay(temp))\n",
    "#     res=dpDelay(temp)\n",
    "#     templire+=res\n",
    "#     #print(\"delay\",res)\n",
    "#     #print()\n",
    "# print(templire/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordAndReport(name, source, loss, n=100):\n",
    "    source.append(loss)\n",
    "    realLength = min(n, len(source))\n",
    "    avgLoss = sum(source[-n:]) / realLength\n",
    "    #print(f\"{name} ({realLength}): {avgLoss}\")\n",
    "    print(name,realLength,\":\" ,avgLoss)\n",
    "\n",
    "\n",
    "def supervisionTrain(epoch, supervisionRule):\n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0\n",
    "        for tp in tp_batch:\n",
    "            bits, payments = supervisionRule(tp)\n",
    "            loss = loss + F.mse_loss(bitsToPayments(bits), payments)\n",
    "\n",
    "        loss = loss / len(tp_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        for bitsMoreOnes in allBits:\n",
    "            for i in range(n):\n",
    "                if bitsMoreOnes[i] == 1:\n",
    "                    bitsLessOnes = bitsMoreOnes.clone()\n",
    "                    bitsLessOnes[i] = 0\n",
    "                    penalty = penalty + sum(\n",
    "                        torch.relu(\n",
    "                            bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                        )\n",
    "                    )\n",
    "        loss = penalty * penaltyLambda\n",
    "        for tp in tp_batch:\n",
    "            for i in range(n):\n",
    "                tp1 = tp.clone()\n",
    "                tp1[i] = 1\n",
    "                tp0 = tp.clone()\n",
    "                tp0[i] = 0\n",
    "                offer = tpToPayments(tp1)[i]\n",
    "                delay1 = tpToTotalDelay(tp1)\n",
    "                delay0 = tpToTotalDelay(tp0)\n",
    "                loss = loss + (1 - cdf(offer,order)) * delay1 + cdf(offer,order) * delay0\n",
    "\n",
    "        loss = loss / len(tp_batch) / n\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "    print(\"penalty:\",penalty.item())\n",
    "    \n",
    "allBits = [torch.tensor(bits) for bits in itertools.product([0, 1], repeat=n)]\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        costSharingLoss = 0\n",
    "        dpLoss = 0\n",
    "        nnLoss = 0\n",
    "        heuristicLoss=0\n",
    "        lenLoss= 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "\n",
    "            for tp in tp_batch:\n",
    "                costSharingLoss += costSharingDelay(tp)\n",
    "                dpLoss += dpDelay(tp)\n",
    "                nnLoss += tpToTotalDelay(tp)\n",
    "                heuristicLoss+= heuristicDelay(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        costSharingLoss /= lenLoss\n",
    "        dpLoss /= lenLoss\n",
    "        nnLoss /= lenLoss\n",
    "        heuristicLoss /= lenLoss\n",
    "        #print(lenLoss)\n",
    "        recordAndReport(\"NN\", runningLossNN, nnLoss)\n",
    "        recordAndReport(\"CS\", runningLossCS, costSharingLoss)\n",
    "        recordAndReport(\"DP\", runningLossDP, dpLoss)\n",
    "        recordAndReport(\"heuristic\", runningLossHeuristic, heuristicLoss)\n",
    "        print(\"DP:\",dp[n, dpPrecision,0])\n",
    "        #for i in range(n, 0, -1):\n",
    "        #    print(\"Heuristic:\",i,5*(1-dp_H[i, i, dpPrecision]))\n",
    "        for i in range(n, 0, -1):\n",
    "            print(\n",
    "                    tpToPayments(\n",
    "                            torch.tensor([0 if ii >= i else 1 for ii in range(n)], dtype=torch.float32)\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "dpPrecision = 100 \n",
    "def producedata(order):\n",
    "    global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "    dpPrecision = 100 \n",
    "    if(order==stage[0]):\n",
    "        print(\"loc\",doublePeakLowMean, \"scale\",doublePeakStd)\n",
    "        print(\"loc\",doublePeakHighMean, \"scale\",doublePeakStd)\n",
    "        signals = np.random.randint(2, size=(trainSize, n))\n",
    "        samples1 = np.random.normal(\n",
    "            loc=doublePeakLowMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=doublePeakLowMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samples2 = np.random.normal(\n",
    "            loc=doublePeakHighMean, scale=doublePeakStd, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "                    samples2[i, j] = np.random.normal(\n",
    "                        loc=doublePeakHighMean, scale=doublePeakStd\n",
    "                    )\n",
    "        samplesJoint = signals * samples1 - (signals - 1) * samples2\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "        # tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "    elif(order==stage[1]):\n",
    "        print(\"loc\",normalloc, \"scale\",normalscale)\n",
    "        samples1 = np.random.normal(\n",
    "            loc=normalloc, scale=normalscale, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        loc=normalloc, scale=normalscale\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    elif(order==stage[2]):  \n",
    "        print(\"uniformlow\",uniformlow, \"uniformhigh\",uniformhigh)\n",
    "        samples1 = np.random.uniform(\n",
    "            uniformlow, uniformhigh, size=(trainSize, n)\n",
    "        )\n",
    "        for i in range(trainSize):\n",
    "            for j in range(n):\n",
    "                while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "                    samples1[i, j] = np.random.normal(\n",
    "                        uniformlow, uniformhigh\n",
    "                    )\n",
    "        samplesJoint = samples1\n",
    "        tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "    \n",
    "    tp_dataset = TensorDataset(tp_tensor[: int(trainSize * 0.3)])\n",
    "    tp_dataset_testing = TensorDataset(tp_tensor[int(trainSize * 0.7) :])\n",
    "    tp_dataloader = DataLoader(tp_dataset, batch_size=128, shuffle=True)\n",
    "    tp_dataloader_testing = DataLoader(tp_dataset_testing, batch_size=256, shuffle=False)\n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp = np.zeros([n + 1, dpPrecision + 1, n + 1])\n",
    "    decision = np.zeros([n + 1, dpPrecision + 1, n + 1], dtype=np.uint8)\n",
    "    # ppl = 0 left\n",
    "    for yes in range(n + 1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            if money == 0:\n",
    "                dp[0, 0, yes] = 0\n",
    "            else:\n",
    "                dp[0, money, yes] = yes# + 1.0\n",
    "    for ppl in range(1,  n + 1):\n",
    "        for yes in range(n + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                minSoFar = 1000000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    res = (1 - cdf(offer,order)) * dp[\n",
    "                        ppl - 1, money - offerIndex, min(yes + 1, n)\n",
    "                    ] + cdf(offer,order) * (1 + dp[ppl - 1, money, yes])\n",
    "                    if minSoFar > res.item():\n",
    "                        minSoFar = res.item()\n",
    "                        decision[ppl, money, yes] = offerIndex\n",
    "                dp[ppl, money, yes] = minSoFar\n",
    "    \n",
    "    print(\"dp\",dp[n, dpPrecision, 0])\n",
    "    \n",
    "    # howManyPpl left, money left, yes already\n",
    "    dp_H = np.zeros([n + 1 , n + 1, dpPrecision + 1])\n",
    "    decision_H = np.zeros([n + 1 , n + 1, dpPrecision + 1], dtype=np.uint8)\n",
    "    # ppl = 0 left\n",
    "    for i in range(1,n+1):\n",
    "        for money in range(dpPrecision + 1):\n",
    "            if money == 0:\n",
    "                dp_H[i, 0, 0] = 1\n",
    "            else:\n",
    "                offer = money / dpPrecision\n",
    "                dp_H[i, 0, money] = 0#cdf(offer)# + 1.0\n",
    "    for i in range(1,n+1):\n",
    "        for ppl in range(1, i + 1):\n",
    "            for money in range(dpPrecision + 1):\n",
    "                maxSoFar = -1000000\n",
    "                for offerIndex in range(money + 1):\n",
    "                    offer = float(offerIndex) / dpPrecision\n",
    "                    res = (1-cdf(offer,order)) * dp_H[\n",
    "                         i, ppl - 1, money - offerIndex\n",
    "                        ]\n",
    "                    if maxSoFar < res.item():\n",
    "                        maxSoFar = res.item()\n",
    "                        decision_H[i, ppl, money] = offerIndex\n",
    "                dp_H[i, ppl, money] = maxSoFar\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc 0.1 scale 0.1\n",
      "loc 0.9 scale 0.1\n",
      "dp 1.8651759624481201\n",
      "Supervised Aim: twopeak costsharing\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.000113\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.000001\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 0.000002\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 0.000000\n",
      "NN 1 : tensor(2.5627)\n",
      "CS 1 : 2.562\n",
      "DP 1 : 1.8656666666666666\n",
      "heuristic 1 : 1.8286666666666667\n",
      "DP: 1.8651759624481201\n",
      "tensor([0.2003, 0.2001, 0.1999, 0.2002, 0.1995])\n",
      "tensor([0.2496, 0.2500, 0.2501, 0.2502, 1.0000])\n",
      "tensor([0.3330, 0.3336, 0.3334, 1.0000, 1.0000])\n",
      "tensor([0.4997, 0.5003, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 2.509565\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 2.192957\n",
      "penalty: 0.05495244264602661\n",
      "NN 2 : tensor(2.3548)\n",
      "CS 2 : 2.562\n",
      "DP 2 : 1.8656666666666666\n",
      "heuristic 2 : 1.8286666666666667\n",
      "DP: 1.8651759624481201\n",
      "tensor([0.0145, 0.1818, 0.5370, 0.0266, 0.2402])\n",
      "tensor([0.0283, 0.2649, 0.6596, 0.0472, 1.0000])\n",
      "tensor([0.0404, 0.2932, 0.6665, 1.0000, 1.0000])\n",
      "tensor([0.1566, 0.8434, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 2.106588\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 2.061779\n",
      "penalty: 0.000334056094288826\n",
      "NN 3 : tensor(2.2137)\n",
      "CS 3 : 2.562\n",
      "DP 3 : 1.8656666666666666\n",
      "heuristic 3 : 1.8286666666666667\n",
      "DP: 1.8651759624481201\n",
      "tensor([0.0212, 0.1167, 0.7326, 0.0177, 0.1118])\n",
      "tensor([0.0467, 0.1820, 0.7315, 0.0398, 1.0000])\n",
      "tensor([0.0536, 0.1925, 0.7539, 1.0000, 1.0000])\n",
      "tensor([0.2052, 0.7948, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: twopeak dp\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.123357\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.045402\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 0.035555\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 0.005823\n",
      "NN 1 : tensor(1.9670)\n",
      "CS 1 : 2.562\n",
      "DP 1 : 1.8656666666666666\n",
      "heuristic 1 : 1.8286666666666667\n",
      "DP: 1.8651759624481201\n",
      "tensor([0.7558, 0.1532, 0.0392, 0.0303, 0.0215])\n",
      "tensor([0.6862, 0.1954, 0.0657, 0.0527, 1.0000])\n",
      "tensor([0.6846, 0.2277, 0.0877, 1.0000, 1.0000])\n",
      "tensor([0.7417, 0.2583, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 2.062537\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 1.876549\n",
      "penalty: 0.0609554648399353\n",
      "NN 2 : tensor(1.9122)\n",
      "CS 2 : 2.562\n",
      "DP 2 : 1.8656666666666666\n",
      "heuristic 2 : 1.8286666666666667\n",
      "DP: 1.8651759624481201\n",
      "tensor([0.7653, 0.1468, 0.0265, 0.0291, 0.0323])\n",
      "tensor([0.7843, 0.1510, 0.0305, 0.0342, 1.0000])\n",
      "tensor([0.7940, 0.1657, 0.0402, 1.0000, 1.0000])\n",
      "tensor([0.8100, 0.1900, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 1.892449\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 1.917353\n",
      "penalty: 0.0013454556465148926\n",
      "NN 3 : tensor(1.8889)\n",
      "CS 3 : 2.562\n",
      "DP 3 : 1.8656666666666666\n",
      "heuristic 3 : 1.8286666666666667\n",
      "DP: 1.8651759624481201\n",
      "tensor([0.7578, 0.1363, 0.0329, 0.0362, 0.0368])\n",
      "tensor([0.7709, 0.1462, 0.0391, 0.0438, 1.0000])\n",
      "tensor([0.7793, 0.1650, 0.0557, 1.0000, 1.0000])\n",
      "tensor([0.8113, 0.1887, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: twopeak heuristic\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.106119\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.051171\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 0.052856\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 0.035925\n",
      "NN 1 : tensor(2.4073)\n",
      "CS 1 : 2.562\n",
      "DP 1 : 1.8656666666666666\n",
      "heuristic 1 : 1.8286666666666667\n",
      "DP: 1.8651759624481201\n",
      "tensor([0.1876, 0.1287, 0.1207, 0.2019, 0.3610])\n",
      "tensor([0.3017, 0.1945, 0.1859, 0.3179, 1.0000])\n",
      "tensor([0.5291, 0.2331, 0.2378, 1.0000, 1.0000])\n",
      "tensor([0.6777, 0.3223, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 2.341245\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 2.011896\n",
      "penalty: 0.015467226505279541\n",
      "NN 2 : tensor(2.1690)\n",
      "CS 2 : 2.562\n",
      "DP 2 : 1.8656666666666666\n",
      "heuristic 2 : 1.8286666666666667\n",
      "DP: 1.8651759624481201\n",
      "tensor([0.1138, 0.0382, 0.0343, 0.1334, 0.6803])\n",
      "tensor([0.3863, 0.1016, 0.0945, 0.4175, 1.0000])\n",
      "tensor([0.6936, 0.1568, 0.1495, 1.0000, 1.0000])\n",
      "tensor([0.7819, 0.2181, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 1.961332\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 1.741376\n",
      "penalty: 0.010120660066604614\n",
      "NN 3 : tensor(2.0647)\n",
      "CS 3 : 2.562\n",
      "DP 3 : 1.8656666666666666\n",
      "heuristic 3 : 1.8286666666666667\n",
      "DP: 1.8651759624481201\n",
      "tensor([0.0898, 0.0251, 0.0228, 0.1099, 0.7524])\n",
      "tensor([0.4252, 0.0543, 0.0506, 0.4699, 1.0000])\n",
      "tensor([0.7591, 0.1244, 0.1165, 1.0000, 1.0000])\n",
      "tensor([0.8309, 0.1691, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: twopeak random initializing\n",
      "do nothing\n",
      "do nothing\n",
      "NN 1 : tensor(1.8560)\n",
      "CS 1 : 2.562\n",
      "DP 1 : 1.8656666666666666\n",
      "heuristic 1 : 1.8286666666666667\n",
      "DP: 1.8651759624481201\n",
      "tensor([0.0898, 0.0251, 0.0228, 0.1099, 0.7524])\n",
      "tensor([0.4252, 0.0543, 0.0506, 0.4699, 1.0000])\n",
      "tensor([0.7591, 0.1244, 0.1165, 1.0000, 1.0000])\n",
      "tensor([0.8309, 0.1691, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 1.766973\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 1.940709\n",
      "penalty: 0.0023126304149627686\n",
      "NN 2 : tensor(1.8503)\n",
      "CS 2 : 2.562\n",
      "DP 2 : 1.8656666666666666\n",
      "heuristic 2 : 1.8286666666666667\n",
      "DP: 1.8651759624481201\n",
      "tensor([0.0862, 0.0333, 0.0296, 0.1033, 0.7477])\n",
      "tensor([0.4137, 0.0496, 0.0446, 0.4921, 1.0000])\n",
      "tensor([0.7669, 0.1221, 0.1110, 1.0000, 1.0000])\n",
      "tensor([0.8178, 0.1822, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 2.070920\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 1.928867\n",
      "penalty: 0.011011246591806412\n",
      "NN 3 : tensor(1.8416)\n",
      "CS 3 : 2.562\n",
      "DP 3 : 1.8656666666666666\n",
      "heuristic 3 : 1.8286666666666667\n",
      "DP: 1.8651759624481201\n",
      "tensor([0.0870, 0.0437, 0.0377, 0.0992, 0.7325])\n",
      "tensor([0.4213, 0.0447, 0.0368, 0.4972, 1.0000])\n",
      "tensor([0.7695, 0.1244, 0.1061, 1.0000, 1.0000])\n",
      "tensor([0.8074, 0.1926, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "loc 0.2 scale 0.1\n",
      "dp 4.783679008483887\n",
      "Supervised Aim: normal costsharing\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.000018\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 0.000000\n",
      "NN 1 : tensor(4.7280)\n",
      "CS 1 : 4.731333333333334\n",
      "DP 1 : 4.779333333333334\n",
      "heuristic 1 : 4.77\n",
      "DP: 4.783679008483887\n",
      "tensor([0.1998, 0.1999, 0.2008, 0.1989, 0.2006])\n",
      "tensor([0.2502, 0.2504, 0.2504, 0.2490, 1.0000])\n",
      "tensor([0.3355, 0.3339, 0.3306, 1.0000, 1.0000])\n",
      "tensor([0.5040, 0.4960, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 4.750284\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 4.761468\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(4.7312)\n",
      "CS 2 : 4.731333333333334\n",
      "DP 2 : 4.779333333333334\n",
      "heuristic 2 : 4.77\n",
      "DP: 4.783679008483887\n",
      "tensor([0.1967, 0.1959, 0.2204, 0.1900, 0.1969])\n",
      "tensor([0.2450, 0.2431, 0.2664, 0.2455, 1.0000])\n",
      "tensor([0.3235, 0.3276, 0.3489, 1.0000, 1.0000])\n",
      "tensor([0.5054, 0.4946, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 4.832699\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 4.780523\n",
      "penalty: 0.0\n",
      "NN 3 : tensor(4.7230)\n",
      "CS 3 : 4.731333333333334\n",
      "DP 3 : 4.779333333333334\n",
      "heuristic 3 : 4.77\n",
      "DP: 4.783679008483887\n",
      "tensor([0.1990, 0.1983, 0.2079, 0.2007, 0.1941])\n",
      "tensor([0.2490, 0.2405, 0.2547, 0.2558, 1.0000])\n",
      "tensor([0.3331, 0.3270, 0.3399, 1.0000, 1.0000])\n",
      "tensor([0.5101, 0.4899, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: normal dp\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.000042\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.000010\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 0.000012\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 0.000037\n",
      "NN 1 : tensor(4.7210)\n",
      "CS 1 : 4.731333333333334\n",
      "DP 1 : 4.779333333333334\n",
      "heuristic 1 : 4.77\n",
      "DP: 4.783679008483887\n",
      "tensor([0.2003, 0.1988, 0.2030, 0.1996, 0.1984])\n",
      "tensor([0.2496, 0.2443, 0.2530, 0.2531, 1.0000])\n",
      "tensor([0.3323, 0.3305, 0.3372, 1.0000, 1.0000])\n",
      "tensor([0.5076, 0.4924, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 4.689974\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 4.832386\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(4.7170)\n",
      "CS 2 : 4.731333333333334\n",
      "DP 2 : 4.779333333333334\n",
      "heuristic 2 : 4.77\n",
      "DP: 4.783679008483887\n",
      "tensor([0.1970, 0.2005, 0.2127, 0.1976, 0.1923])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2459, 0.2431, 0.2585, 0.2526, 1.0000])\n",
      "tensor([0.3267, 0.3302, 0.3430, 1.0000, 1.0000])\n",
      "tensor([0.5068, 0.4932, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 4.759440\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 4.805884\n",
      "penalty: 0.0\n",
      "NN 3 : tensor(4.7164)\n",
      "CS 3 : 4.731333333333334\n",
      "DP 3 : 4.779333333333334\n",
      "heuristic 3 : 4.77\n",
      "DP: 4.783679008483887\n",
      "tensor([0.1997, 0.1996, 0.2086, 0.1975, 0.1946])\n",
      "tensor([0.2487, 0.2434, 0.2526, 0.2554, 1.0000])\n",
      "tensor([0.3323, 0.3317, 0.3359, 1.0000, 1.0000])\n",
      "tensor([0.5078, 0.4922, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: normal heuristic\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 0.000000\n",
      "NN 1 : tensor(4.7330)\n",
      "CS 1 : 4.731333333333334\n",
      "DP 1 : 4.779333333333334\n",
      "heuristic 1 : 4.77\n",
      "DP: 4.783679008483887\n",
      "tensor([0.2001, 0.1997, 0.2022, 0.1988, 0.1993])\n",
      "tensor([0.2501, 0.2449, 0.2490, 0.2560, 1.0000])\n",
      "tensor([0.3348, 0.3344, 0.3308, 1.0000, 1.0000])\n",
      "tensor([0.5033, 0.4967, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 4.812282\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 4.717745\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(4.7212)\n",
      "CS 2 : 4.731333333333334\n",
      "DP 2 : 4.779333333333334\n",
      "heuristic 2 : 4.77\n",
      "DP: 4.783679008483887\n",
      "tensor([0.2000, 0.2009, 0.2112, 0.1969, 0.1911])\n",
      "tensor([0.2461, 0.2439, 0.2580, 0.2521, 1.0000])\n",
      "tensor([0.3257, 0.3306, 0.3437, 1.0000, 1.0000])\n",
      "tensor([0.5006, 0.4994, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 4.707200\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 4.788256\n",
      "penalty: 0.0\n",
      "NN 3 : tensor(4.7201)\n",
      "CS 3 : 4.731333333333334\n",
      "DP 3 : 4.779333333333334\n",
      "heuristic 3 : 4.77\n",
      "DP: 4.783679008483887\n",
      "tensor([0.1971, 0.1962, 0.2097, 0.1998, 0.1972])\n",
      "tensor([0.2458, 0.2396, 0.2561, 0.2584, 1.0000])\n",
      "tensor([0.3285, 0.3248, 0.3467, 1.0000, 1.0000])\n",
      "tensor([0.5077, 0.4923, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: normal random initializing\n",
      "do nothing\n",
      "do nothing\n",
      "NN 1 : tensor(4.7180)\n",
      "CS 1 : 4.731333333333334\n",
      "DP 1 : 4.779333333333334\n",
      "heuristic 1 : 4.77\n",
      "DP: 4.783679008483887\n",
      "tensor([0.1971, 0.1962, 0.2097, 0.1998, 0.1972])\n",
      "tensor([0.2458, 0.2396, 0.2561, 0.2584, 1.0000])\n",
      "tensor([0.3285, 0.3248, 0.3467, 1.0000, 1.0000])\n",
      "tensor([0.5077, 0.4923, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 4.770579\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 4.767777\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(4.7153)\n",
      "CS 2 : 4.731333333333334\n",
      "DP 2 : 4.779333333333334\n",
      "heuristic 2 : 4.77\n",
      "DP: 4.783679008483887\n",
      "tensor([0.1990, 0.1996, 0.2078, 0.2000, 0.1937])\n",
      "tensor([0.2468, 0.2419, 0.2535, 0.2578, 1.0000])\n",
      "tensor([0.3281, 0.3300, 0.3419, 1.0000, 1.0000])\n",
      "tensor([0.5064, 0.4936, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 4.773795\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 4.892706\n",
      "penalty: 0.0\n",
      "NN 3 : tensor(4.7178)\n",
      "CS 3 : 4.731333333333334\n",
      "DP 3 : 4.779333333333334\n",
      "heuristic 3 : 4.77\n",
      "DP: 4.783679008483887\n",
      "tensor([0.1941, 0.1961, 0.2114, 0.2040, 0.1944])\n",
      "tensor([0.2428, 0.2402, 0.2570, 0.2600, 1.0000])\n",
      "tensor([0.3222, 0.3269, 0.3509, 1.0000, 1.0000])\n",
      "tensor([0.5049, 0.4951, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "uniformlow 0 uniformhigh 1.0\n",
      "dp 1.6252939701080322\n",
      "Supervised Aim: uniform costsharing\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.000119\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 0.000002\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 0.000000\n",
      "NN 1 : tensor(1.4137)\n",
      "CS 1 : 1.4133333333333333\n",
      "DP 1 : 1.6383333333333334\n",
      "heuristic 1 : 1.533\n",
      "DP: 1.6252939701080322\n",
      "tensor([0.1999, 0.2001, 0.2003, 0.1994, 0.2003])\n",
      "tensor([0.2501, 0.2505, 0.2506, 0.2488, 1.0000])\n",
      "tensor([0.3329, 0.3335, 0.3336, 1.0000, 1.0000])\n",
      "tensor([0.4990, 0.5010, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 1.395293\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 1.341885\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.4147)\n",
      "CS 2 : 1.4133333333333333\n",
      "DP 2 : 1.6383333333333334\n",
      "heuristic 2 : 1.533\n",
      "DP: 1.6252939701080322\n",
      "tensor([0.1947, 0.2070, 0.1977, 0.2066, 0.1940])\n",
      "tensor([0.2388, 0.2575, 0.2466, 0.2570, 1.0000])\n",
      "tensor([0.3239, 0.3495, 0.3266, 1.0000, 1.0000])\n",
      "tensor([0.4843, 0.5157, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 1.423251\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 1.368114\n",
      "penalty: 0.0\n",
      "NN 3 : tensor(1.4139)\n",
      "CS 3 : 1.4133333333333333\n",
      "DP 3 : 1.6383333333333334\n",
      "heuristic 3 : 1.5330000000000001\n",
      "DP: 1.6252939701080322\n",
      "tensor([0.1902, 0.2034, 0.1976, 0.2087, 0.2001])\n",
      "tensor([0.2338, 0.2562, 0.2479, 0.2621, 1.0000])\n",
      "tensor([0.3147, 0.3518, 0.3335, 1.0000, 1.0000])\n",
      "tensor([0.4809, 0.5191, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: uniform dp\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.010304\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.004955\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 0.004375\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 0.001567\n",
      "NN 1 : tensor(1.5143)\n",
      "CS 1 : 1.4133333333333333\n",
      "DP 1 : 1.6383333333333334\n",
      "heuristic 1 : 1.533\n",
      "DP: 1.6252939701080322\n",
      "tensor([0.3140, 0.2849, 0.2262, 0.1451, 0.0298])\n",
      "tensor([0.3232, 0.2955, 0.2309, 0.1504, 1.0000])\n",
      "tensor([0.3494, 0.3528, 0.2978, 1.0000, 1.0000])\n",
      "tensor([0.4827, 0.5173, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 1.426997\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 1.413424\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.4645)\n",
      "CS 2 : 1.4133333333333333\n",
      "DP 2 : 1.6383333333333334\n",
      "heuristic 2 : 1.533\n",
      "DP: 1.6252939701080322\n",
      "tensor([0.2055, 0.2058, 0.1901, 0.1981, 0.2005])\n",
      "tensor([0.2474, 0.2530, 0.2419, 0.2577, 1.0000])\n",
      "tensor([0.3333, 0.3484, 0.3183, 1.0000, 1.0000])\n",
      "tensor([0.4939, 0.5061, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 1.328653\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 1.437533\n",
      "penalty: 0.0\n",
      "NN 3 : tensor(1.4459)\n",
      "CS 3 : 1.4133333333333333\n",
      "DP 3 : 1.6383333333333334\n",
      "heuristic 3 : 1.5330000000000001\n",
      "DP: 1.6252939701080322\n",
      "tensor([0.1926, 0.2015, 0.2017, 0.2021, 0.2022])\n",
      "tensor([0.2370, 0.2514, 0.2528, 0.2587, 1.0000])\n",
      "tensor([0.3160, 0.3476, 0.3364, 1.0000, 1.0000])\n",
      "tensor([0.4849, 0.5151, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: uniform heuristic\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 0.000026\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 0.000014\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 0.000016\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 0.000005\n",
      "NN 1 : tensor(1.4067)\n",
      "CS 1 : 1.4133333333333333\n",
      "DP 1 : 1.6383333333333334\n",
      "heuristic 1 : 1.533\n",
      "DP: 1.6252939701080322\n",
      "tensor([0.2015, 0.1988, 0.2022, 0.1988, 0.1989])\n",
      "tensor([0.2467, 0.2472, 0.2524, 0.2538, 1.0000])\n",
      "tensor([0.3251, 0.3384, 0.3365, 1.0000, 1.0000])\n",
      "tensor([0.4962, 0.5038, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 1.335676\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 1.438723\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.4098)\n",
      "CS 2 : 1.4133333333333333\n",
      "DP 2 : 1.6383333333333334\n",
      "heuristic 2 : 1.533\n",
      "DP: 1.6252939701080322\n",
      "tensor([0.1964, 0.2045, 0.1975, 0.1984, 0.2032])\n",
      "tensor([0.2420, 0.2543, 0.2494, 0.2544, 1.0000])\n",
      "tensor([0.3183, 0.3504, 0.3313, 1.0000, 1.0000])\n",
      "tensor([0.4863, 0.5137, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 1.487635\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 1.282403\n",
      "penalty: 0.0\n",
      "NN 3 : tensor(1.4091)\n",
      "CS 3 : 1.4133333333333333\n",
      "DP 3 : 1.6383333333333334\n",
      "heuristic 3 : 1.5330000000000001\n",
      "DP: 1.6252939701080322\n",
      "tensor([0.1977, 0.2006, 0.1966, 0.2057, 0.1994])\n",
      "tensor([0.2407, 0.2518, 0.2468, 0.2607, 1.0000])\n",
      "tensor([0.3179, 0.3519, 0.3302, 1.0000, 1.0000])\n",
      "tensor([0.4868, 0.5132, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n",
      "Supervised Aim: uniform random initializing\n",
      "do nothing\n",
      "do nothing\n",
      "NN 1 : tensor(1.4077)\n",
      "CS 1 : 1.4133333333333333\n",
      "DP 1 : 1.6383333333333334\n",
      "heuristic 1 : 1.533\n",
      "DP: 1.6252939701080322\n",
      "tensor([0.1977, 0.2006, 0.1966, 0.2057, 0.1994])\n",
      "tensor([0.2407, 0.2518, 0.2468, 0.2607, 1.0000])\n",
      "tensor([0.3179, 0.3519, 0.3302, 1.0000, 1.0000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4868, 0.5132, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 1.385183\n",
      "Train Epoch: 1 [2560/3000 (83%)]\tLoss: 1.508479\n",
      "penalty: 0.0\n",
      "NN 2 : tensor(1.4063)\n",
      "CS 2 : 1.4133333333333333\n",
      "DP 2 : 1.6383333333333334\n",
      "heuristic 2 : 1.533\n",
      "DP: 1.6252939701080322\n",
      "tensor([0.1972, 0.2015, 0.2027, 0.2040, 0.1946])\n",
      "tensor([0.2372, 0.2521, 0.2532, 0.2575, 1.0000])\n",
      "tensor([0.3113, 0.3560, 0.3328, 1.0000, 1.0000])\n",
      "tensor([0.4826, 0.5174, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 1.638316\n",
      "Train Epoch: 2 [2560/3000 (83%)]\tLoss: 1.475922\n",
      "penalty: 0.0\n",
      "NN 3 : tensor(1.4059)\n",
      "CS 3 : 1.4133333333333333\n",
      "DP 3 : 1.6383333333333334\n",
      "heuristic 3 : 1.5330000000000001\n",
      "DP: 1.6252939701080322\n",
      "tensor([0.1965, 0.2028, 0.2005, 0.2053, 0.1948])\n",
      "tensor([0.2345, 0.2581, 0.2497, 0.2577, 1.0000])\n",
      "tensor([0.3039, 0.3672, 0.3289, 1.0000, 1.0000])\n",
      "tensor([0.4761, 0.5239, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for order in stage:\n",
    "    producedata(order)\n",
    "\n",
    "    # for mapping binary to payments before softmax\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(n, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, n),\n",
    "    )\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "                \n",
    "    #running\n",
    "    for order1 in range(len(order1name)):\n",
    "        print(\"Supervised Aim:\",order,order1name[order1])\n",
    "\n",
    "        runningLossNN = []\n",
    "        runningLossCS = []\n",
    "        runningLossDP = []\n",
    "        runningLossHeuristic = []\n",
    "        \n",
    "        for batch_idx, (tp_batch,) in enumerate(tp_dataloader_testing):\n",
    "            penalty = 0\n",
    "            for bitsMoreOnes in allBits:\n",
    "                for i in range(n):\n",
    "                    if bitsMoreOnes[i] == 1:\n",
    "                        bitsLessOnes = bitsMoreOnes.clone()\n",
    "                        bitsLessOnes[i] = 0\n",
    "                        penalty = penalty + sum(\n",
    "                                torch.relu(\n",
    "                                    bitsToPayments(bitsMoreOnes) - bitsToPayments(bitsLessOnes)\n",
    "                                )\n",
    "                            )\n",
    "            loss = penalty * penaltyLambda\n",
    "            for tp in tp_batch:\n",
    "                    for i in range(n):\n",
    "                        tp1 = tp.clone()\n",
    "                        tp1[i] = 1\n",
    "                        tp0 = tp.clone()\n",
    "                        tp0[i] = 0\n",
    "                        offer = tpToPayments(tp1)[i]\n",
    "                        delay1 = tpToTotalDelay(tp1)\n",
    "                        delay0 = tpToTotalDelay(tp0)\n",
    "                        #loss = loss + (1 - cdf(offer)) * delay1 + cdf(offer) * delay0\n",
    "                        loss = loss + (1 - cdf(offer,order)) * delay1 + cdf(offer,order) * delay0\n",
    "\n",
    "            tp1 = tp.clone()\n",
    "            tp1[0] = 1\n",
    "            tp0 = tp.clone()\n",
    "            tp0[0] = 0\n",
    "            offer = tpToPayments(tp1)[0]\n",
    "            break;\n",
    "        #model=torch.load(\"save/pytorchNN=5dp1\");\n",
    "        #model.eval()\n",
    "        for epoch in range(1, supervisionEpochs + 1):\n",
    "#             print(\"distributionRatio\",distributionRatio)\n",
    "            if(order1==0):\n",
    "                supervisionTrain(epoch, costSharingSupervisionRule)\n",
    "            elif(order1==1):\n",
    "                supervisionTrain(epoch, dpSupervisionRule)\n",
    "            elif(order1==2):\n",
    "                supervisionTrain(epoch, heuristicSupervisionRule)\n",
    "            elif(order1==3):\n",
    "                print(\"do nothing\");\n",
    "\n",
    "        test()\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train(epoch)\n",
    "            test()\n",
    "\n",
    "        savepath=\"save/pytorchNN=5all\"+order+str(order1)\n",
    "        torch.save(model, savepath);\n",
    "        print(\"end\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
