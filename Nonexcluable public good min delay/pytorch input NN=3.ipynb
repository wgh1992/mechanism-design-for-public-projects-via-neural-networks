{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3540388371733616\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from random import randint\n",
    "import random\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "global  samplesJoint,tp_dataloader,tp_dataloader_testing,dp,decision,dp_H,decision_H\n",
    "from pylab import *\n",
    "from scipy.stats import beta\n",
    "import math\n",
    "n = 3\n",
    "epochs = 1\n",
    "supervisionEpochs = 1\n",
    "lr = 0.0005\n",
    "log_interval = 20\n",
    "trainSize = 60000#100000\n",
    "percentage_train_test= 0.25\n",
    "penaltyLambda = 10\n",
    "doublePeakHighMean = 0.9\n",
    "doublePeakLowMean = 0.1\n",
    "doublePeakStd = 0.1\n",
    "uniformlow=0\n",
    "uniformhigh=1.0\n",
    "normalloc = 0.2\n",
    "normalscale = 0.1\n",
    "\n",
    "cauchyloc = 1/n\n",
    "cauchyscalen = 0.004\n",
    "\n",
    "exponentialhigh = 15 #Symbol(\"b\", real=True)\n",
    "exponentiallow  = 15 #Symbol(\"a\", real=True)\n",
    "\n",
    "\n",
    "beta_a = 0.1\n",
    "beta_b  = 0.1\n",
    "kumaraswamy_a = beta_a \n",
    "kumaraswamy_b = (1.0+(beta_a-1.0)*math.pow( (beta_a+beta_b-2.0)/(beta_a-1.0), beta_a) )/beta_a \n",
    "print(kumaraswamy_b)\n",
    "\n",
    "independentnormalloc1=[(float(ii)+1)/(2*n+1) for ii in range(n,0,-1)]\n",
    "independentnormalscale1=[0.05 for ii in range(n)]\n",
    "\n",
    "independentnormalloc2=[(float(ii)+1)/(2*n+1) for ii in range(1,n+1,1)]\n",
    "independentnormalscale2=[0.05 for ii in range(n)]\n",
    "stage=[\"twopeak\"]\n",
    "order=\"twopeak\"\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"beta\",\"U-exponential\",\"arcsine\"\n",
    "order1name=[\"costsharing\",\"random initializing\",\"dp\"]\n",
    "#order1name=[\"random initializing1\",\"random initializing2\",\"random initializing3\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = D.normal.Normal(doublePeakLowMean, doublePeakStd)\n",
    "d2 = D.normal.Normal(doublePeakHighMean, doublePeakStd)\n",
    "distributionRatio1 = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase1 = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(normalloc, normalscale)\n",
    "distributionRatio3 = d3.cdf(1) - d3.cdf(0)\n",
    "distributionBase3 = d3.cdf(0)\n",
    "\n",
    "d4 = D.uniform.Uniform(uniformlow,uniformhigh)\n",
    "distributionRatio4 = d4.cdf(1) - d4.cdf(0)\n",
    "distributionBase4 = d4.cdf(0)\n",
    "\n",
    "d5 = [D.normal.Normal(independentnormalloc1[ii], independentnormalscale1[ii]) for ii in range(n)]\n",
    "d6 = [D.normal.Normal(independentnormalloc2[ii], independentnormalscale2[ii]) for ii in range(n)]\n",
    "\n",
    "d7 = D.cauchy.Cauchy(cauchyloc,cauchyscalen)\n",
    "\n",
    "d81 = D.exponential.Exponential(exponentiallow)\n",
    "d82 = D.exponential.Exponential(exponentialhigh)\n",
    "\n",
    "d9 = D.beta.Beta(beta_a,beta_b)\n",
    "#sample_d9=d9.rsample(torch.Size([100000]))\n",
    "\n",
    "#d9_sample=np.linspace(0.0001, 0.9999, 10000)\n",
    "#d9_pdf=torch.exp(d9.log_prob(torch.tensor(d9_sample,dtype=torch.float32)))\n",
    "#d9_delta=d9_sample[1]-d9_sample[0]\n",
    "#d9_sum_pdf=torch.sum(d9_pdf*d9_delta)\n",
    "\n",
    "d10 = D.beta.Beta(0.5,0.5)\n",
    "\n",
    "def cdf(x,y, i=None):\n",
    "    if(y==\"twopeak\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) - distributionBase1) / 2 / distributionRatio1\n",
    "    elif(y==\"normal\"):\n",
    "        return (d3.cdf(x)-distributionBase3)/distributionRatio3;\n",
    "    elif(y==\"uniform\"):\n",
    "        return (d4.cdf(x)-distributionBase4)/distributionRatio4;\n",
    "    elif(y==\"independent1\"):\n",
    "        return d5[i].cdf(x);\n",
    "    elif(y==\"independent2\"):\n",
    "        return d6[i].cdf(x);\n",
    "    elif(y==\"cauchy\"):\n",
    "        return d7.cdf(x);\n",
    "    elif(y==\"beta\"):\n",
    "#         sum_cdf=0.0;\n",
    "#         if(x<0.0001):\n",
    "#             x=0.00011;\n",
    "#         if(x>0.9999):\n",
    "#             x=0.99989;\n",
    "#         for i in range(len(d9_pdf)):\n",
    "#             if(d9_sample[i]<x):\n",
    "#                 sum_cdf+=d9_pdf[i]*d9_delta;\n",
    "#             else:\n",
    "#                 sum_cdf+=(d9_pdf[i]+d9_pdf[i-1])/ 2 *(x-d9_sample[i-1])\n",
    "#                 break;\n",
    "#         return sum_cdf/d9_sum_pdf\n",
    "#         cdf_v=torch.sum((sample_d9<(x)), dtype=torch.float32)/100000\n",
    "#         return cdf_v\n",
    "#    F(x|a,b)=1–(1–x^a)^b\n",
    "        if(x<0.0000001):\n",
    "            x=0.0000001\n",
    "        elif(x >0.9999999):\n",
    "            x=0.9999999\n",
    "        try:\n",
    "            return 1.0-torch.pow(1.0-torch.pow(x,kumaraswamy_a),kumaraswamy_b);\n",
    "        except:\n",
    "            return 1.0-torch.pow(1.0-torch.pow(torch.tensor(x,dtype=torch.float32),kumaraswamy_a),kumaraswamy_b);\n",
    "    elif(y==\"arcsine\"):\n",
    "        #\n",
    "        if(x<0.0000001):\n",
    "            x=0.0000001\n",
    "        elif(x >0.9999999):\n",
    "            x=0.9999999\n",
    "        try:\n",
    "            res=2.0/math.pi * torch.asin(torch.sqrt(x))\n",
    "            #print(x)\n",
    "            return res# + 0.0001*1.0/(\n",
    "            #math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "        except:\n",
    "            return 2.0/math.pi * torch.asin(torch.sqrt(torch.tensor(x,dtype=torch.float32)))# + 0.0001*1.0/(\n",
    "            #math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "    elif(y==\"U-exponential\"):\n",
    "        return (d81.cdf(x) + (1.0 - d82.cdf(1.0-x)))  / 2 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2585742771625519\n",
      "2.2242771685123444\n"
     ]
    }
   ],
   "source": [
    "dpPrecision = 100\n",
    "# howManyPpl left, money left, yes already\n",
    "dp = np.zeros([n + 1, dpPrecision + 1])\n",
    "decision = np.zeros([n + 1, dpPrecision + 1], dtype=np.uint8)\n",
    "# ppl = 0 left\n",
    "for money in range(dpPrecision + 1):\n",
    "    if money == 0:\n",
    "        dp[0, 0] = 1\n",
    "    else:\n",
    "        offer = money / dpPrecision\n",
    "        dp[0, money] = 0#cdf(offer)# + 1.0\n",
    "for ppl in range(1, n + 1):\n",
    "    for money in range(dpPrecision + 1):\n",
    "        maxSoFar = -1_000_000\n",
    "        for offerIndex in range(money + 1):\n",
    "            offer = offerIndex / dpPrecision\n",
    "            res = (1-cdf(offer,order)) * dp[\n",
    "                 ppl - 1, money - offerIndex\n",
    "                ]\n",
    "            if maxSoFar < res:\n",
    "                maxSoFar = res\n",
    "                decision[ppl, money] = offerIndex\n",
    "        dp[ppl, money] = maxSoFar\n",
    "print(dp[n, dpPrecision])\n",
    "print(n*(1-dp[n, dpPrecision]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAASMklEQVR4nO3dbaxc113v8e+PuA2FVmlKTiLLCThUBppgmoIJEeWitLklae4LtxJILqhYqMggUlQQL3B4QYOQpYDEg67uDcjQqL4SNIpoufG9KYUoPJSqD+EEpUmcEGKa0rix4tMWKA9SkN0/L85uGJw5PnPOPO413490NDNr9j7zX57xb9asWXufVBWSpLZ8zbwLkCRNnuEuSQ0y3CWpQYa7JDXIcJekBu2YdwEAl112We3evXveZUhSrzz88MNfqKqVYfctRLjv3r2b1dXVeZchSb2S5O83us9pGUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMN9QvYe2zvvEiTpRYa7JDXIcJekBhnuktTZffj+eZcwMYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatCm4Z7ka5M8lOTTSU4k+aWu/TVJHkjydHd56cA+tyc5meSpJDdPswOSpJcaZeT+AvDmqno9cB1wS5IbgMPAg1W1B3iwu02Sa4ADwLXALcBdSS6aRvHT5ikFJPXVpuFe6/6lu/my7qeA/cCxrv0Y8Lbu+n7gnqp6oaqeAU4C10+0aknSBY00557koiSPAGeAB6rqU8AVVXUaoLu8vNt8F/DswO6nurbzf+ehJKtJVtfW1sbpgyTpPCOFe1Wdq6rrgCuB65N8+wU2z7BfMeR3Hq2qfVW1b2VlZbRqJUkj2dJqmar6R+DPWZ9Lfz7JToDu8ky32SngqoHdrgSeG7vSebnjknlXIGmeepoBo6yWWUny6u76K4D/DvwNcBw42G12ELivu34cOJDk4iRXA3uAhyZduCRtW08Deyt2jLDNTuBYt+Lla4B7q+r/J/kEcG+SdwGfA34IoKpOJLkXeAI4C9xWVeemU74kaZhNw72qHgXeMKT9i8BNG+xzBDgydnUN2HtsL48dfGzeZUhaMh6hug2uf5eWSx/P8264j8hAl9Qnhvsk3XFJL9/hpWWy2UCtlYGc4b5NgyFuoEv91EqQD2O4S1KDDHdJy2EJ1rYPMtwlqUGGu6Sl1up3Zoa7JEFz0zZLH+5D37Ube5IlLZ+lD3dJbWt12mUzhrskna/79N7ndfCG+3m2/GQ6hSMtnGUdrQ8y3LdgSy8YQ1+aqRf/f/p/DzDcJWlbFv3TgeE+YNpPVp/n76Rl0/eVdIa7JDXIcJ+BRf/4Jqk9hrskNchwl6QGGe6Ses/FCi9luEvSmBbxe7VNwz3JVUn+LMmTSU4keU/XfkeSzyd5pPu5dWCf25OcTPJUkpun2YGJmeASJ0cR0oKY0tLFPvwfH2Xkfhb4uap6HXADcFuSa7r7fqOqrut+PgzQ3XcAuBa4BbgryUVTqH1s836Cdh++f+41SGrTpuFeVaer6q+76/8MPAnsusAu+4F7quqFqnoGOAlcP4liJ2bRDkRYtHqkRi3i9Mm0bGnOPclu4A3Ap7qmdyd5NMndSS7t2nYBzw7sdoohbwZJDiVZTbK6tra25cIlSRsbOdyTvBL4IPAzVfVl4LeA1wLXAaeBX/vqpkN2r5c0VB2tqn1VtW9lZWXLhUvSQljQT94jhXuSl7Ee7L9XVR8CqKrnq+pcVX0F+B3+c+rlFHDVwO5XAs9NruTZWKaPb5LaM8pqmQDvA56sql8faN85sNnbgce768eBA0kuTnI1sAd4aHIlS5I2M8rI/Y3AO4E3n7fs8VeTPJbkUeBNwM8CVNUJ4F7gCeAjwG1VdW465fePnwikydh7bO9Mp0RGWtm2QFM0OzbboKo+xvB59A9fYJ8jwJEx6pIkjcEjVCWpQYa7JE3Qoky9Gu4L4vwXhEeuShqH4T4vC/TFi9S6ZRwsGe6SNAGL9gZiuEvStM3hk7rhLkkTtgijeMN90TgXL2kCli7cF+EdVdIWOejZsqULd0map1mtgzfcJalBzYe7f8pOasOiHPnZF82HuyQtI8N9gTlSkXpszl8CG+6SNEXzmhY23CVpRmYZ9Ia7pN5wccToDPcF4gtX0qQY7pLUIMNdkhpkuEtSg9oOd082JGlJtR3ukrSkNg33JFcl+bMkTyY5keQ9XftrkjyQ5Onu8tKBfW5PcjLJU0lunmYHJDVqo0/ed1zi0dsjGGXkfhb4uap6HXADcFuSa4DDwINVtQd4sLtNd98B4FrgFuCuJBdNo/gLcVmhpGW2abhX1emq+uvu+j8DTwK7gP3AsW6zY8Dbuuv7gXuq6oWqegY4CVw/6cIlSRvb0px7kt3AG4BPAVdU1WlYfwMALu822wU8O7Dbqa7t/N91KMlqktW1tbWtVy5J2tDI4Z7klcAHgZ+pqi9faNMhbfWShqqjVbWvqvatrKyMWoYkaQQjhXuSl7Ee7L9XVR/qmp9PsrO7fydwpms/BVw1sPuVwHOTKXcMfV4W2efaJc3FKKtlArwPeLKqfn3gruPAwe76QeC+gfYDSS5OcjWwB3hociVvzm/SJS27UUbubwTeCbw5ySPdz63AncBbkjwNvKW7TVWdAO4FngA+AtxWVeemUv0wjnIliR2bbVBVH2P4PDrATRvscwQ4MkZdW7b78P189s7/McuHlKSF5RGqktQgw12SGmS495RH4GoZuDhi+wx3SWqQ4S5JDTLcJalBhrskNchw7wm/WJK0FYa7JDXIcJekBhnuPTQ4ReN0jaRhDHdJapDhLknzMOUz2BrukubPU3VPXBPh7nlWpHb4PdJkNBHuwpGPeskgnx7DvQF+clGfDb5+fS1PjuEuSQ0y3PvMqRhJGzDcJalBhnvfOFqXNALDXZIatGm4J7k7yZkkjw+03ZHk80ke6X5uHbjv9iQnkzyV5OZpFS5JfTfNpaCjjNzfD9wypP03quq67ufDAEmuAQ4A13b73JXkokkVK0kazabhXlUfBb404u/bD9xTVS9U1TPASeD6MeqTJG3DOHPu707yaDdtc2nXtgt4dmCbU13bSyQ5lGQ1yera2toYZUjqGw9Wmr7thvtvAa8FrgNOA7/WtWfItjXsF1TV0araV1X7VlZWtlmGpN5y5ddUbSvcq+r5qjpXVV8Bfof/nHo5BVw1sOmVwHPjlShJ2qpthXuSnQM33w58dSXNceBAkouTXA3sAR4ar0RJ0lbt2GyDJB8AbgQuS3IKeC9wY5LrWJ9y+SzwEwBVdSLJvcATwFngtqo6N53SNczeY3t57OBj8y5D0pxtGu5V9Y4hze+7wPZHgCPjFCVJGo9HqEpSgwx3SWqQ4S5JDTLcJalBhrukmfLvps6G4S5JDTLcJalBhrskNchwl6QGGe6SZsczQc6M4S5JDTLcJalBhrskNchwl6QGGe6N82hAzYuvvfky3CVNlX8Mez4Md0lqkOEuSQ0y3CVNnfPvs2e4S1KDDPcGOUqSZLi3zPN4SEvLcJekBm0a7knuTnImyeMDba9J8kCSp7vLSwfuuz3JySRPJbl5WoVre1xzLC2HUUbu7wduOa/tMPBgVe0BHuxuk+Qa4ABwbbfPXUkumli1mhjn5aW2bRruVfVR4EvnNe8HjnXXjwFvG2i/p6peqKpngJPA9ROqVZI0ou3OuV9RVacBusvLu/ZdwLMD253q2l4iyaEkq0lW19bWtlmGJGmYSX+hmiFtNWzDqjpaVfuqat/KysqEy5Ck5bbdcH8+yU6A7vJM134KuGpguyuB57ZfniRpO7Yb7seBg931g8B9A+0Hklyc5GpgD/DQeCVKkrZqx2YbJPkAcCNwWZJTwHuBO4F7k7wL+BzwQwBVdSLJvcATwFngtqo6N6XaJUkb2DTcq+odG9x10wbbHwGOjFOUpmP34ft51evmXYWkWfAI1WXkaQmk5hnuy8JA1wx5JPT8Ge6S1CDDXZIaZLhLUoMMd0lqkOG+xPzSS2qX4S5JDTLcJU2OS24XhuEuaWz+8ZfFY7gvO0daUpMMd0nb5pfyi8twlzQRBv1iMdwlbYvz7IvNcJekBhnuksbjl/ILyXAX4Hyp1BrDXZIaZLjrRX5BJrXDcJekBhnuGmr34fudh9dL+OmuPwx3SWrQWOGe5LNJHkvySJLVru01SR5I8nR3eelkStVcuMxN6qVJjNzfVFXXVdW+7vZh4MGq2gM82N2W1AMXmnZxmq5fpjEtsx841l0/BrxtCo8haZo2+8TmJ7qFN264F/AnSR5Ocqhru6KqTgN0l5cP2zHJoSSrSVbX1tbGLEPSNDha768dY+7/xqp6LsnlwANJ/mbUHavqKHAUYN++fTVmHZKkAWON3Kvque7yDPCHwPXA80l2AnSXZ8YtUvPl8rcl5xRML2073JN8fZJXffU68APA48Bx4GC32UHgvnGLlCRtzTgj9yuAjyX5NPAQcH9VfQS4E3hLkqeBt3S31QhH8VI/bHvOvao+A7x+SPsXgZvGKUpzdsclwO/PuwpJY/AIVUlqkOEuaZ1fnDbFcNdIXO8s9YvhrrEY+tJiMty1ZQa6tPgMd22P87PN8s27DYa7Jsp18P1koLfHcJekBhnuGp1TMU04f5Tup602Ge7Sshh4czbQ22e4a2wGhbR4DHdNh1M4/eDz1CzDXZIaZLhrchwFSgvDcJekBhnuktQgw10T59GO87f78P0+D0vOcJca4ZJUDTLcNTUvho1ftM5P92/vKH75GO6aqo1CxbCZMN9AdR7DXbM17BD4Oy5xSmFCfNPUVxnumpnNgsdg2poN/70cxQvDXeoNV8BoK6YW7kluSfJUkpNJDk/rcdSYIVM0rQfasP69pG2D0bjTWdrIVMI9yUXA/wbeClwDvCPJNdN4LLVp77G9m08vbHL/or4pDAvkLYW00y4awbRG7tcDJ6vqM1X178A9wP4pPZaWwcCSvsEgfHGqYnDJ31bCbxtBeaE3jaHLP4fUtmGdg59cuuuL+ialxZaqmvwvTX4QuKWqfry7/U7ge6rq3QPbHAIOdTe/FXhqmw93GfCFMcrtI/u8HOzzchinz99UVSvD7tix/XouKEPa/su7SFUdBY6O/UDJalXtG/f39Il9Xg72eTlMq8/TmpY5BVw1cPtK4LkpPZYk6TzTCve/AvYkuTrJy4EDwPEpPZYk6TxTmZapqrNJ3g38MXARcHdVnZjGYzGBqZ0ess/LwT4vh6n0eSpfqEqS5ssjVCWpQYa7JDWoN+G+2ekMsu5/dvc/muQ751HnJI3Q5x/p+vpoko8nef086pykUU9bkeS7k5zrjqnotVH6nOTGJI8kOZHkL2Zd46SN8Nq+JMn/S/Lprs8/No86JyXJ3UnOJHl8g/snn19VtfA/rH8p+3fANwMvBz4NXHPeNrcCf8T6GvsbgE/Nu+4Z9Pl7gUu7629dhj4PbPenwIeBH5x33TN4nl8NPAF8Y3f78nnXPYM+/wLwK931FeBLwMvnXfsYff5+4DuBxze4f+L51ZeR+yinM9gP/J9a90ng1Ul2zrrQCdq0z1X18ar6h+7mJ1k/nqDPRj1txU8DHwTOzLK4KRmlzz8MfKiqPgdQVX3v9yh9LuBVSQK8kvVwPzvbMienqj7Keh82MvH86ku47wKeHbh9qmvb6jZ9stX+vIv1d/4+27TPSXYBbwd+e4Z1TdMoz/O3AJcm+fMkDyf50ZlVNx2j9Pl/Aa9j/eDHx4D3VNVXZlPeXEw8v6Z1+oFJ2/R0BiNu0ycj9yfJm1gP9++bakXTN0qffxP4+ao6tz6o671R+rwD+C7gJuAVwCeSfLKq/nbaxU3JKH2+GXgEeDPwWuCBJH9ZVV+ednFzMvH86ku4j3I6g9ZOeTBSf5J8B/C7wFur6oszqm1aRunzPuCeLtgvA25Ncraq/u9sSpy4UV/bX6iqfwX+NclHgdcDfQ33Ufr8Y8CdtT4hfTLJM8C3AQ/NpsSZm3h+9WVaZpTTGRwHfrT71vkG4J+q6vSsC52gTfuc5BuBDwHv7PEobtCmfa6qq6tqd1XtBv4A+KkeBzuM9tq+D/hvSXYk+Trge4AnZ1znJI3S58+x/kmFJFewfubYz8y0ytmaeH71YuReG5zOIMlPdvf/NusrJ24FTgL/xvo7f2+N2OdfBL4BuKsbyZ6tHp9Rb8Q+N2WUPlfVk0k+AjwKfAX43aoauqSuD0Z8nn8ZeH+Sx1ifsvj5qurtqYCTfAC4EbgsySngvcDLYHr55ekHJKlBfZmWkSRtgeEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGvQf2JnzGZNKpwAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "signals = np.random.randint(2, size=(trainSize, n))\n",
    "# samples1 = np.random.uniform(low=0.1, high=0.2, size=(trainSize, n))\n",
    "# samples2 = np.random.uniform(low=0.8, high=0.9, size=(trainSize, n))\n",
    "samples1 = np.random.normal(\n",
    "    loc=doublePeakLowMean, scale=doublePeakStd, size=(trainSize, n)\n",
    ")\n",
    "for i in range(trainSize):\n",
    "    for j in range(n):\n",
    "        while samples1[i, j] < 0 or samples1[i, j] > 1:\n",
    "            samples1[i, j] = np.random.normal(\n",
    "                loc=doublePeakLowMean, scale=doublePeakStd\n",
    "            )\n",
    "samples2 = np.random.normal(\n",
    "    loc=doublePeakHighMean, scale=doublePeakStd, size=(trainSize, n)\n",
    ")\n",
    "for i in range(trainSize):\n",
    "    for j in range(n):\n",
    "        while samples2[i, j] < 0 or samples2[i, j] > 1:\n",
    "            samples2[i, j] = np.random.normal(\n",
    "                loc=doublePeakHighMean, scale=doublePeakStd\n",
    "            )\n",
    "samplesJoint = signals * samples1 - (signals - 1) * samples2\n",
    "tp_tensor = torch.tensor(samplesJoint, dtype=torch.float32)\n",
    "# tp_tensor = torch.tensor(np.random.rand(10000, n), dtype=torch.float32)\n",
    "tp_dataset = TensorDataset(tp_tensor[: int(trainSize * percentage_train_test)])\n",
    "tp_dataset_testing = TensorDataset(tp_tensor[int(trainSize * (1.0-percentage_train_test)) :])\n",
    "tp_dataloader = DataLoader(tp_dataset, batch_size=128, shuffle=True)\n",
    "tp_dataloader_testing = DataLoader(tp_dataset_testing, batch_size=256, shuffle=False)\n",
    "plt.hist(samplesJoint,bins=500)\n",
    "plt.show()\n",
    "runningLossNN = []\n",
    "runningLossCS = []\n",
    "runningLossDP = []\n",
    "# for mapping binary to payments before softmax\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, n),\n",
    ")\n",
    "\n",
    "model.apply(init_weights)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    bits = bits.type(torch.float32)\n",
    "    payments = model(torch.ones(n))\n",
    "    payments = torch.softmax(payments, 0)\n",
    "    return payments\n",
    "\n",
    "\n",
    "def tpToBits(tp, bits=torch.ones(n).type(torch.uint8)):\n",
    "    payments = bitsToPayments(bits)\n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    \n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return bits-bits#tpToBits(tp, newBits)\n",
    "\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp))\n",
    "\n",
    "\n",
    "def tpToTotalDelay(tp):\n",
    "    if torch.sum(tpToBits(tp).type(torch.float32))==n:\n",
    "        return 0\n",
    "    else:\n",
    "        return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_dp(temp,debug):\n",
    "    if(debug==1):\n",
    "        print(temp)\n",
    "    remain=dpPrecision\n",
    "    ans =0;\n",
    "    o_list=[];\n",
    "    remain_list=[];\n",
    "    for ppl in range(n,0,-1):\n",
    "        o=decision[ppl, remain]\n",
    "        if(debug==1):\n",
    "            print(o,remain)\n",
    "        o_list.append(o)\n",
    "        remain_list.append(remain);\n",
    "        if(o<temp[n-ppl]):\n",
    "            remain-=int(o);\n",
    "        elif (remain>0):\n",
    "            ans=n;\n",
    "    if(remain<=1):\n",
    "        return ans,o_list;\n",
    "    else:\n",
    "        return n,o_list;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.23704026 94.12288772 84.11094679]\n",
      "79 100\n",
      "47 100\n",
      "53 53\n",
      "(3, [79, 47, 53])\n",
      "[10.44850461 96.88123534 87.92691944]\n",
      "79 100\n",
      "47 100\n",
      "53 53\n",
      "(3, [79, 47, 53])\n",
      "[28.01536789 78.17133656 11.7824142 ]\n",
      "79 100\n",
      "47 100\n",
      "53 53\n",
      "(3, [79, 47, 53])\n",
      "[95.33046895  2.85769372 17.02045414]\n",
      "79 100\n",
      "10 21\n",
      "21 21\n",
      "(3, [79, 10, 21])\n",
      "[18.31190411 81.41590757 94.15467224]\n",
      "79 100\n",
      "47 100\n",
      "53 53\n",
      "(3, [79, 47, 53])\n",
      "2.219190404797601\n"
     ]
    }
   ],
   "source": [
    "ans_list=[];\n",
    "for i in range(5):\n",
    "    temp=samplesJoint[i]*dpPrecision\n",
    "    #print(temp)\n",
    "    tempres=plan_dp(temp,1)\n",
    "    ans_list.append(tempres[0]);\n",
    "    print(tempres)\n",
    "    #print(\"\\n\",temp)\n",
    "    #print(plan_dp(temp,1))\n",
    "for i in range(10000):\n",
    "    temp=samplesJoint[i]*dpPrecision\n",
    "    #print(temp)\n",
    "    ans_list.append(plan_dp(temp,0)[0]);\n",
    "    #print(\"\\n\",temp)\n",
    "    #print(plan_dp(temp))\n",
    "print(sum(ans_list)/len(ans_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpSupervisionRule(tp):\n",
    "    tp = list(tp.numpy())\n",
    "    bits = [1 for ii in range(n)]\n",
    "    payments = [0 for ii in range(n)]\n",
    "    money = dpPrecision\n",
    "    yes = 0\n",
    "    for i in range(n):\n",
    "        offerIndex = decision[n - i, money]\n",
    "        offer = offerIndex / dpPrecision\n",
    "        if tp[i] >= offer:\n",
    "            money -= offerIndex\n",
    "            yes += 1\n",
    "            bits[i] = 1\n",
    "            payments[i] = offer\n",
    "        else:\n",
    "            bits = [0 for ii in range(n)]\n",
    "            payments = [1 for ii in range(n)]\n",
    "            money=1\n",
    "            #bits[i] = 0\n",
    "            #payments[i] = 0#1\n",
    "            break\n",
    "    if money > 0:\n",
    "        bits = [0 for ii in range(n)]\n",
    "        payments = [1 for ii in range(n)]\n",
    "\n",
    "    bits = torch.tensor(bits, dtype=torch.float32)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    # print()\n",
    "    # print(tp)\n",
    "    # print(bits)\n",
    "    # print(payments)\n",
    "    # print()\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def costSharingSupervisionRule(tp):\n",
    "    tp = list(tp.numpy())\n",
    "    #for k in range(n, -1, -1):\n",
    "    k=n;\n",
    "    bits = [1 if tp[ii] >= 1 / k else 0 for ii in range(n)]\n",
    "    payments = [1 / k  for ii in range(n)]\n",
    "        \n",
    "    bits = torch.tensor(bits, dtype=torch.uint8)\n",
    "    payments = torch.tensor(payments, dtype=torch.float32)\n",
    "    return (bits, payments)\n",
    "\n",
    "\n",
    "def costSharingDelay(tp):\n",
    "    if torch.sum(costSharingSupervisionRule(tp)[0]).item() == n:\n",
    "        return 0\n",
    "    else:\n",
    "        return n;\n",
    "\n",
    "def dpDelay(tp):\n",
    "    if torch.sum(dpSupervisionRule(tp)[0]).item() == n:\n",
    "        return 0\n",
    "    else:\n",
    "        return n;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0750, 0.1933, 0.3376])\n",
      "3\n",
      "(tensor([0, 0, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.8344, 0.0357, 0.7964])\n",
      "3\n",
      "(tensor([1, 0, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.9362, 0.9183, 0.8351])\n",
      "0\n",
      "(tensor([1, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "3\n",
      "\n",
      "\n",
      "tensor([0.0583, 0.8785, 0.0483])\n",
      "3\n",
      "(tensor([0, 1, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.9360, 0.9420, 0.1949])\n",
      "3\n",
      "(tensor([1, 1, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.8792, 0.9745, 0.0276])\n",
      "3\n",
      "(tensor([1, 1, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.0070, 0.7733, 0.1103])\n",
      "3\n",
      "(tensor([0, 1, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.1270, 0.1371, 0.0589])\n",
      "3\n",
      "(tensor([0, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "0\n",
      "\n",
      "\n",
      "tensor([0.0818, 0.6996, 0.1478])\n",
      "3\n",
      "(tensor([0, 1, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.9312, 0.0025, 0.8102])\n",
      "3\n",
      "(tensor([1, 0, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.8488, 0.9807, 0.8933])\n",
      "0\n",
      "(tensor([1, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "3\n",
      "\n",
      "\n",
      "tensor([0.1026, 0.8947, 0.9987])\n",
      "3\n",
      "(tensor([0, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.2801, 0.0530, 0.7761])\n",
      "3\n",
      "(tensor([0, 0, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.0895, 0.9577, 0.8953])\n",
      "3\n",
      "(tensor([0, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.8325, 0.9742, 0.8604])\n",
      "0\n",
      "(tensor([1, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "3\n",
      "\n",
      "\n",
      "tensor([0.1347, 0.0393, 0.8221])\n",
      "3\n",
      "(tensor([0, 0, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.8707, 0.9195, 0.9815])\n",
      "0\n",
      "(tensor([1, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "3\n",
      "\n",
      "\n",
      "tensor([0.9551, 0.9017, 0.8217])\n",
      "0\n",
      "(tensor([1, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "3\n",
      "\n",
      "\n",
      "tensor([0.8862, 0.0881, 0.0853])\n",
      "3\n",
      "(tensor([1, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.9207, 0.1550, 0.8109])\n",
      "3\n",
      "(tensor([1, 0, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.0126, 0.8615, 0.9506])\n",
      "3\n",
      "(tensor([0, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.7117, 0.1201, 0.8036])\n",
      "3\n",
      "(tensor([1, 0, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.9256, 0.8617, 0.9275])\n",
      "0\n",
      "(tensor([1, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "3\n",
      "\n",
      "\n",
      "tensor([0.8518, 0.0963, 0.0623])\n",
      "3\n",
      "(tensor([1, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.1474, 0.9663, 0.8750])\n",
      "3\n",
      "(tensor([0, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.1651, 0.1840, 0.8177])\n",
      "3\n",
      "(tensor([0, 0, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.0346, 0.9185, 0.0943])\n",
      "3\n",
      "(tensor([0, 1, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.0502, 0.7333, 0.2293])\n",
      "3\n",
      "(tensor([0, 1, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.2037, 0.8828, 0.9526])\n",
      "3\n",
      "(tensor([0, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.2175, 0.0575, 0.0904])\n",
      "3\n",
      "(tensor([0, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "0\n",
      "\n",
      "\n",
      "tensor([0.2013, 0.0693, 0.7831])\n",
      "3\n",
      "(tensor([0, 0, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.9274, 0.0182, 0.2094])\n",
      "3\n",
      "(tensor([1, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.8374, 0.1662, 0.1270])\n",
      "3\n",
      "(tensor([1, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.1401, 0.0323, 0.0638])\n",
      "3\n",
      "(tensor([0, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "0\n",
      "\n",
      "\n",
      "tensor([0.0253, 0.8667, 0.9296])\n",
      "3\n",
      "(tensor([0, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.8582, 0.9253, 0.8882])\n",
      "0\n",
      "(tensor([1, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "3\n",
      "\n",
      "\n",
      "tensor([0.2335, 0.1814, 0.8772])\n",
      "3\n",
      "(tensor([0, 0, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.7911, 0.0161, 0.0988])\n",
      "3\n",
      "(tensor([1, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.2778, 0.7836, 0.9811])\n",
      "3\n",
      "(tensor([0, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.1453, 0.8631, 0.7482])\n",
      "3\n",
      "(tensor([0, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.8639, 0.8560, 0.8618])\n",
      "0\n",
      "(tensor([1, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "3\n",
      "\n",
      "\n",
      "tensor([0.9088, 0.9838, 0.9171])\n",
      "0\n",
      "(tensor([1, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "3\n",
      "\n",
      "\n",
      "tensor([0.1597, 0.9035, 0.0281])\n",
      "3\n",
      "(tensor([0, 1, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.8296, 0.9926, 0.1109])\n",
      "3\n",
      "(tensor([1, 1, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.9301, 0.9561, 0.1269])\n",
      "3\n",
      "(tensor([1, 1, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.1615, 0.1507, 0.1522])\n",
      "3\n",
      "(tensor([0, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "0\n",
      "\n",
      "\n",
      "tensor([0.8724, 0.9045, 0.1053])\n",
      "3\n",
      "(tensor([1, 1, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.8078, 0.7428, 0.8623])\n",
      "0\n",
      "(tensor([1, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "3\n",
      "\n",
      "\n",
      "tensor([0.8768, 0.1199, 0.8656])\n",
      "3\n",
      "(tensor([1, 0, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.9408, 0.6929, 0.8899])\n",
      "0\n",
      "(tensor([1, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "3\n",
      "\n",
      "\n",
      "tensor([0.0425, 0.1555, 0.1315])\n",
      "3\n",
      "(tensor([0, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "0\n",
      "\n",
      "\n",
      "tensor([0.0485, 0.2010, 0.0927])\n",
      "3\n",
      "(tensor([0, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "0\n",
      "\n",
      "\n",
      "tensor([0.1147, 0.0166, 0.2407])\n",
      "3\n",
      "(tensor([0, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "0\n",
      "\n",
      "\n",
      "tensor([0.0453, 0.9618, 0.7860])\n",
      "3\n",
      "(tensor([0, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n",
      "tensor([0.1334, 0.0329, 0.8009])\n",
      "3\n",
      "(tensor([0, 0, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.1177, 0.0481, 0.1909])\n",
      "3\n",
      "(tensor([0, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "0\n",
      "\n",
      "\n",
      "tensor([0.1827, 0.0958, 0.8671])\n",
      "3\n",
      "(tensor([0, 0, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.7413, 0.1764, 0.2524])\n",
      "3\n",
      "(tensor([1, 0, 0], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "1\n",
      "\n",
      "\n",
      "tensor([0.1611, 0.9466, 0.9315])\n",
      "3\n",
      "(tensor([0, 1, 1], dtype=torch.uint8), tensor([0.3333, 0.3333, 0.3333]))\n",
      "2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (tp_batch,) in enumerate(tp_dataloader_testing):\n",
    "    print(tp_batch[0])\n",
    "    print(costSharingDelay(tp_batch[0]))\n",
    "    print(costSharingSupervisionRule(tp_batch[0]))\n",
    "    print(torch.sum(costSharingSupervisionRule(tp_batch[0])[0]).item())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0, 0, 0]), tensor([0, 0, 1]), tensor([0, 1, 0]), tensor([0, 1, 1]), tensor([1, 0, 0]), tensor([1, 0, 1]), tensor([1, 1, 0]), tensor([1, 1, 1])]\n",
      "\n",
      "tensor([0.9132, 0.1612, 0.1141])\n",
      "tensor(0.3780, grad_fn=<SelectBackward>)\n",
      "tensor([0.3780, 0.2844, 0.3376], grad_fn=<SoftmaxBackward>)\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "allBits = [torch.tensor(bits) for bits in itertools.product([0, 1], repeat=n)]\n",
    "print(allBits)\n",
    "\n",
    "for batch_idx, (tp_batch,) in enumerate(tp_dataloader_testing):\n",
    "    penalty = 0\n",
    "    loss = penalty * penaltyLambda\n",
    "    for tp in tp_batch:\n",
    "            for i in range(n):\n",
    "                tp1 = tp.clone()\n",
    "                tp1[i] = 1\n",
    "                tp0 = tp.clone()\n",
    "                tp0[i] = 0\n",
    "                offer = tpToPayments(tp1)[i]\n",
    "                delay1 = tpToTotalDelay(tp1)\n",
    "                delay0 = tpToTotalDelay(tp0)\n",
    "                #loss = loss + (1 - cdf(offer)) * delay1 + cdf(offer) * delay0\n",
    "                loss = loss + (1 - cdf(offer,order)) * delay1 + cdf(offer,order) * delay0\n",
    "    print()\n",
    "    print(tp)\n",
    "    tp1 = tp.clone()\n",
    "    tp1[0] = 1\n",
    "    tp0 = tp.clone()\n",
    "    tp0[0] = 0\n",
    "    offer = tpToPayments(tp1)[0]\n",
    "    print(offer)\n",
    "    print(tpToPayments(tp1))\n",
    "    print(delay1)\n",
    "    print(delay0)\n",
    "    break\n",
    "#print(loss)\n",
    "#print(penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordAndReport(name, source, loss):\n",
    "    source.append(loss)\n",
    "    realLength = len(source)\n",
    "    #print(f\"{name} ({realLength}): {loss}\")\n",
    "    print(name,realLength,\":\" ,loss)\n",
    "\n",
    "def supervisionTrain(epoch, supervisionRule):\n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        loss = penalty * penaltyLambda /100000\n",
    "        \n",
    "        for tp in tp_batch:\n",
    "            bits, payments = supervisionRule(tp)\n",
    "            #print(\"bits\",bitsToPayments(bits))\n",
    "            loss = loss + F.mse_loss(bitsToPayments(bits), payments)\n",
    "\n",
    "        loss = loss / len(tp_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "losslist=[];\n",
    "losslistname=[];\n",
    "losslisttemp=[];\n",
    "def test_batch():\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        lenLoss= 0\n",
    "        nnLoss = 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "            for tp in tp_batch:\n",
    "                nnLoss += tpToTotalDelay(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        nnLoss/=lenLoss\n",
    "    return nnLoss\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    global losslisttemp; \n",
    "    model.train()\n",
    "    for batch_idx, (tp_batch,) in enumerate(tp_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        penalty = 0\n",
    "        loss = penalty * penaltyLambda\n",
    "        for tp in tp_batch:\n",
    "            for i in range(n):\n",
    "                tp1 = tp.clone()\n",
    "                tp1[i] = 1\n",
    "                tp0 = tp.clone()\n",
    "                tp0[i] = 0\n",
    "                offer = tpToPayments(tp1)[i]\n",
    "                delay1 = tpToTotalDelay(tp1)\n",
    "                delay0 = tpToTotalDelay(tp0)\n",
    "                if(order!=\"independent1\" and order!=\"independent2\"):\n",
    "                    loss = loss + (1 - cdf(offer,order)) * delay1 + cdf(offer,order) * delay0\n",
    "                else:\n",
    "                    loss = loss + (1 - cdf(offer,order,i)) * delay1 + cdf(offer,order,i) * delay0\n",
    "\n",
    "        loss = loss / len(tp_batch) / n\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            losstemp=test_batch();\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(tp_batch),\n",
    "                    len(tp_dataloader.dataset),\n",
    "                    100.0 * batch_idx / len(tp_dataloader),\n",
    "                    loss.item(),\n",
    "                ),\"testing loss:\",losstemp\n",
    "            )\n",
    "            losslisttemp.append(losstemp);\n",
    "            \n",
    "    \n",
    "allBits = [torch.tensor(bits, dtype=torch.int16) for bits in itertools.product([0, 1], repeat=n)]\n",
    "\n",
    "def test():\n",
    "    global losslisttemp; \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        costSharingLoss = 0\n",
    "        dpLoss = 0\n",
    "        nnLoss = 0\n",
    "        lenLoss= 0\n",
    "        for (tp_batch,) in tp_dataloader_testing:\n",
    "\n",
    "            for tp in tp_batch:\n",
    "                costSharingLoss += costSharingDelay(tp)\n",
    "                dpLoss += dpDelay(tp)\n",
    "                nnLoss += tpToTotalDelay(tp)\n",
    "            lenLoss+=len(tp_batch)\n",
    "        costSharingLoss /= lenLoss\n",
    "        dpLoss /= lenLoss\n",
    "        nnLoss /= lenLoss\n",
    "        #print(lenLoss)\n",
    "        losslisttemp.append(nnLoss);\n",
    "        recordAndReport(\"NN\", runningLossNN, nnLoss)\n",
    "        recordAndReport(\"CS\", runningLossCS, costSharingLoss)\n",
    "        recordAndReport(\"DP\", runningLossDP, dpLoss)\n",
    "        print(\"DP:\",n*(1-dp[n, dpPrecision]))\n",
    "        #for i in range(n, 0, -1):\n",
    "        #    print(\"Heuristic:\",i,5*(1-dp_H[i, i, dpPrecision]))\n",
    "        for i in range(n, 0, -1):\n",
    "            print(\n",
    "                    tpToPayments(\n",
    "                            torch.tensor([0 if ii >= i else 1 for ii in range(n)], dtype=torch.float32)\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "dpPrecision = 100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8413)\n",
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: 0.001468\n",
      "Train Epoch: 1 [2560/15000 (17%)]\tLoss: 0.000038\n",
      "Train Epoch: 1 [5120/15000 (34%)]\tLoss: 0.000011\n",
      "Train Epoch: 1 [7680/15000 (51%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [10240/15000 (68%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [12800/15000 (85%)]\tLoss: 0.000000\n",
      "NN 1 : 2.6236\n",
      "CS 1 : 2.6236\n",
      "DP 1 : 2.2342\n",
      "DP: 2.2242771685123444\n",
      "tensor([0.3334, 0.3333, 0.3333])\n",
      "tensor([0.3334, 0.3333, 0.3333])\n",
      "tensor([0.3334, 0.3333, 0.3333])\n",
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: 2.624578 testing loss: 2.6234\n",
      "Train Epoch: 1 [2560/15000 (17%)]\tLoss: 2.290394 testing loss: 2.2744\n",
      "Train Epoch: 1 [5120/15000 (34%)]\tLoss: 2.269862 testing loss: 2.2624\n",
      "Train Epoch: 1 [7680/15000 (51%)]\tLoss: 2.286751 testing loss: 2.246\n",
      "Train Epoch: 1 [10240/15000 (68%)]\tLoss: 2.225124 testing loss: 2.2288\n",
      "Train Epoch: 1 [12800/15000 (85%)]\tLoss: 2.221406 testing loss: 2.2214\n",
      "NN 2 : 2.2228\n",
      "CS 2 : 2.6236\n",
      "DP 2 : 2.2342\n",
      "DP: 2.2242771685123444\n",
      "tensor([0.1145, 0.7881, 0.0974])\n",
      "tensor([0.1145, 0.7881, 0.0974])\n",
      "tensor([0.1145, 0.7881, 0.0974])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, supervisionEpochs + 1):\n",
    "    print(distributionRatio1)\n",
    "    supervisionTrain(epoch, costSharingSupervisionRule)\n",
    "    #supervisionTrain(epoch, dpSupervisionRule)\n",
    "test()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    train(epoch)\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "order1=\"\"\n",
    "losslistname.append(order+\" \"+order1);\n",
    "losslist.append(losslisttemp);\n",
    "losslisttemp=[];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colorlist=[\"#D2691E\",'#4169E1',\"#9ACD32\",\"#B22222\",\"#FF00FF\",\"#708090\"]\n",
    "for i in range(len(losslist)):\n",
    "    plt.plot(losslist[i], 'ro-', color=colorlist[i], alpha=0.8, label=losslistname[i])\n",
    "\n",
    "# 显示标签，如果不加这句，即使加了label='一些数字'的参数，最终还是不会显示标签\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('trianing times')\n",
    "plt.ylabel('delay')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
